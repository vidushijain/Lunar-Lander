<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>Assignment_2_Part_2</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Assignment-2:-Lunar-Lander--Task-2">Assignment 2: Lunar Lander- Task 2<a class="anchor-link" href="#Assignment-2:-Lunar-Lander--Task-2">&#182;</a></h2><p>Student Name- Vidushi Jain <br/>
Student Number- 18200009</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Part-2.-Use-the-DeepQLearning-reinforcement-learning-algorithm-to-train-an-agent-to-play-the-Lunar-Lander-">Part 2. Use the DeepQLearning reinforcement learning algorithm to train an agent to play the Lunar Lander <br /><a class="anchor-link" href="#Part-2.-Use-the-DeepQLearning-reinforcement-learning-algorithm-to-train-an-agent-to-play-the-Lunar-Lander-">&#182;</a></h2><p> Select sensible hyper-parameters<br/>
 Perform a suitable evaluation experiment to determine how effective the model trained is &lt;/br&gt;</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rl_model_reward_comparisons</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">rl_model_time_comparisons</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="k">import</span> <span class="n">Adam</span>

<span class="kn">from</span> <span class="nn">rl.agents.dqn</span> <span class="k">import</span> <span class="n">DQNAgent</span>
<span class="kn">from</span> <span class="nn">rl.policy</span> <span class="k">import</span> <span class="n">BoltzmannQPolicy</span><span class="p">,</span> <span class="n">EpsGreedyQPolicy</span><span class="p">,</span> <span class="n">LinearAnnealedPolicy</span>
<span class="kn">from</span> <span class="nn">rl.memory</span> <span class="k">import</span> <span class="n">SequentialMemory</span>
<span class="kn">import</span> <span class="nn">time</span>



<span class="c1"># Path environment changed to make things work properly</span>
<span class="c1"># export DYLD_FALLBACK_LIBRARY_PATH=$DYLD_FALLBACK_LIBRARY_PATH:/usr/lib</span>


<span class="n">ENV_NAME</span> <span class="o">=</span> <span class="s1">&#39;LunarLander-v2&#39;</span>


<span class="c1"># Get the environment and extract the number of actions.</span>
<span class="c1">#env = gym.make(ENV_NAME)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">nb_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Model-1">Model 1<a class="anchor-link" href="#Model-1">&#182;</a></h1><p><a id="task2_model1"></a>
<b>Model Architecture</b></p>
<p>1) We have created a Sequential model with three hidden layers with 16 neurons each. The input will be a 1 x state space vector and there will be an output neuron for each possible action that will predict the Q value of that action for each step. By taking the argmax of the outputs, we can choose the action with the highest Q value.<br/>
2) We have created a SequentialMemory object of class called rl.memory.SequentialMemory. This provides a fast and efficient data structure for storing the agent's experience. In that we have specified the maximum size for this memory object as 50000. As new experiences are added to this memory and it becomes full, old experiences are forgotten. <br/>
3) We have used EpsGreedyQPolicy which we can use to balance exploration and exploitation. We can set the value of  in this policy.If a random number is selected which is less than this value, an action is chosen completely at random Otherwise the best action is choosen. This step allows some random exploration of the value of various actions in various states, and can be scaled back over time to allow the algorithm to concentrate more on exploiting the best strategies that it has found. In this model, we have used the default value of <b>eps</b> which is <b>0.1</b> <br/>
4) After our model,memory and policy are defined, we create a deep Q network Agent and send that agent with those objects. <br/>
5) Finally the model is compiled using a mean-squared error loss function with the Adam optimizer. <b>The learning rate of Adam optimizer is set to 0.0001.</b></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Next, we build a very simple model.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="c1"># Finally, we configure and compile our agent. You can use every built-in Keras optimizer and</span>
<span class="c1"># even the metrics!</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">SequentialMemory</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">window_length</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">EpsGreedyQPolicy</span><span class="p">()</span>
<span class="n">dqn</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">nb_actions</span><span class="o">=</span><span class="n">nb_actions</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="n">nb_steps_warmup</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
               <span class="n">target_model_update</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">)</span>
<span class="n">dqn</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mae&#39;</span><span class="p">])</span>

<span class="c1"># Okay, now it&#39;s time to learn something! We visualize the training here for show, but this</span>
<span class="c1"># slows down training quite a lot. You can always safely abort the training prematurely using</span>
<span class="c1"># Ctrl + C.</span>

<span class="n">start</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">dqn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_steps</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">timetaken</span><span class="o">=</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
<span class="n">rl_model_time_comparisons</span><span class="p">[</span><span class="s1">&#39;Model 1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">timetaken</span>

<span class="c1"># After training is done, we save the final weights.</span>
<span class="n">dqn</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;dqn_</span><span class="si">{}</span><span class="s1">_weights_model1.h5f&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ENV_NAME</span><span class="p">),</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 8)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                144       
_________________________________________________________________
activation_1 (Activation)    (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 16)                272       
_________________________________________________________________
activation_2 (Activation)    (None, 16)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 16)                272       
_________________________________________________________________
activation_3 (Activation)    (None, 16)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 4)                 68        
_________________________________________________________________
activation_4 (Activation)    (None, 4)                 0         
=================================================================
Total params: 756
Trainable params: 756
Non-trainable params: 0
_________________________________________________________________
None
Training for 100000 steps ...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/anaconda3/lib/python3.6/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!
  warnings.warn(&#39;Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!&#39;)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>    83/100000: episode: 1, duration: 1.594s, episode steps: 83, steps per second: 52, episode reward: -555.523, mean reward: -6.693 [-100.000, 2.843], mean action: 1.458 [1.000, 3.000], mean observation: 0.141 [-3.516, 3.300], loss: 10.181509, mean_absolute_error: 0.996055, mean_q: 0.192844
   157/100000: episode: 2, duration: 0.385s, episode steps: 74, steps per second: 192, episode reward: -425.596, mean reward: -5.751 [-100.000, 1.874], mean action: 1.297 [0.000, 3.000], mean observation: 0.161 [-1.476, 2.642], loss: 59.335529, mean_absolute_error: 1.477775, mean_q: 0.153759
   214/100000: episode: 3, duration: 0.296s, episode steps: 57, steps per second: 193, episode reward: -328.833, mean reward: -5.769 [-100.000, -1.098], mean action: 0.807 [0.000, 3.000], mean observation: 0.065 [-1.662, 1.988], loss: 73.101723, mean_absolute_error: 1.507687, mean_q: 0.088515
   271/100000: episode: 4, duration: 0.284s, episode steps: 57, steps per second: 201, episode reward: -262.763, mean reward: -4.610 [-100.000, 3.840], mean action: 0.702 [0.000, 3.000], mean observation: 0.006 [-1.926, 5.592], loss: 57.101704, mean_absolute_error: 1.386591, mean_q: 0.077560
   338/100000: episode: 5, duration: 0.333s, episode steps: 67, steps per second: 201, episode reward: -216.563, mean reward: -3.232 [-100.000, 3.593], mean action: 1.269 [0.000, 3.000], mean observation: -0.020 [-1.827, 1.409], loss: 89.987228, mean_absolute_error: 1.462803, mean_q: 0.059866
   408/100000: episode: 6, duration: 0.353s, episode steps: 70, steps per second: 198, episode reward: -311.121, mean reward: -4.445 [-100.000, 125.325], mean action: 1.357 [0.000, 3.000], mean observation: -0.110 [-4.099, 1.401], loss: 97.875191, mean_absolute_error: 1.422450, mean_q: 0.041121
   494/100000: episode: 7, duration: 0.443s, episode steps: 86, steps per second: 194, episode reward: -390.318, mean reward: -4.539 [-100.000, 2.649], mean action: 2.105 [0.000, 3.000], mean observation: -0.036 [-2.370, 1.687], loss: 106.577583, mean_absolute_error: 1.526659, mean_q: 0.026802
   549/100000: episode: 8, duration: 0.278s, episode steps: 55, steps per second: 198, episode reward: -109.577, mean reward: -1.992 [-100.000, 9.528], mean action: 1.145 [0.000, 3.000], mean observation: -0.035 [-1.782, 5.729], loss: 95.037621, mean_absolute_error: 1.448215, mean_q: 0.008100
   616/100000: episode: 9, duration: 0.331s, episode steps: 67, steps per second: 202, episode reward: -109.364, mean reward: -1.632 [-100.000, 20.196], mean action: 0.239 [0.000, 3.000], mean observation: -0.055 [-4.089, 1.412], loss: 73.825768, mean_absolute_error: 1.305684, mean_q: -0.002182
   704/100000: episode: 10, duration: 0.427s, episode steps: 88, steps per second: 206, episode reward: -211.455, mean reward: -2.403 [-100.000, 7.865], mean action: 0.193 [0.000, 3.000], mean observation: 0.038 [-1.820, 2.955], loss: 86.853050, mean_absolute_error: 1.346904, mean_q: -0.010202
   763/100000: episode: 11, duration: 0.288s, episode steps: 59, steps per second: 205, episode reward: -169.275, mean reward: -2.869 [-100.000, 5.753], mean action: 0.339 [0.000, 3.000], mean observation: 0.072 [-1.714, 4.516], loss: 81.573509, mean_absolute_error: 1.279340, mean_q: -0.021195
   851/100000: episode: 12, duration: 0.435s, episode steps: 88, steps per second: 203, episode reward: -110.260, mean reward: -1.253 [-100.000, 8.541], mean action: 0.364 [0.000, 3.000], mean observation: 0.171 [-1.678, 5.875], loss: 83.994286, mean_absolute_error: 1.253596, mean_q: -0.037362
   909/100000: episode: 13, duration: 0.285s, episode steps: 58, steps per second: 203, episode reward: -99.034, mean reward: -1.707 [-100.000, 49.726], mean action: 0.224 [0.000, 3.000], mean observation: 0.027 [-1.775, 4.263], loss: 101.000336, mean_absolute_error: 1.331362, mean_q: -0.049998
   962/100000: episode: 14, duration: 0.260s, episode steps: 53, steps per second: 204, episode reward: -97.855, mean reward: -1.846 [-100.000, 9.358], mean action: 0.170 [0.000, 3.000], mean observation: -0.096 [-5.346, 1.388], loss: 86.667908, mean_absolute_error: 1.299449, mean_q: -0.065951
  1044/100000: episode: 15, duration: 0.395s, episode steps: 82, steps per second: 207, episode reward: -124.846, mean reward: -1.523 [-100.000, 8.545], mean action: 0.317 [0.000, 3.000], mean observation: 0.038 [-1.829, 1.450], loss: 70.026657, mean_absolute_error: 1.220333, mean_q: -0.079930
  1120/100000: episode: 16, duration: 0.365s, episode steps: 76, steps per second: 208, episode reward: -162.438, mean reward: -2.137 [-100.000, 7.775], mean action: 0.118 [0.000, 3.000], mean observation: 0.099 [-5.427, 1.448], loss: 62.212551, mean_absolute_error: 1.148338, mean_q: -0.099315
  1185/100000: episode: 17, duration: 0.326s, episode steps: 65, steps per second: 199, episode reward: -121.672, mean reward: -1.872 [-100.000, 16.076], mean action: 0.277 [0.000, 3.000], mean observation: -0.038 [-6.021, 1.402], loss: 87.050758, mean_absolute_error: 1.311912, mean_q: -0.121837
  1251/100000: episode: 18, duration: 0.321s, episode steps: 66, steps per second: 205, episode reward: -172.190, mean reward: -2.609 [-100.000, 5.827], mean action: 0.197 [0.000, 3.000], mean observation: 0.048 [-1.843, 1.426], loss: 91.314423, mean_absolute_error: 1.338305, mean_q: -0.152215
  1338/100000: episode: 19, duration: 0.426s, episode steps: 87, steps per second: 204, episode reward: -107.985, mean reward: -1.241 [-100.000, 16.501], mean action: 0.230 [0.000, 3.000], mean observation: -0.002 [-1.826, 1.480], loss: 65.077110, mean_absolute_error: 1.214613, mean_q: -0.190198
  1415/100000: episode: 20, duration: 0.374s, episode steps: 77, steps per second: 206, episode reward: -139.704, mean reward: -1.814 [-100.000, 9.029], mean action: 0.325 [0.000, 3.000], mean observation: -0.019 [-5.698, 1.431], loss: 85.219505, mean_absolute_error: 1.338997, mean_q: -0.229781
  1500/100000: episode: 21, duration: 0.414s, episode steps: 85, steps per second: 205, episode reward: -143.474, mean reward: -1.688 [-100.000, 13.989], mean action: 0.612 [0.000, 3.000], mean observation: 0.073 [-1.857, 1.451], loss: 56.322845, mean_absolute_error: 1.248334, mean_q: -0.276508
  1556/100000: episode: 22, duration: 0.278s, episode steps: 56, steps per second: 202, episode reward: -117.399, mean reward: -2.096 [-100.000, 5.456], mean action: 0.732 [0.000, 3.000], mean observation: -0.008 [-1.823, 5.973], loss: 78.785820, mean_absolute_error: 1.375351, mean_q: -0.315784
  1629/100000: episode: 23, duration: 0.358s, episode steps: 73, steps per second: 204, episode reward: -172.494, mean reward: -2.363 [-100.000, 9.907], mean action: 0.630 [0.000, 3.000], mean observation: -0.031 [-4.600, 1.417], loss: 89.529694, mean_absolute_error: 1.447737, mean_q: -0.358672
  1707/100000: episode: 24, duration: 0.378s, episode steps: 78, steps per second: 206, episode reward: -157.718, mean reward: -2.022 [-100.000, 8.020], mean action: 0.333 [0.000, 3.000], mean observation: 0.016 [-1.768, 5.536], loss: 78.986557, mean_absolute_error: 1.468633, mean_q: -0.410018
  1769/100000: episode: 25, duration: 0.311s, episode steps: 62, steps per second: 199, episode reward: -101.471, mean reward: -1.637 [-100.000, 10.767], mean action: 0.806 [0.000, 3.000], mean observation: -0.084 [-4.862, 1.404], loss: 74.222755, mean_absolute_error: 1.451787, mean_q: -0.464983
  1847/100000: episode: 26, duration: 0.393s, episode steps: 78, steps per second: 198, episode reward: -154.519, mean reward: -1.981 [-100.000, 3.080], mean action: 0.821 [0.000, 3.000], mean observation: -0.113 [-1.870, 5.908], loss: 78.068520, mean_absolute_error: 1.540789, mean_q: -0.520559
  1929/100000: episode: 27, duration: 0.406s, episode steps: 82, steps per second: 202, episode reward: -82.676, mean reward: -1.008 [-100.000, 49.726], mean action: 1.195 [0.000, 3.000], mean observation: -0.148 [-2.307, 2.027], loss: 49.648647, mean_absolute_error: 1.461039, mean_q: -0.562372
  2023/100000: episode: 28, duration: 0.464s, episode steps: 94, steps per second: 203, episode reward: -226.174, mean reward: -2.406 [-100.000, 5.051], mean action: 0.553 [0.000, 3.000], mean observation: -0.141 [-4.834, 1.525], loss: 75.074142, mean_absolute_error: 1.679501, mean_q: -0.606739
  2076/100000: episode: 29, duration: 0.275s, episode steps: 53, steps per second: 193, episode reward: -206.153, mean reward: -3.890 [-100.000, 59.571], mean action: 1.943 [0.000, 3.000], mean observation: -0.234 [-4.946, 1.386], loss: 64.485588, mean_absolute_error: 1.655640, mean_q: -0.644422
  2150/100000: episode: 30, duration: 0.374s, episode steps: 74, steps per second: 198, episode reward: -227.960, mean reward: -3.081 [-100.000, 70.240], mean action: 1.392 [0.000, 3.000], mean observation: -0.240 [-4.327, 1.413], loss: 57.721172, mean_absolute_error: 1.681816, mean_q: -0.690200
  2215/100000: episode: 31, duration: 0.352s, episode steps: 65, steps per second: 185, episode reward: -562.688, mean reward: -8.657 [-100.000, -2.002], mean action: 2.769 [1.000, 3.000], mean observation: -0.183 [-3.998, 1.405], loss: 82.631088, mean_absolute_error: 1.880725, mean_q: -0.753196
  2275/100000: episode: 32, duration: 0.315s, episode steps: 60, steps per second: 191, episode reward: -261.098, mean reward: -4.352 [-100.000, 41.211], mean action: 2.283 [1.000, 3.000], mean observation: -0.172 [-5.089, 1.394], loss: 81.957642, mean_absolute_error: 1.972646, mean_q: -0.836198
  2348/100000: episode: 33, duration: 0.381s, episode steps: 73, steps per second: 192, episode reward: -214.102, mean reward: -2.933 [-100.000, 32.287], mean action: 2.055 [0.000, 3.000], mean observation: -0.167 [-4.855, 1.411], loss: 76.240227, mean_absolute_error: 2.061826, mean_q: -0.985236
  2429/100000: episode: 34, duration: 0.432s, episode steps: 81, steps per second: 187, episode reward: -292.851, mean reward: -3.615 [-100.000, 3.930], mean action: 2.099 [1.000, 3.000], mean observation: 0.011 [-1.839, 1.445], loss: 79.767128, mean_absolute_error: 2.166635, mean_q: -1.140820
  2501/100000: episode: 35, duration: 0.377s, episode steps: 72, steps per second: 191, episode reward: -265.200, mean reward: -3.683 [-100.000, 8.301], mean action: 2.056 [0.000, 3.000], mean observation: -0.110 [-7.587, 1.413], loss: 69.744492, mean_absolute_error: 2.260918, mean_q: -1.291084
  2560/100000: episode: 36, duration: 0.307s, episode steps: 59, steps per second: 192, episode reward: -219.726, mean reward: -3.724 [-100.000, 61.882], mean action: 2.136 [0.000, 3.000], mean observation: -0.161 [-4.444, 1.395], loss: 71.441460, mean_absolute_error: 2.345353, mean_q: -1.414817
  2615/100000: episode: 37, duration: 0.288s, episode steps: 55, steps per second: 191, episode reward: -212.305, mean reward: -3.860 [-100.000, 69.281], mean action: 2.109 [1.000, 3.000], mean observation: -0.153 [-3.635, 1.385], loss: 70.618271, mean_absolute_error: 2.507865, mean_q: -1.558301
  2698/100000: episode: 38, duration: 0.428s, episode steps: 83, steps per second: 194, episode reward: -243.388, mean reward: -2.932 [-100.000, 17.215], mean action: 2.000 [0.000, 3.000], mean observation: -0.076 [-6.004, 1.445], loss: 73.518555, mean_absolute_error: 2.640953, mean_q: -1.733916
  2754/100000: episode: 39, duration: 0.296s, episode steps: 56, steps per second: 189, episode reward: -193.163, mean reward: -3.449 [-100.000, 5.731], mean action: 2.214 [0.000, 3.000], mean observation: -0.224 [-5.575, 1.393], loss: 110.101578, mean_absolute_error: 2.958438, mean_q: -1.953035
  2841/100000: episode: 40, duration: 0.446s, episode steps: 87, steps per second: 195, episode reward: -260.097, mean reward: -2.990 [-100.000, 5.831], mean action: 2.000 [0.000, 3.000], mean observation: 0.035 [-1.750, 1.518], loss: 98.787033, mean_absolute_error: 3.115916, mean_q: -2.178008
  2941/100000: episode: 41, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: -347.351, mean reward: -3.474 [-100.000, 123.427], mean action: 1.810 [0.000, 3.000], mean observation: -0.264 [-3.400, 1.413], loss: 75.745338, mean_absolute_error: 3.257303, mean_q: -2.483233
  2998/100000: episode: 42, duration: 0.298s, episode steps: 57, steps per second: 192, episode reward: -206.820, mean reward: -3.628 [-100.000, 37.772], mean action: 2.070 [0.000, 3.000], mean observation: -0.090 [-6.527, 1.393], loss: 92.502777, mean_absolute_error: 3.540110, mean_q: -2.720803
  3065/100000: episode: 43, duration: 0.347s, episode steps: 67, steps per second: 193, episode reward: -274.834, mean reward: -4.102 [-100.000, 67.942], mean action: 2.045 [1.000, 3.000], mean observation: -0.099 [-4.633, 1.404], loss: 97.535065, mean_absolute_error: 3.735502, mean_q: -2.954482
  3155/100000: episode: 44, duration: 0.475s, episode steps: 90, steps per second: 189, episode reward: -187.192, mean reward: -2.080 [-100.000, 85.761], mean action: 2.011 [1.000, 3.000], mean observation: -0.111 [-3.519, 1.493], loss: 55.870132, mean_absolute_error: 3.693555, mean_q: -3.223794
  3222/100000: episode: 45, duration: 0.356s, episode steps: 67, steps per second: 188, episode reward: -235.452, mean reward: -3.514 [-100.000, 6.220], mean action: 1.970 [0.000, 3.000], mean observation: -0.022 [-1.933, 1.409], loss: 78.757523, mean_absolute_error: 4.013494, mean_q: -3.500955
  3302/100000: episode: 46, duration: 0.422s, episode steps: 80, steps per second: 190, episode reward: -234.878, mean reward: -2.936 [-100.000, 7.495], mean action: 2.062 [0.000, 3.000], mean observation: -0.066 [-4.059, 1.446], loss: 89.770302, mean_absolute_error: 4.376426, mean_q: -3.841354
  3382/100000: episode: 47, duration: 0.415s, episode steps: 80, steps per second: 193, episode reward: -212.925, mean reward: -2.662 [-100.000, 34.400], mean action: 1.975 [0.000, 3.000], mean observation: -0.047 [-4.687, 1.431], loss: 68.256790, mean_absolute_error: 4.488160, mean_q: -4.188830
  3436/100000: episode: 48, duration: 0.279s, episode steps: 54, steps per second: 193, episode reward: -200.305, mean reward: -3.709 [-100.000, 6.048], mean action: 2.037 [0.000, 3.000], mean observation: -0.099 [-2.335, 1.386], loss: 91.551208, mean_absolute_error: 4.869494, mean_q: -4.560133
  3511/100000: episode: 49, duration: 0.383s, episode steps: 75, steps per second: 196, episode reward: -219.394, mean reward: -2.925 [-100.000, 6.005], mean action: 1.587 [0.000, 3.000], mean observation: -0.191 [-6.776, 1.418], loss: 96.369255, mean_absolute_error: 5.124916, mean_q: -4.933808
  3587/100000: episode: 50, duration: 0.395s, episode steps: 76, steps per second: 192, episode reward: -357.935, mean reward: -4.710 [-100.000, 111.109], mean action: 1.829 [0.000, 3.000], mean observation: -0.186 [-3.432, 1.401], loss: 91.488472, mean_absolute_error: 5.444623, mean_q: -5.429756
  3674/100000: episode: 51, duration: 0.435s, episode steps: 87, steps per second: 200, episode reward: -190.951, mean reward: -2.195 [-100.000, 28.557], mean action: 0.770 [0.000, 3.000], mean observation: -0.122 [-5.236, 1.481], loss: 49.255753, mean_absolute_error: 5.620492, mean_q: -5.936885
  3754/100000: episode: 52, duration: 0.403s, episode steps: 80, steps per second: 198, episode reward: -231.523, mean reward: -2.894 [-100.000, 7.412], mean action: 0.625 [0.000, 3.000], mean observation: -0.039 [-6.728, 1.439], loss: 76.282394, mean_absolute_error: 6.145980, mean_q: -6.432063
  3810/100000: episode: 53, duration: 0.283s, episode steps: 56, steps per second: 198, episode reward: -176.689, mean reward: -3.155 [-100.000, 5.939], mean action: 1.018 [0.000, 3.000], mean observation: -0.207 [-6.561, 1.391], loss: 79.184898, mean_absolute_error: 6.488236, mean_q: -6.874758
  3899/100000: episode: 54, duration: 0.440s, episode steps: 89, steps per second: 202, episode reward: -213.680, mean reward: -2.401 [-100.000, 6.693], mean action: 0.607 [0.000, 3.000], mean observation: 0.063 [-6.990, 1.500], loss: 78.736694, mean_absolute_error: 6.880053, mean_q: -7.442422
  3974/100000: episode: 55, duration: 0.367s, episode steps: 75, steps per second: 204, episode reward: -197.207, mean reward: -2.629 [-100.000, 7.770], mean action: 0.413 [0.000, 3.000], mean observation: -0.059 [-1.789, 1.425], loss: 68.985527, mean_absolute_error: 7.217761, mean_q: -8.022926
  4029/100000: episode: 56, duration: 0.280s, episode steps: 55, steps per second: 196, episode reward: -162.803, mean reward: -2.960 [-100.000, 9.406], mean action: 0.782 [0.000, 3.000], mean observation: -0.088 [-1.847, 3.013], loss: 72.240402, mean_absolute_error: 7.691441, mean_q: -8.602278
  4084/100000: episode: 57, duration: 0.278s, episode steps: 55, steps per second: 198, episode reward: -132.768, mean reward: -2.414 [-100.000, 10.549], mean action: 0.582 [0.000, 3.000], mean observation: -0.086 [-1.779, 4.927], loss: 87.052834, mean_absolute_error: 8.130480, mean_q: -9.051161
  4159/100000: episode: 58, duration: 0.365s, episode steps: 75, steps per second: 205, episode reward: -156.740, mean reward: -2.090 [-100.000, 11.148], mean action: 0.200 [0.000, 3.000], mean observation: 0.113 [-1.705, 5.446], loss: 59.365658, mean_absolute_error: 8.347437, mean_q: -9.608255
  4227/100000: episode: 59, duration: 0.340s, episode steps: 68, steps per second: 200, episode reward: -132.905, mean reward: -1.954 [-100.000, 6.299], mean action: 0.706 [0.000, 3.000], mean observation: -0.105 [-1.720, 6.020], loss: 70.062195, mean_absolute_error: 8.768688, mean_q: -10.132042
  4295/100000: episode: 60, duration: 0.348s, episode steps: 68, steps per second: 196, episode reward: -131.118, mean reward: -1.928 [-100.000, 12.821], mean action: 0.632 [0.000, 3.000], mean observation: 0.067 [-1.634, 4.372], loss: 80.207359, mean_absolute_error: 9.317349, mean_q: -10.759901
  4381/100000: episode: 61, duration: 0.420s, episode steps: 86, steps per second: 205, episode reward: -118.775, mean reward: -1.381 [-100.000, 16.105], mean action: 0.372 [0.000, 3.000], mean observation: -0.023 [-1.789, 1.474], loss: 70.022072, mean_absolute_error: 9.847662, mean_q: -11.565759
  4438/100000: episode: 62, duration: 0.282s, episode steps: 57, steps per second: 202, episode reward: -70.977, mean reward: -1.245 [-100.000, 12.467], mean action: 0.842 [0.000, 3.000], mean observation: -0.040 [-1.577, 4.154], loss: 56.458893, mean_absolute_error: 10.216285, mean_q: -12.168903
  4510/100000: episode: 63, duration: 0.360s, episode steps: 72, steps per second: 200, episode reward: -88.633, mean reward: -1.231 [-100.000, 10.839], mean action: 0.750 [0.000, 3.000], mean observation: 0.006 [-1.413, 4.012], loss: 66.762115, mean_absolute_error: 10.689608, mean_q: -12.661192
  4611/100000: episode: 64, duration: 0.530s, episode steps: 101, steps per second: 191, episode reward: -343.947, mean reward: -3.405 [-100.000, 4.838], mean action: 1.762 [0.000, 3.000], mean observation: 0.118 [-0.942, 2.521], loss: 61.912197, mean_absolute_error: 11.180488, mean_q: -13.366904
  4682/100000: episode: 65, duration: 0.367s, episode steps: 71, steps per second: 193, episode reward: 8.898, mean reward: 0.125 [-100.000, 13.408], mean action: 1.169 [0.000, 3.000], mean observation: 0.012 [-1.281, 1.969], loss: 51.912762, mean_absolute_error: 11.601897, mean_q: -14.000808
  4763/100000: episode: 66, duration: 0.411s, episode steps: 81, steps per second: 197, episode reward: -28.780, mean reward: -0.355 [-100.000, 22.552], mean action: 1.136 [0.000, 3.000], mean observation: -0.094 [-1.326, 1.408], loss: 57.337860, mean_absolute_error: 12.153786, mean_q: -14.727612
  4863/100000: episode: 67, duration: 0.513s, episode steps: 100, steps per second: 195, episode reward: -394.700, mean reward: -3.947 [-100.000, 0.859], mean action: 1.560 [0.000, 3.000], mean observation: 0.369 [-0.365, 2.088], loss: 65.781494, mean_absolute_error: 12.685575, mean_q: -15.247335
  4974/100000: episode: 68, duration: 0.578s, episode steps: 111, steps per second: 192, episode reward: -774.060, mean reward: -6.974 [-100.000, 0.874], mean action: 1.928 [0.000, 3.000], mean observation: 0.629 [-0.491, 4.837], loss: 53.466797, mean_absolute_error: 13.351510, mean_q: -16.090406
  5048/100000: episode: 69, duration: 0.387s, episode steps: 74, steps per second: 191, episode reward: -497.868, mean reward: -6.728 [-100.000, 0.371], mean action: 1.932 [0.000, 3.000], mean observation: 0.383 [-1.113, 2.531], loss: 53.854778, mean_absolute_error: 14.014830, mean_q: -16.973848
  5130/100000: episode: 70, duration: 0.427s, episode steps: 82, steps per second: 192, episode reward: -376.602, mean reward: -4.593 [-100.000, 1.662], mean action: 1.610 [0.000, 2.000], mean observation: 0.261 [-0.757, 2.502], loss: 58.471306, mean_absolute_error: 14.630855, mean_q: -17.812149
  5191/100000: episode: 71, duration: 0.300s, episode steps: 61, steps per second: 204, episode reward: -118.280, mean reward: -1.939 [-100.000, 17.375], mean action: 0.459 [0.000, 3.000], mean observation: -0.048 [-3.497, 1.399], loss: 33.546787, mean_absolute_error: 14.966753, mean_q: -18.484106
  5263/100000: episode: 72, duration: 0.356s, episode steps: 72, steps per second: 202, episode reward: -125.540, mean reward: -1.744 [-100.000, 16.784], mean action: 0.181 [0.000, 3.000], mean observation: 0.009 [-1.806, 1.408], loss: 59.141987, mean_absolute_error: 15.676378, mean_q: -19.140198
  5358/100000: episode: 73, duration: 0.471s, episode steps: 95, steps per second: 202, episode reward: -38.315, mean reward: -0.403 [-100.000, 86.184], mean action: 0.600 [0.000, 3.000], mean observation: 0.041 [-2.335, 1.950], loss: 43.400616, mean_absolute_error: 16.211365, mean_q: -19.975088
  5420/100000: episode: 74, duration: 0.303s, episode steps: 62, steps per second: 205, episode reward: -122.021, mean reward: -1.968 [-100.000, 12.774], mean action: 0.226 [0.000, 3.000], mean observation: 0.011 [-1.690, 4.069], loss: 44.694355, mean_absolute_error: 16.832335, mean_q: -20.784050
  5492/100000: episode: 75, duration: 0.358s, episode steps: 72, steps per second: 201, episode reward: -116.468, mean reward: -1.618 [-100.000, 16.307], mean action: 0.361 [0.000, 3.000], mean observation: -0.016 [-1.825, 1.414], loss: 49.876057, mean_absolute_error: 17.493021, mean_q: -21.606104
  5558/100000: episode: 76, duration: 0.325s, episode steps: 66, steps per second: 203, episode reward: -128.471, mean reward: -1.947 [-100.000, 15.211], mean action: 0.258 [0.000, 3.000], mean observation: 0.048 [-1.678, 4.332], loss: 47.175125, mean_absolute_error: 18.007521, mean_q: -22.406309
  5646/100000: episode: 77, duration: 0.428s, episode steps: 88, steps per second: 206, episode reward: -97.968, mean reward: -1.113 [-100.000, 17.427], mean action: 0.216 [0.000, 3.000], mean observation: 0.068 [-1.887, 1.490], loss: 43.409184, mean_absolute_error: 18.438063, mean_q: -22.997759
  5701/100000: episode: 78, duration: 0.274s, episode steps: 55, steps per second: 201, episode reward: -98.871, mean reward: -1.798 [-100.000, 6.290], mean action: 0.818 [0.000, 3.000], mean observation: -0.116 [-6.503, 1.390], loss: 56.601173, mean_absolute_error: 19.089718, mean_q: -23.680304
  5767/100000: episode: 79, duration: 0.325s, episode steps: 66, steps per second: 203, episode reward: -125.633, mean reward: -1.904 [-100.000, 15.927], mean action: 0.394 [0.000, 3.000], mean observation: -0.004 [-1.832, 1.406], loss: 64.178162, mean_absolute_error: 19.761885, mean_q: -24.652466
  5857/100000: episode: 80, duration: 0.437s, episode steps: 90, steps per second: 206, episode reward: -134.165, mean reward: -1.491 [-100.000, 8.799], mean action: 0.178 [0.000, 3.000], mean observation: 0.093 [-6.145, 1.519], loss: 40.198792, mean_absolute_error: 20.304249, mean_q: -25.424805
  5944/100000: episode: 81, duration: 0.421s, episode steps: 87, steps per second: 207, episode reward: -114.233, mean reward: -1.313 [-100.000, 18.597], mean action: 0.448 [0.000, 3.000], mean observation: -0.049 [-1.849, 1.475], loss: 41.871670, mean_absolute_error: 20.999924, mean_q: -26.284210
  6020/100000: episode: 82, duration: 0.373s, episode steps: 76, steps per second: 204, episode reward: -115.626, mean reward: -1.521 [-100.000, 16.786], mean action: 0.197 [0.000, 3.000], mean observation: 0.023 [-1.838, 1.424], loss: 41.223804, mean_absolute_error: 21.623365, mean_q: -27.089197
  6109/100000: episode: 83, duration: 0.436s, episode steps: 89, steps per second: 204, episode reward: -108.336, mean reward: -1.217 [-100.000, 23.482], mean action: 0.494 [0.000, 3.000], mean observation: -0.051 [-6.294, 1.500], loss: 34.604340, mean_absolute_error: 22.251930, mean_q: -27.922205
  6191/100000: episode: 84, duration: 0.405s, episode steps: 82, steps per second: 202, episode reward: -165.398, mean reward: -2.017 [-100.000, 7.350], mean action: 0.049 [0.000, 2.000], mean observation: 0.096 [-1.769, 1.455], loss: 38.180153, mean_absolute_error: 23.055756, mean_q: -28.833628
  6279/100000: episode: 85, duration: 0.428s, episode steps: 88, steps per second: 206, episode reward: -115.463, mean reward: -1.312 [-100.000, 7.933], mean action: 0.170 [0.000, 3.000], mean observation: -0.005 [-6.500, 1.481], loss: 37.285862, mean_absolute_error: 23.635632, mean_q: -29.551115
  6349/100000: episode: 86, duration: 0.356s, episode steps: 70, steps per second: 196, episode reward: -132.065, mean reward: -1.887 [-100.000, 23.539], mean action: 0.157 [0.000, 3.000], mean observation: -0.024 [-2.450, 1.408], loss: 30.179213, mean_absolute_error: 24.101496, mean_q: -30.216148
  6428/100000: episode: 87, duration: 0.389s, episode steps: 79, steps per second: 203, episode reward: -156.129, mean reward: -1.976 [-100.000, 6.772], mean action: 0.658 [0.000, 3.000], mean observation: -0.108 [-1.853, 5.571], loss: 27.188635, mean_absolute_error: 24.437899, mean_q: -30.755270
  6495/100000: episode: 88, duration: 0.329s, episode steps: 67, steps per second: 204, episode reward: -114.228, mean reward: -1.705 [-100.000, 17.105], mean action: 0.209 [0.000, 3.000], mean observation: -0.004 [-1.797, 1.404], loss: 31.045647, mean_absolute_error: 25.179974, mean_q: -31.674484
  6552/100000: episode: 89, duration: 0.279s, episode steps: 57, steps per second: 205, episode reward: -133.132, mean reward: -2.336 [-100.000, 28.051], mean action: 0.158 [0.000, 3.000], mean observation: 0.020 [-1.910, 3.736], loss: 19.261345, mean_absolute_error: 25.308504, mean_q: -31.936813
  6615/100000: episode: 90, duration: 0.313s, episode steps: 63, steps per second: 201, episode reward: -131.049, mean reward: -2.080 [-100.000, 8.289], mean action: 0.349 [0.000, 3.000], mean observation: -0.039 [-6.317, 1.398], loss: 19.307365, mean_absolute_error: 25.800413, mean_q: -32.591026
  6706/100000: episode: 91, duration: 0.444s, episode steps: 91, steps per second: 205, episode reward: -134.518, mean reward: -1.478 [-100.000, 9.142], mean action: 0.308 [0.000, 3.000], mean observation: 0.015 [-6.035, 1.527], loss: 29.669558, mean_absolute_error: 26.068272, mean_q: -32.864098
  6764/100000: episode: 92, duration: 0.287s, episode steps: 58, steps per second: 202, episode reward: -105.123, mean reward: -1.812 [-100.000, 7.295], mean action: 0.586 [0.000, 3.000], mean observation: -0.105 [-1.848, 6.071], loss: 32.590389, mean_absolute_error: 26.749346, mean_q: -33.933353
  6853/100000: episode: 93, duration: 0.432s, episode steps: 89, steps per second: 206, episode reward: -123.710, mean reward: -1.390 [-100.000, 8.669], mean action: 0.371 [0.000, 3.000], mean observation: 0.027 [-1.876, 5.827], loss: 25.104454, mean_absolute_error: 27.197329, mean_q: -34.605007
  6909/100000: episode: 94, duration: 0.275s, episode steps: 56, steps per second: 204, episode reward: -99.427, mean reward: -1.775 [-100.000, 5.876], mean action: 0.536 [0.000, 3.000], mean observation: -0.074 [-1.852, 1.390], loss: 36.106163, mean_absolute_error: 27.597412, mean_q: -35.187859
  6992/100000: episode: 95, duration: 0.403s, episode steps: 83, steps per second: 206, episode reward: -51.118, mean reward: -0.616 [-100.000, 137.238], mean action: 0.048 [0.000, 1.000], mean observation: 0.083 [-2.117, 1.448], loss: 26.144781, mean_absolute_error: 27.881474, mean_q: -35.712627
  7086/100000: episode: 96, duration: 0.461s, episode steps: 94, steps per second: 204, episode reward: -109.999, mean reward: -1.170 [-100.000, 6.094], mean action: 0.468 [0.000, 3.000], mean observation: 0.081 [-1.842, 1.512], loss: 25.093742, mean_absolute_error: 28.510443, mean_q: -36.577881
  7154/100000: episode: 97, duration: 0.333s, episode steps: 68, steps per second: 204, episode reward: -116.378, mean reward: -1.711 [-100.000, 17.525], mean action: 0.603 [0.000, 3.000], mean observation: 0.017 [-1.795, 1.407], loss: 27.701681, mean_absolute_error: 29.011936, mean_q: -37.276375
  7218/100000: episode: 98, duration: 0.332s, episode steps: 64, steps per second: 193, episode reward: -130.767, mean reward: -2.043 [-100.000, 5.716], mean action: 0.719 [0.000, 3.000], mean observation: -0.092 [-1.782, 6.048], loss: 20.007183, mean_absolute_error: 29.506474, mean_q: -37.978031
  7276/100000: episode: 99, duration: 0.299s, episode steps: 58, steps per second: 194, episode reward: -115.799, mean reward: -1.997 [-100.000, 16.230], mean action: 0.603 [0.000, 3.000], mean observation: -0.088 [-1.775, 5.562], loss: 24.745884, mean_absolute_error: 29.887489, mean_q: -38.459812
  7366/100000: episode: 100, duration: 0.440s, episode steps: 90, steps per second: 205, episode reward: -143.341, mean reward: -1.593 [-100.000, 15.349], mean action: 0.278 [0.000, 3.000], mean observation: 0.124 [-1.659, 1.474], loss: 26.907568, mean_absolute_error: 30.530762, mean_q: -39.325115
  7451/100000: episode: 101, duration: 0.421s, episode steps: 85, steps per second: 202, episode reward: -118.529, mean reward: -1.394 [-100.000, 9.684], mean action: 0.588 [0.000, 3.000], mean observation: 0.016 [-5.796, 1.462], loss: 24.198753, mean_absolute_error: 30.956598, mean_q: -39.848408
  7534/100000: episode: 102, duration: 0.414s, episode steps: 83, steps per second: 200, episode reward: -118.849, mean reward: -1.432 [-100.000, 9.217], mean action: 0.675 [0.000, 3.000], mean observation: -0.051 [-6.535, 1.470], loss: 22.753559, mean_absolute_error: 31.570379, mean_q: -40.673058
  7615/100000: episode: 103, duration: 0.398s, episode steps: 81, steps per second: 204, episode reward: -145.164, mean reward: -1.792 [-100.000, 8.750], mean action: 0.222 [0.000, 3.000], mean observation: 0.019 [-1.780, 5.908], loss: 28.793280, mean_absolute_error: 32.255268, mean_q: -41.513264
  7678/100000: episode: 104, duration: 0.314s, episode steps: 63, steps per second: 200, episode reward: -114.413, mean reward: -1.816 [-100.000, 11.332], mean action: 0.698 [0.000, 3.000], mean observation: -0.051 [-1.778, 1.401], loss: 22.822416, mean_absolute_error: 32.570076, mean_q: -42.010887
  7731/100000: episode: 105, duration: 0.261s, episode steps: 53, steps per second: 203, episode reward: -95.561, mean reward: -1.803 [-100.000, 11.615], mean action: 0.604 [0.000, 3.000], mean observation: -0.101 [-1.851, 1.387], loss: 18.370083, mean_absolute_error: 32.793663, mean_q: -42.358265
  7785/100000: episode: 106, duration: 0.268s, episode steps: 54, steps per second: 201, episode reward: -80.134, mean reward: -1.484 [-100.000, 16.304], mean action: 0.574 [0.000, 3.000], mean observation: -0.051 [-1.827, 1.386], loss: 24.817741, mean_absolute_error: 33.444012, mean_q: -43.169266
  7867/100000: episode: 107, duration: 0.409s, episode steps: 82, steps per second: 201, episode reward: -133.175, mean reward: -1.624 [-100.000, 3.214], mean action: 0.744 [0.000, 3.000], mean observation: -0.055 [-2.976, 1.483], loss: 19.339682, mean_absolute_error: 33.611580, mean_q: -43.438351
  7961/100000: episode: 108, duration: 0.464s, episode steps: 94, steps per second: 203, episode reward: -113.089, mean reward: -1.203 [-100.000, 9.159], mean action: 0.681 [0.000, 3.000], mean observation: -0.009 [-1.738, 4.493], loss: 28.771608, mean_absolute_error: 34.528622, mean_q: -44.591770
  8018/100000: episode: 109, duration: 0.279s, episode steps: 57, steps per second: 204, episode reward: -126.648, mean reward: -2.222 [-100.000, 7.264], mean action: 0.158 [0.000, 3.000], mean observation: 0.020 [-1.751, 5.803], loss: 17.586695, mean_absolute_error: 34.932762, mean_q: -45.270500
  8070/100000: episode: 110, duration: 0.257s, episode steps: 52, steps per second: 202, episode reward: -110.282, mean reward: -2.121 [-100.000, 5.450], mean action: 0.654 [0.000, 3.000], mean observation: -0.120 [-1.905, 1.386], loss: 18.359240, mean_absolute_error: 35.546043, mean_q: -45.975079
  8146/100000: episode: 111, duration: 0.385s, episode steps: 76, steps per second: 197, episode reward: -107.807, mean reward: -1.419 [-100.000, 10.097], mean action: 0.526 [0.000, 3.000], mean observation: -0.039 [-5.461, 1.426], loss: 13.606285, mean_absolute_error: 35.916157, mean_q: -46.409683
  8235/100000: episode: 112, duration: 0.437s, episode steps: 89, steps per second: 204, episode reward: -117.513, mean reward: -1.320 [-100.000, 5.381], mean action: 0.404 [0.000, 3.000], mean observation: -0.017 [-1.803, 5.171], loss: 15.298425, mean_absolute_error: 36.453423, mean_q: -47.094048
  8317/100000: episode: 113, duration: 0.406s, episode steps: 82, steps per second: 202, episode reward: -108.981, mean reward: -1.329 [-100.000, 10.081], mean action: 0.549 [0.000, 3.000], mean observation: 0.010 [-1.786, 1.442], loss: 24.796783, mean_absolute_error: 36.876442, mean_q: -47.626953
  8379/100000: episode: 114, duration: 0.304s, episode steps: 62, steps per second: 204, episode reward: -118.533, mean reward: -1.912 [-100.000, 15.753], mean action: 0.371 [0.000, 3.000], mean observation: -0.022 [-1.844, 1.401], loss: 23.468367, mean_absolute_error: 37.174957, mean_q: -48.049690
  8433/100000: episode: 115, duration: 0.271s, episode steps: 54, steps per second: 199, episode reward: -129.202, mean reward: -2.393 [-100.000, 5.729], mean action: 1.074 [0.000, 3.000], mean observation: -0.155 [-1.748, 5.810], loss: 12.909849, mean_absolute_error: 37.615513, mean_q: -48.696434
  8528/100000: episode: 116, duration: 0.471s, episode steps: 95, steps per second: 202, episode reward: -119.362, mean reward: -1.256 [-100.000, 8.760], mean action: 0.937 [0.000, 3.000], mean observation: 0.146 [-6.076, 1.497], loss: 18.298168, mean_absolute_error: 37.922440, mean_q: -49.049683
  8620/100000: episode: 117, duration: 0.460s, episode steps: 92, steps per second: 200, episode reward: -170.508, mean reward: -1.853 [-100.000, 5.812], mean action: 0.728 [0.000, 3.000], mean observation: -0.067 [-1.858, 1.510], loss: 16.367878, mean_absolute_error: 38.256809, mean_q: -49.606171
  8677/100000: episode: 118, duration: 0.296s, episode steps: 57, steps per second: 192, episode reward: -129.739, mean reward: -2.276 [-100.000, 8.414], mean action: 0.877 [0.000, 3.000], mean observation: 0.129 [-1.969, 1.395], loss: 14.121495, mean_absolute_error: 38.557331, mean_q: -50.059608
  8743/100000: episode: 119, duration: 0.330s, episode steps: 66, steps per second: 200, episode reward: -129.114, mean reward: -1.956 [-100.000, 12.147], mean action: 0.758 [0.000, 3.000], mean observation: 0.009 [-1.738, 5.567], loss: 10.769598, mean_absolute_error: 38.850166, mean_q: -50.493454
  8814/100000: episode: 120, duration: 0.357s, episode steps: 71, steps per second: 199, episode reward: -148.066, mean reward: -2.085 [-100.000, 6.282], mean action: 0.930 [0.000, 3.000], mean observation: -0.087 [-1.674, 3.788], loss: 18.347851, mean_absolute_error: 39.255859, mean_q: -50.988159
  8866/100000: episode: 121, duration: 0.266s, episode steps: 52, steps per second: 196, episode reward: -75.991, mean reward: -1.461 [-100.000, 14.004], mean action: 1.365 [0.000, 3.000], mean observation: 0.029 [-1.742, 1.386], loss: 9.714737, mean_absolute_error: 39.445194, mean_q: -51.268757
  8930/100000: episode: 122, duration: 0.325s, episode steps: 64, steps per second: 197, episode reward: -151.120, mean reward: -2.361 [-100.000, 6.221], mean action: 1.141 [0.000, 3.000], mean observation: -0.067 [-1.802, 5.765], loss: 16.187941, mean_absolute_error: 39.643440, mean_q: -51.512642
  8997/100000: episode: 123, duration: 0.331s, episode steps: 67, steps per second: 203, episode reward: -142.677, mean reward: -2.130 [-100.000, 11.818], mean action: 0.672 [0.000, 3.000], mean observation: -0.066 [-1.772, 5.951], loss: 15.425253, mean_absolute_error: 40.259529, mean_q: -52.312302
  9051/100000: episode: 124, duration: 0.268s, episode steps: 54, steps per second: 202, episode reward: -113.373, mean reward: -2.099 [-100.000, 7.817], mean action: 0.296 [0.000, 3.000], mean observation: 0.020 [-6.441, 1.390], loss: 17.423088, mean_absolute_error: 40.257942, mean_q: -52.367580
  9138/100000: episode: 125, duration: 0.430s, episode steps: 87, steps per second: 202, episode reward: -150.769, mean reward: -1.733 [-100.000, 8.540], mean action: 0.632 [0.000, 3.000], mean observation: 0.154 [-3.387, 1.490], loss: 20.666655, mean_absolute_error: 40.501736, mean_q: -52.609028
  9204/100000: episode: 126, duration: 0.329s, episode steps: 66, steps per second: 201, episode reward: -156.363, mean reward: -2.369 [-100.000, 9.024], mean action: 0.682 [0.000, 3.000], mean observation: 0.060 [-5.993, 1.406], loss: 10.656000, mean_absolute_error: 40.816990, mean_q: -53.138142
  9263/100000: episode: 127, duration: 0.291s, episode steps: 59, steps per second: 203, episode reward: -107.261, mean reward: -1.818 [-100.000, 6.305], mean action: 0.576 [0.000, 3.000], mean observation: -0.089 [-1.779, 4.838], loss: 10.242796, mean_absolute_error: 41.012989, mean_q: -53.387207
  9343/100000: episode: 128, duration: 0.403s, episode steps: 80, steps per second: 199, episode reward: -136.277, mean reward: -1.703 [-100.000, 9.110], mean action: 0.912 [0.000, 3.000], mean observation: 0.136 [-5.403, 1.436], loss: 18.172823, mean_absolute_error: 41.293396, mean_q: -53.672325
  9420/100000: episode: 129, duration: 0.385s, episode steps: 77, steps per second: 200, episode reward: -101.297, mean reward: -1.316 [-100.000, 16.353], mean action: 0.870 [0.000, 3.000], mean observation: -0.010 [-1.691, 1.421], loss: 19.295557, mean_absolute_error: 41.437717, mean_q: -53.815361
  9499/100000: episode: 130, duration: 0.398s, episode steps: 79, steps per second: 198, episode reward: -106.985, mean reward: -1.354 [-100.000, 15.479], mean action: 1.165 [0.000, 3.000], mean observation: 0.029 [-1.718, 1.425], loss: 11.174640, mean_absolute_error: 41.666019, mean_q: -54.237225
  9557/100000: episode: 131, duration: 0.300s, episode steps: 58, steps per second: 193, episode reward: -146.642, mean reward: -2.528 [-100.000, 7.755], mean action: 1.586 [0.000, 3.000], mean observation: 0.089 [-3.246, 1.396], loss: 20.998802, mean_absolute_error: 42.133785, mean_q: -54.624161
  9649/100000: episode: 132, duration: 0.454s, episode steps: 92, steps per second: 202, episode reward: -126.146, mean reward: -1.371 [-100.000, 8.545], mean action: 0.826 [0.000, 3.000], mean observation: 0.055 [-1.882, 6.384], loss: 15.478545, mean_absolute_error: 42.133774, mean_q: -54.591557
  9702/100000: episode: 133, duration: 0.274s, episode steps: 53, steps per second: 194, episode reward: -126.605, mean reward: -2.389 [-100.000, 8.133], mean action: 1.340 [0.000, 3.000], mean observation: 0.041 [-6.342, 1.387], loss: 12.748558, mean_absolute_error: 42.251976, mean_q: -54.793163
  9792/100000: episode: 134, duration: 0.450s, episode steps: 90, steps per second: 200, episode reward: -174.216, mean reward: -1.936 [-100.000, 4.935], mean action: 1.378 [0.000, 3.000], mean observation: -0.101 [-1.869, 6.514], loss: 16.735674, mean_absolute_error: 42.546387, mean_q: -55.166470
  9855/100000: episode: 135, duration: 0.326s, episode steps: 63, steps per second: 193, episode reward: -116.094, mean reward: -1.843 [-100.000, 9.075], mean action: 1.810 [0.000, 3.000], mean observation: 0.052 [-1.719, 1.399], loss: 9.163628, mean_absolute_error: 42.565971, mean_q: -55.304737
  9908/100000: episode: 136, duration: 0.271s, episode steps: 53, steps per second: 196, episode reward: -137.753, mean reward: -2.599 [-100.000, 15.031], mean action: 0.811 [0.000, 3.000], mean observation: 0.125 [-1.796, 1.390], loss: 8.901179, mean_absolute_error: 42.834732, mean_q: -55.727997
  9961/100000: episode: 137, duration: 0.265s, episode steps: 53, steps per second: 200, episode reward: -89.875, mean reward: -1.696 [-100.000, 7.319], mean action: 0.453 [0.000, 3.000], mean observation: -0.066 [-1.804, 1.386], loss: 18.530224, mean_absolute_error: 43.406761, mean_q: -56.388176
 10032/100000: episode: 138, duration: 0.347s, episode steps: 71, steps per second: 204, episode reward: -121.229, mean reward: -1.707 [-100.000, 15.434], mean action: 0.465 [0.000, 3.000], mean observation: -0.091 [-1.738, 4.413], loss: 9.430498, mean_absolute_error: 43.256523, mean_q: -56.306843
 10110/100000: episode: 139, duration: 0.397s, episode steps: 78, steps per second: 197, episode reward: -89.682, mean reward: -1.150 [-100.000, 26.109], mean action: 0.962 [0.000, 3.000], mean observation: 0.139 [-2.165, 1.410], loss: 10.067439, mean_absolute_error: 43.320675, mean_q: -56.335930
 10183/100000: episode: 140, duration: 0.371s, episode steps: 73, steps per second: 197, episode reward: -136.580, mean reward: -1.871 [-100.000, 20.762], mean action: 0.849 [0.000, 3.000], mean observation: 0.151 [-1.707, 1.413], loss: 11.343923, mean_absolute_error: 43.525875, mean_q: -56.646389
 10256/100000: episode: 141, duration: 0.371s, episode steps: 73, steps per second: 197, episode reward: -149.652, mean reward: -2.050 [-100.000, 10.174], mean action: 1.370 [0.000, 3.000], mean observation: 0.083 [-6.060, 1.412], loss: 21.176886, mean_absolute_error: 43.995480, mean_q: -57.050247
 10322/100000: episode: 142, duration: 0.339s, episode steps: 66, steps per second: 195, episode reward: -162.953, mean reward: -2.469 [-100.000, 8.682], mean action: 1.667 [0.000, 3.000], mean observation: 0.120 [-5.862, 1.407], loss: 10.454019, mean_absolute_error: 43.931377, mean_q: -56.983013
 10401/100000: episode: 143, duration: 0.398s, episode steps: 79, steps per second: 198, episode reward: -134.475, mean reward: -1.702 [-100.000, 5.797], mean action: 1.418 [0.000, 3.000], mean observation: -0.011 [-1.786, 6.286], loss: 11.614863, mean_absolute_error: 44.189232, mean_q: -57.383869
 10462/100000: episode: 144, duration: 0.319s, episode steps: 61, steps per second: 191, episode reward: -126.071, mean reward: -2.067 [-100.000, 6.482], mean action: 1.951 [0.000, 3.000], mean observation: -0.061 [-1.824, 1.399], loss: 10.462427, mean_absolute_error: 44.388527, mean_q: -57.712814
 10520/100000: episode: 145, duration: 0.313s, episode steps: 58, steps per second: 185, episode reward: -126.984, mean reward: -2.189 [-100.000, 18.053], mean action: 1.914 [0.000, 3.000], mean observation: 0.096 [-1.789, 1.395], loss: 15.942976, mean_absolute_error: 44.371838, mean_q: -57.706497
 10612/100000: episode: 146, duration: 0.467s, episode steps: 92, steps per second: 197, episode reward: -86.324, mean reward: -0.938 [-100.000, 12.996], mean action: 1.391 [0.000, 3.000], mean observation: -0.017 [-1.617, 1.519], loss: 15.239416, mean_absolute_error: 44.417526, mean_q: -57.765526
 10675/100000: episode: 147, duration: 0.321s, episode steps: 63, steps per second: 196, episode reward: -116.443, mean reward: -1.848 [-100.000, 6.099], mean action: 1.667 [0.000, 3.000], mean observation: -0.049 [-1.776, 4.013], loss: 9.780944, mean_absolute_error: 44.299519, mean_q: -57.647038
 10758/100000: episode: 148, duration: 0.420s, episode steps: 83, steps per second: 198, episode reward: -131.498, mean reward: -1.584 [-100.000, 15.230], mean action: 1.422 [0.000, 3.000], mean observation: 0.109 [-5.762, 1.445], loss: 14.946885, mean_absolute_error: 44.553173, mean_q: -57.960419
 10879/100000: episode: 149, duration: 0.638s, episode steps: 121, steps per second: 190, episode reward: 23.023, mean reward: 0.190 [-100.000, 15.258], mean action: 1.678 [0.000, 3.000], mean observation: -0.095 [-0.863, 1.410], loss: 10.425450, mean_absolute_error: 44.847935, mean_q: -58.406239
 11546/100000: episode: 150, duration: 4.331s, episode steps: 667, steps per second: 154, episode reward: 176.257, mean reward: 0.264 [-16.933, 100.000], mean action: 1.132 [0.000, 3.000], mean observation: 0.086 [-0.893, 1.417], loss: 12.175551, mean_absolute_error: 45.416508, mean_q: -59.206860
 12239/100000: episode: 151, duration: 4.501s, episode steps: 693, steps per second: 154, episode reward: -242.904, mean reward: -0.351 [-100.000, 17.616], mean action: 1.486 [0.000, 3.000], mean observation: -0.050 [-1.000, 1.392], loss: 10.506127, mean_absolute_error: 45.425190, mean_q: -59.205570
 12792/100000: episode: 152, duration: 3.632s, episode steps: 553, steps per second: 152, episode reward: 110.725, mean reward: 0.200 [-16.932, 100.000], mean action: 1.405 [0.000, 3.000], mean observation: -0.024 [-0.827, 1.405], loss: 11.519811, mean_absolute_error: 44.619453, mean_q: -58.080425
 12957/100000: episode: 153, duration: 0.847s, episode steps: 165, steps per second: 195, episode reward: -71.721, mean reward: -0.435 [-100.000, 3.342], mean action: 1.267 [0.000, 3.000], mean observation: -0.056 [-1.000, 1.409], loss: 9.663682, mean_absolute_error: 44.436859, mean_q: -57.873543
 13095/100000: episode: 154, duration: 0.733s, episode steps: 138, steps per second: 188, episode reward: -253.203, mean reward: -1.835 [-100.000, 3.830], mean action: 1.696 [0.000, 3.000], mean observation: 0.044 [-1.629, 1.455], loss: 10.559399, mean_absolute_error: 44.344261, mean_q: -57.679634
 13255/100000: episode: 155, duration: 0.844s, episode steps: 160, steps per second: 189, episode reward: -169.679, mean reward: -1.060 [-100.000, 3.678], mean action: 1.681 [0.000, 3.000], mean observation: -0.023 [-1.001, 1.407], loss: 13.435455, mean_absolute_error: 44.326122, mean_q: -57.607079
 13362/100000: episode: 156, duration: 0.548s, episode steps: 107, steps per second: 195, episode reward: -256.824, mean reward: -2.400 [-100.000, 2.279], mean action: 1.411 [0.000, 3.000], mean observation: 0.053 [-1.318, 1.633], loss: 8.965079, mean_absolute_error: 44.156879, mean_q: -57.500423
 13453/100000: episode: 157, duration: 0.476s, episode steps: 91, steps per second: 191, episode reward: -277.559, mean reward: -3.050 [-100.000, 1.439], mean action: 1.890 [0.000, 3.000], mean observation: 0.039 [-1.520, 1.875], loss: 15.266274, mean_absolute_error: 44.296734, mean_q: -57.535965
 13568/100000: episode: 158, duration: 0.603s, episode steps: 115, steps per second: 191, episode reward: -340.959, mean reward: -2.965 [-100.000, 2.040], mean action: 1.661 [0.000, 3.000], mean observation: 0.096 [-1.581, 1.795], loss: 9.250190, mean_absolute_error: 44.117985, mean_q: -57.425343
 13646/100000: episode: 159, duration: 0.408s, episode steps: 78, steps per second: 191, episode reward: -35.989, mean reward: -0.461 [-100.000, 21.129], mean action: 1.949 [0.000, 3.000], mean observation: 0.106 [-3.714, 1.394], loss: 12.194407, mean_absolute_error: 44.092453, mean_q: -57.398487
 13785/100000: episode: 160, duration: 0.728s, episode steps: 139, steps per second: 191, episode reward: -212.951, mean reward: -1.532 [-100.000, 3.652], mean action: 1.604 [0.000, 3.000], mean observation: -0.019 [-1.220, 1.462], loss: 9.862917, mean_absolute_error: 44.070164, mean_q: -57.216187
 13877/100000: episode: 161, duration: 0.483s, episode steps: 92, steps per second: 190, episode reward: -364.503, mean reward: -3.962 [-100.000, 0.829], mean action: 1.935 [0.000, 3.000], mean observation: 0.138 [-1.491, 2.586], loss: 9.930414, mean_absolute_error: 43.959572, mean_q: -57.151722
 14017/100000: episode: 162, duration: 0.734s, episode steps: 140, steps per second: 191, episode reward: -247.768, mean reward: -1.770 [-100.000, 3.995], mean action: 1.564 [0.000, 3.000], mean observation: 0.051 [-1.237, 1.598], loss: 9.304592, mean_absolute_error: 43.869907, mean_q: -57.084618
 14181/100000: episode: 163, duration: 0.887s, episode steps: 164, steps per second: 185, episode reward: -155.382, mean reward: -0.947 [-100.000, 4.569], mean action: 1.829 [0.000, 3.000], mean observation: -0.067 [-1.316, 1.402], loss: 19.243181, mean_absolute_error: 43.705276, mean_q: -56.742493
 14269/100000: episode: 164, duration: 0.460s, episode steps: 88, steps per second: 191, episode reward: -302.718, mean reward: -3.440 [-100.000, 1.469], mean action: 1.659 [0.000, 3.000], mean observation: 0.148 [-1.347, 2.544], loss: 11.201852, mean_absolute_error: 43.647087, mean_q: -56.664528
 14568/100000: episode: 165, duration: 1.642s, episode steps: 299, steps per second: 182, episode reward: -154.893, mean reward: -0.518 [-100.000, 5.374], mean action: 1.595 [0.000, 3.000], mean observation: -0.046 [-1.017, 1.404], loss: 12.381260, mean_absolute_error: 43.412319, mean_q: -56.513050
 14940/100000: episode: 166, duration: 2.209s, episode steps: 372, steps per second: 168, episode reward: -136.496, mean reward: -0.367 [-100.000, 4.415], mean action: 1.634 [0.000, 3.000], mean observation: -0.047 [-1.002, 1.387], loss: 15.569643, mean_absolute_error: 43.135880, mean_q: -56.105080
 15059/100000: episode: 167, duration: 0.624s, episode steps: 119, steps per second: 191, episode reward: -236.144, mean reward: -1.984 [-100.000, 3.410], mean action: 1.857 [0.000, 3.000], mean observation: 0.097 [-1.081, 2.002], loss: 13.644409, mean_absolute_error: 42.710648, mean_q: -55.452126
 15217/100000: episode: 168, duration: 0.830s, episode steps: 158, steps per second: 190, episode reward: -176.777, mean reward: -1.119 [-100.000, 5.052], mean action: 1.538 [0.000, 3.000], mean observation: -0.057 [-1.341, 1.444], loss: 10.146832, mean_absolute_error: 42.617008, mean_q: -55.402702
 15333/100000: episode: 169, duration: 0.607s, episode steps: 116, steps per second: 191, episode reward: -120.511, mean reward: -1.039 [-100.000, 9.695], mean action: 1.836 [0.000, 3.000], mean observation: -0.032 [-1.382, 1.402], loss: 13.025053, mean_absolute_error: 42.841099, mean_q: -55.676384
 16201/100000: episode: 170, duration: 6.006s, episode steps: 868, steps per second: 145, episode reward: -239.040, mean reward: -0.275 [-100.000, 15.342], mean action: 1.566 [0.000, 3.000], mean observation: -0.062 [-0.949, 1.406], loss: 12.930632, mean_absolute_error: 41.796783, mean_q: -54.310062
 16265/100000: episode: 171, duration: 0.338s, episode steps: 64, steps per second: 189, episode reward: -47.252, mean reward: -0.738 [-100.000, 19.647], mean action: 1.766 [0.000, 3.000], mean observation: 0.099 [-3.263, 1.385], loss: 9.064602, mean_absolute_error: 41.380905, mean_q: -53.829929
 16384/100000: episode: 172, duration: 0.626s, episode steps: 119, steps per second: 190, episode reward: -326.196, mean reward: -2.741 [-100.000, 2.038], mean action: 1.361 [0.000, 3.000], mean observation: 0.048 [-1.313, 1.622], loss: 9.019434, mean_absolute_error: 41.285549, mean_q: -53.727203
 16503/100000: episode: 173, duration: 0.616s, episode steps: 119, steps per second: 193, episode reward: -317.299, mean reward: -2.666 [-100.000, 2.063], mean action: 1.303 [0.000, 3.000], mean observation: 0.154 [-1.251, 2.268], loss: 11.277167, mean_absolute_error: 41.173710, mean_q: -53.490879
 16894/100000: episode: 174, duration: 2.351s, episode steps: 391, steps per second: 166, episode reward: -162.770, mean reward: -0.416 [-100.000, 5.458], mean action: 1.540 [0.000, 3.000], mean observation: -0.025 [-1.204, 1.440], loss: 12.799208, mean_absolute_error: 41.239582, mean_q: -53.617805
 17238/100000: episode: 175, duration: 1.910s, episode steps: 344, steps per second: 180, episode reward: -318.858, mean reward: -0.927 [-100.000, 5.990], mean action: 1.741 [0.000, 3.000], mean observation: 0.017 [-1.323, 1.495], loss: 11.960275, mean_absolute_error: 40.794216, mean_q: -53.064522
 17324/100000: episode: 176, duration: 0.453s, episode steps: 86, steps per second: 190, episode reward: -18.924, mean reward: -0.220 [-100.000, 29.135], mean action: 1.895 [0.000, 3.000], mean observation: 0.083 [-2.727, 1.386], loss: 9.077558, mean_absolute_error: 41.174355, mean_q: -53.484291
 17434/100000: episode: 177, duration: 0.571s, episode steps: 110, steps per second: 193, episode reward: -184.425, mean reward: -1.677 [-100.000, 2.201], mean action: 1.609 [0.000, 3.000], mean observation: -0.014 [-1.089, 1.398], loss: 13.809996, mean_absolute_error: 40.880257, mean_q: -53.159000
 17748/100000: episode: 178, duration: 1.784s, episode steps: 314, steps per second: 176, episode reward: -162.700, mean reward: -0.518 [-100.000, 5.058], mean action: 1.484 [0.000, 3.000], mean observation: -0.024 [-1.000, 1.393], loss: 8.715073, mean_absolute_error: 40.826115, mean_q: -53.130600
 17853/100000: episode: 179, duration: 0.541s, episode steps: 105, steps per second: 194, episode reward: -174.941, mean reward: -1.666 [-100.000, 4.506], mean action: 1.295 [0.000, 3.000], mean observation: 0.028 [-1.043, 1.696], loss: 8.075257, mean_absolute_error: 40.895672, mean_q: -53.241856
 17967/100000: episode: 180, duration: 0.585s, episode steps: 114, steps per second: 195, episode reward: -255.938, mean reward: -2.245 [-100.000, 1.569], mean action: 1.237 [0.000, 3.000], mean observation: 0.106 [-1.151, 2.129], loss: 7.772230, mean_absolute_error: 41.043228, mean_q: -53.443542
 18967/100000: episode: 181, duration: 7.523s, episode steps: 1000, steps per second: 133, episode reward: -111.059, mean reward: -0.111 [-6.589, 5.677], mean action: 1.411 [0.000, 3.000], mean observation: -0.050 [-0.963, 1.398], loss: 10.280248, mean_absolute_error: 40.785339, mean_q: -53.085411
 19347/100000: episode: 182, duration: 2.221s, episode steps: 380, steps per second: 171, episode reward: 170.283, mean reward: 0.448 [-10.399, 100.000], mean action: 1.297 [0.000, 3.000], mean observation: 0.023 [-0.879, 1.396], loss: 11.054795, mean_absolute_error: 40.209831, mean_q: -52.309101
 19805/100000: episode: 183, duration: 2.599s, episode steps: 458, steps per second: 176, episode reward: -136.855, mean reward: -0.299 [-100.000, 4.506], mean action: 1.469 [0.000, 3.000], mean observation: -0.046 [-1.002, 1.525], loss: 11.899096, mean_absolute_error: 40.097229, mean_q: -52.183628
 20162/100000: episode: 184, duration: 2.015s, episode steps: 357, steps per second: 177, episode reward: -161.733, mean reward: -0.453 [-100.000, 5.188], mean action: 1.266 [0.000, 3.000], mean observation: -0.045 [-1.000, 1.403], loss: 9.222262, mean_absolute_error: 40.157768, mean_q: -52.296085
 20284/100000: episode: 185, duration: 0.651s, episode steps: 122, steps per second: 187, episode reward: -172.308, mean reward: -1.412 [-100.000, 61.915], mean action: 2.057 [0.000, 3.000], mean observation: 0.125 [-1.330, 1.668], loss: 11.994528, mean_absolute_error: 39.754417, mean_q: -51.728119
 20400/100000: episode: 186, duration: 0.614s, episode steps: 116, steps per second: 189, episode reward: -212.493, mean reward: -1.832 [-100.000, 1.344], mean action: 1.578 [0.000, 3.000], mean observation: 0.051 [-1.000, 1.723], loss: 13.612709, mean_absolute_error: 40.320133, mean_q: -52.434837
 20920/100000: episode: 187, duration: 3.094s, episode steps: 520, steps per second: 168, episode reward: -211.755, mean reward: -0.407 [-100.000, 4.724], mean action: 1.381 [0.000, 3.000], mean observation: -0.051 [-1.002, 1.425], loss: 10.980080, mean_absolute_error: 39.833626, mean_q: -51.814228
 21064/100000: episode: 188, duration: 0.779s, episode steps: 144, steps per second: 185, episode reward: -47.348, mean reward: -0.329 [-100.000, 36.145], mean action: 1.986 [0.000, 3.000], mean observation: 0.008 [-1.263, 1.415], loss: 6.423733, mean_absolute_error: 39.469242, mean_q: -51.416435
 21211/100000: episode: 189, duration: 0.768s, episode steps: 147, steps per second: 192, episode reward: -177.641, mean reward: -1.208 [-100.000, 4.600], mean action: 1.694 [0.000, 3.000], mean observation: -0.023 [-1.004, 1.424], loss: 18.219713, mean_absolute_error: 39.291870, mean_q: -51.077068
 22211/100000: episode: 190, duration: 6.563s, episode steps: 1000, steps per second: 152, episode reward: -167.528, mean reward: -0.168 [-5.564, 5.338], mean action: 1.531 [0.000, 3.000], mean observation: -0.039 [-0.996, 1.450], loss: 9.821365, mean_absolute_error: 38.518509, mean_q: -50.042030
 22887/100000: episode: 191, duration: 4.240s, episode steps: 676, steps per second: 159, episode reward: -238.198, mean reward: -0.352 [-100.000, 14.907], mean action: 1.673 [0.000, 3.000], mean observation: -0.002 [-1.002, 2.101], loss: 11.564005, mean_absolute_error: 37.572624, mean_q: -48.835903
 23043/100000: episode: 192, duration: 0.825s, episode steps: 156, steps per second: 189, episode reward: -411.651, mean reward: -2.639 [-100.000, 2.759], mean action: 1.494 [0.000, 3.000], mean observation: 0.181 [-1.091, 2.761], loss: 9.978833, mean_absolute_error: 37.290802, mean_q: -48.449387
 23246/100000: episode: 193, duration: 1.085s, episode steps: 203, steps per second: 187, episode reward: -140.855, mean reward: -0.694 [-100.000, 4.889], mean action: 1.360 [0.000, 3.000], mean observation: 0.066 [-1.001, 1.901], loss: 11.044949, mean_absolute_error: 37.470066, mean_q: -48.716618
 23462/100000: episode: 194, duration: 1.183s, episode steps: 216, steps per second: 183, episode reward: -87.437, mean reward: -0.405 [-100.000, 9.704], mean action: 1.606 [0.000, 3.000], mean observation: -0.034 [-1.110, 1.412], loss: 11.520973, mean_absolute_error: 37.486423, mean_q: -48.702682
 23993/100000: episode: 195, duration: 3.399s, episode steps: 531, steps per second: 156, episode reward: -213.517, mean reward: -0.402 [-100.000, 9.597], mean action: 1.505 [0.000, 3.000], mean observation: -0.054 [-0.981, 1.417], loss: 11.119852, mean_absolute_error: 36.804680, mean_q: -47.766659
 24993/100000: episode: 196, duration: 7.314s, episode steps: 1000, steps per second: 137, episode reward: -106.933, mean reward: -0.107 [-5.002, 4.374], mean action: 1.496 [0.000, 3.000], mean observation: -0.034 [-0.915, 1.411], loss: 11.259805, mean_absolute_error: 36.271580, mean_q: -47.075027
 25280/100000: episode: 197, duration: 1.621s, episode steps: 287, steps per second: 177, episode reward: -205.655, mean reward: -0.717 [-100.000, 4.370], mean action: 1.498 [0.000, 3.000], mean observation: 0.048 [-1.002, 1.411], loss: 9.367358, mean_absolute_error: 35.914593, mean_q: -46.629635
 25453/100000: episode: 198, duration: 0.930s, episode steps: 173, steps per second: 186, episode reward: -183.037, mean reward: -1.058 [-100.000, 5.538], mean action: 1.780 [0.000, 3.000], mean observation: 0.006 [-1.238, 1.409], loss: 10.585162, mean_absolute_error: 35.633823, mean_q: -46.197010
 25546/100000: episode: 199, duration: 0.496s, episode steps: 93, steps per second: 188, episode reward: -9.573, mean reward: -0.103 [-100.000, 24.997], mean action: 1.849 [0.000, 3.000], mean observation: 0.058 [-1.595, 1.392], loss: 17.647081, mean_absolute_error: 35.988674, mean_q: -46.648537
 25630/100000: episode: 200, duration: 0.445s, episode steps: 84, steps per second: 189, episode reward: -37.333, mean reward: -0.444 [-100.000, 18.190], mean action: 1.881 [0.000, 3.000], mean observation: 0.090 [-2.782, 1.392], loss: 8.675731, mean_absolute_error: 36.030251, mean_q: -46.743980
 26630/100000: episode: 201, duration: 6.701s, episode steps: 1000, steps per second: 149, episode reward: -98.278, mean reward: -0.098 [-5.208, 4.910], mean action: 1.415 [0.000, 3.000], mean observation: -0.043 [-0.875, 1.394], loss: 11.187312, mean_absolute_error: 35.501724, mean_q: -46.079056
 27630/100000: episode: 202, duration: 6.246s, episode steps: 1000, steps per second: 160, episode reward: -164.954, mean reward: -0.165 [-5.188, 5.145], mean action: 1.435 [0.000, 3.000], mean observation: -0.010 [-0.961, 1.398], loss: 9.835616, mean_absolute_error: 34.728119, mean_q: -45.039257
 27954/100000: episode: 203, duration: 1.781s, episode steps: 324, steps per second: 182, episode reward: -62.306, mean reward: -0.192 [-100.000, 13.416], mean action: 1.213 [0.000, 3.000], mean observation: 0.061 [-1.191, 1.932], loss: 8.922900, mean_absolute_error: 34.434185, mean_q: -44.674812
 28954/100000: episode: 204, duration: 6.769s, episode steps: 1000, steps per second: 148, episode reward: -196.097, mean reward: -0.196 [-5.661, 4.831], mean action: 1.497 [0.000, 3.000], mean observation: 0.053 [-0.826, 1.946], loss: 11.246696, mean_absolute_error: 34.296612, mean_q: -44.477970
 29228/100000: episode: 205, duration: 1.507s, episode steps: 274, steps per second: 182, episode reward: -143.725, mean reward: -0.525 [-100.000, 4.743], mean action: 1.496 [0.000, 3.000], mean observation: 0.020 [-1.001, 1.430], loss: 10.542090, mean_absolute_error: 34.073128, mean_q: -44.194736
 29769/100000: episode: 206, duration: 3.368s, episode steps: 541, steps per second: 161, episode reward: -219.199, mean reward: -0.405 [-100.000, 4.409], mean action: 1.536 [0.000, 3.000], mean observation: 0.040 [-1.000, 1.410], loss: 11.155368, mean_absolute_error: 33.835514, mean_q: -43.846771
 30769/100000: episode: 207, duration: 7.723s, episode steps: 1000, steps per second: 129, episode reward: -105.762, mean reward: -0.106 [-10.085, 13.116], mean action: 1.419 [0.000, 3.000], mean observation: -0.034 [-1.065, 1.388], loss: 9.946199, mean_absolute_error: 33.026524, mean_q: -42.790646
 31769/100000: episode: 208, duration: 6.543s, episode steps: 1000, steps per second: 153, episode reward: -75.264, mean reward: -0.075 [-4.894, 4.504], mean action: 1.362 [0.000, 3.000], mean observation: -0.016 [-0.983, 1.526], loss: 10.151671, mean_absolute_error: 32.175045, mean_q: -41.641228
 32416/100000: episode: 209, duration: 4.354s, episode steps: 647, steps per second: 149, episode reward: -190.845, mean reward: -0.295 [-100.000, 4.093], mean action: 1.590 [0.000, 3.000], mean observation: 0.037 [-1.000, 1.468], loss: 10.619569, mean_absolute_error: 31.458191, mean_q: -40.683388
 33416/100000: episode: 210, duration: 6.241s, episode steps: 1000, steps per second: 160, episode reward: -181.590, mean reward: -0.182 [-4.526, 4.842], mean action: 1.425 [0.000, 3.000], mean observation: 0.005 [-0.980, 1.422], loss: 8.491277, mean_absolute_error: 30.776348, mean_q: -39.781845
 34330/100000: episode: 211, duration: 5.720s, episode steps: 914, steps per second: 160, episode reward: -260.999, mean reward: -0.286 [-100.000, 4.099], mean action: 1.508 [0.000, 3.000], mean observation: 0.014 [-1.001, 1.387], loss: 9.216863, mean_absolute_error: 29.979824, mean_q: -38.680550
 35330/100000: episode: 212, duration: 6.282s, episode steps: 1000, steps per second: 159, episode reward: -84.302, mean reward: -0.084 [-4.640, 4.100], mean action: 1.399 [0.000, 3.000], mean observation: 0.001 [-0.964, 1.397], loss: 9.683659, mean_absolute_error: 29.074312, mean_q: -37.472050
 36330/100000: episode: 213, duration: 6.943s, episode steps: 1000, steps per second: 144, episode reward: -141.265, mean reward: -0.141 [-4.761, 4.235], mean action: 1.617 [0.000, 3.000], mean observation: 0.067 [-0.836, 1.425], loss: 8.575230, mean_absolute_error: 27.686485, mean_q: -35.652954
 37330/100000: episode: 214, duration: 7.129s, episode steps: 1000, steps per second: 140, episode reward: -134.500, mean reward: -0.134 [-4.130, 4.084], mean action: 1.640 [0.000, 3.000], mean observation: 0.062 [-0.999, 1.773], loss: 10.692883, mean_absolute_error: 26.840427, mean_q: -34.470932
 37851/100000: episode: 215, duration: 3.144s, episode steps: 521, steps per second: 166, episode reward: -140.732, mean reward: -0.270 [-100.000, 4.006], mean action: 1.388 [0.000, 3.000], mean observation: 0.049 [-1.001, 1.567], loss: 8.840762, mean_absolute_error: 26.038523, mean_q: -33.412857
 38851/100000: episode: 216, duration: 6.473s, episode steps: 1000, steps per second: 154, episode reward: -164.743, mean reward: -0.165 [-4.983, 4.796], mean action: 1.374 [0.000, 3.000], mean observation: 0.052 [-0.981, 1.498], loss: 10.089519, mean_absolute_error: 25.701668, mean_q: -32.935257
 39851/100000: episode: 217, duration: 6.972s, episode steps: 1000, steps per second: 143, episode reward: -161.596, mean reward: -0.162 [-5.695, 4.874], mean action: 1.530 [0.000, 3.000], mean observation: 0.021 [-1.088, 1.470], loss: 8.750873, mean_absolute_error: 24.570847, mean_q: -31.438589
 40851/100000: episode: 218, duration: 6.761s, episode steps: 1000, steps per second: 148, episode reward: -127.853, mean reward: -0.128 [-4.953, 4.403], mean action: 1.449 [0.000, 3.000], mean observation: 0.090 [-0.916, 1.770], loss: 8.639117, mean_absolute_error: 23.795687, mean_q: -30.377848
 41851/100000: episode: 219, duration: 6.290s, episode steps: 1000, steps per second: 159, episode reward: -187.997, mean reward: -0.188 [-4.976, 4.210], mean action: 1.390 [0.000, 3.000], mean observation: 0.068 [-0.908, 1.641], loss: 7.737190, mean_absolute_error: 23.192558, mean_q: -29.594696
 42851/100000: episode: 220, duration: 6.831s, episode steps: 1000, steps per second: 146, episode reward: -143.715, mean reward: -0.144 [-4.990, 4.378], mean action: 1.383 [0.000, 3.000], mean observation: 0.031 [-0.952, 1.484], loss: 8.151820, mean_absolute_error: 22.272570, mean_q: -28.367477
 43851/100000: episode: 221, duration: 6.246s, episode steps: 1000, steps per second: 160, episode reward: -154.132, mean reward: -0.154 [-4.732, 4.328], mean action: 1.410 [0.000, 3.000], mean observation: 0.055 [-0.892, 1.413], loss: 9.801093, mean_absolute_error: 21.286354, mean_q: -27.027067
 44070/100000: episode: 222, duration: 1.199s, episode steps: 219, steps per second: 183, episode reward: -105.425, mean reward: -0.481 [-100.000, 10.209], mean action: 1.753 [0.000, 3.000], mean observation: -0.007 [-1.565, 1.438], loss: 5.388813, mean_absolute_error: 20.606583, mean_q: -26.127296
 44206/100000: episode: 223, duration: 0.730s, episode steps: 136, steps per second: 186, episode reward: -107.760, mean reward: -0.792 [-100.000, 24.088], mean action: 1.963 [0.000, 3.000], mean observation: -0.038 [-1.345, 1.399], loss: 11.447156, mean_absolute_error: 20.480701, mean_q: -25.918795
 44456/100000: episode: 224, duration: 1.401s, episode steps: 250, steps per second: 178, episode reward: -12.025, mean reward: -0.048 [-100.000, 13.013], mean action: 1.684 [0.000, 3.000], mean observation: -0.009 [-1.546, 1.387], loss: 6.444604, mean_absolute_error: 20.049040, mean_q: -25.391653
 45456/100000: episode: 225, duration: 6.188s, episode steps: 1000, steps per second: 162, episode reward: -141.280, mean reward: -0.141 [-13.727, 16.957], mean action: 1.455 [0.000, 3.000], mean observation: 0.044 [-0.926, 1.654], loss: 8.709590, mean_absolute_error: 19.462120, mean_q: -24.592793
 46456/100000: episode: 226, duration: 6.550s, episode steps: 1000, steps per second: 153, episode reward: -130.848, mean reward: -0.131 [-6.457, 4.875], mean action: 1.445 [0.000, 3.000], mean observation: 0.049 [-0.810, 1.505], loss: 8.814354, mean_absolute_error: 18.642706, mean_q: -23.478601
 47076/100000: episode: 227, duration: 3.714s, episode steps: 620, steps per second: 167, episode reward: -46.196, mean reward: -0.075 [-100.000, 17.633], mean action: 1.555 [0.000, 3.000], mean observation: 0.042 [-1.174, 1.549], loss: 7.738500, mean_absolute_error: 17.990036, mean_q: -22.579498
 48052/100000: episode: 228, duration: 6.397s, episode steps: 976, steps per second: 153, episode reward: -215.789, mean reward: -0.221 [-100.000, 10.857], mean action: 1.443 [0.000, 3.000], mean observation: 0.039 [-1.025, 1.679], loss: 9.091146, mean_absolute_error: 17.162722, mean_q: -21.504152
 48762/100000: episode: 229, duration: 4.360s, episode steps: 710, steps per second: 163, episode reward: -137.502, mean reward: -0.194 [-100.000, 23.778], mean action: 1.575 [0.000, 3.000], mean observation: 0.024 [-0.954, 1.568], loss: 8.596550, mean_absolute_error: 16.457817, mean_q: -20.523996
 49499/100000: episode: 230, duration: 4.549s, episode steps: 737, steps per second: 162, episode reward: -188.948, mean reward: -0.256 [-100.000, 9.611], mean action: 1.627 [0.000, 3.000], mean observation: 0.012 [-1.723, 1.478], loss: 6.783752, mean_absolute_error: 15.888571, mean_q: -19.767410
 49718/100000: episode: 231, duration: 1.215s, episode steps: 219, steps per second: 180, episode reward: -96.435, mean reward: -0.440 [-100.000, 10.139], mean action: 1.822 [0.000, 3.000], mean observation: -0.040 [-1.330, 1.995], loss: 10.493308, mean_absolute_error: 15.446990, mean_q: -19.132017
 49823/100000: episode: 232, duration: 0.561s, episode steps: 105, steps per second: 187, episode reward: -44.474, mean reward: -0.424 [-100.000, 25.761], mean action: 1.981 [0.000, 3.000], mean observation: 0.087 [-1.917, 1.398], loss: 10.462918, mean_absolute_error: 15.236015, mean_q: -18.835400
 50048/100000: episode: 233, duration: 1.239s, episode steps: 225, steps per second: 182, episode reward: -246.717, mean reward: -1.097 [-100.000, 37.834], mean action: 1.751 [0.000, 3.000], mean observation: -0.065 [-2.030, 1.397], loss: 10.071241, mean_absolute_error: 14.776778, mean_q: -18.263910
 51048/100000: episode: 234, duration: 6.185s, episode steps: 1000, steps per second: 162, episode reward: -101.408, mean reward: -0.101 [-5.679, 4.363], mean action: 1.347 [0.000, 3.000], mean observation: 0.034 [-0.888, 1.498], loss: 7.979974, mean_absolute_error: 14.192753, mean_q: -17.481215
 51506/100000: episode: 235, duration: 2.659s, episode steps: 458, steps per second: 172, episode reward: -293.714, mean reward: -0.641 [-100.000, 54.785], mean action: 1.616 [0.000, 3.000], mean observation: 0.073 [-0.817, 2.009], loss: 6.817142, mean_absolute_error: 13.249881, mean_q: -16.257019
 52024/100000: episode: 236, duration: 3.002s, episode steps: 518, steps per second: 173, episode reward: -187.134, mean reward: -0.361 [-100.000, 21.614], mean action: 1.434 [0.000, 3.000], mean observation: 0.088 [-0.811, 1.632], loss: 6.191833, mean_absolute_error: 12.783189, mean_q: -15.629065
 52470/100000: episode: 237, duration: 2.600s, episode steps: 446, steps per second: 172, episode reward: -240.725, mean reward: -0.540 [-100.000, 62.472], mean action: 1.500 [0.000, 3.000], mean observation: 0.064 [-0.907, 2.339], loss: 8.745048, mean_absolute_error: 12.260538, mean_q: -14.881029
 52954/100000: episode: 238, duration: 2.978s, episode steps: 484, steps per second: 163, episode reward: -255.806, mean reward: -0.529 [-100.000, 61.725], mean action: 1.519 [0.000, 3.000], mean observation: 0.068 [-0.877, 2.256], loss: 7.101481, mean_absolute_error: 11.664323, mean_q: -14.122648
 53352/100000: episode: 239, duration: 2.260s, episode steps: 398, steps per second: 176, episode reward: -173.485, mean reward: -0.436 [-100.000, 7.656], mean action: 1.693 [0.000, 3.000], mean observation: 0.023 [-2.107, 1.404], loss: 6.601337, mean_absolute_error: 10.851545, mean_q: -13.094187
 53608/100000: episode: 240, duration: 1.442s, episode steps: 256, steps per second: 178, episode reward: -137.325, mean reward: -0.536 [-100.000, 6.168], mean action: 1.797 [0.000, 3.000], mean observation: 0.009 [-1.828, 1.389], loss: 7.455210, mean_absolute_error: 10.731093, mean_q: -12.905365
 53810/100000: episode: 241, duration: 1.157s, episode steps: 202, steps per second: 175, episode reward: -170.260, mean reward: -0.843 [-100.000, 29.296], mean action: 1.802 [0.000, 3.000], mean observation: -0.055 [-1.775, 1.390], loss: 4.775943, mean_absolute_error: 10.219947, mean_q: -12.255670
 54025/100000: episode: 242, duration: 1.178s, episode steps: 215, steps per second: 183, episode reward: -57.349, mean reward: -0.267 [-100.000, 21.573], mean action: 1.837 [0.000, 3.000], mean observation: -0.016 [-1.258, 1.451], loss: 9.513577, mean_absolute_error: 9.905169, mean_q: -11.800614
 54248/100000: episode: 243, duration: 1.249s, episode steps: 223, steps per second: 179, episode reward: -69.632, mean reward: -0.312 [-100.000, 10.943], mean action: 1.839 [0.000, 3.000], mean observation: 0.013 [-2.189, 1.407], loss: 6.703732, mean_absolute_error: 9.861044, mean_q: -11.751093
 55248/100000: episode: 244, duration: 6.977s, episode steps: 1000, steps per second: 143, episode reward: -28.498, mean reward: -0.028 [-20.937, 21.789], mean action: 1.332 [0.000, 3.000], mean observation: 0.056 [-1.034, 1.400], loss: 6.924356, mean_absolute_error: 9.152664, mean_q: -10.819000
 55486/100000: episode: 245, duration: 1.332s, episode steps: 238, steps per second: 179, episode reward: -158.536, mean reward: -0.666 [-100.000, 48.044], mean action: 1.832 [0.000, 3.000], mean observation: 0.059 [-0.859, 2.383], loss: 5.384006, mean_absolute_error: 8.614263, mean_q: -10.114700
 56041/100000: episode: 246, duration: 3.386s, episode steps: 555, steps per second: 164, episode reward: -149.378, mean reward: -0.269 [-100.000, 9.119], mean action: 1.571 [0.000, 3.000], mean observation: 0.036 [-0.957, 1.879], loss: 5.688192, mean_absolute_error: 8.362261, mean_q: -9.758005
 56515/100000: episode: 247, duration: 2.823s, episode steps: 474, steps per second: 168, episode reward: -143.783, mean reward: -0.303 [-100.000, 53.136], mean action: 1.819 [0.000, 3.000], mean observation: 0.035 [-1.002, 1.388], loss: 6.455259, mean_absolute_error: 7.859008, mean_q: -9.079310
 56816/100000: episode: 248, duration: 1.662s, episode steps: 301, steps per second: 181, episode reward: -99.872, mean reward: -0.332 [-100.000, 12.383], mean action: 1.774 [0.000, 3.000], mean observation: 0.089 [-3.395, 1.547], loss: 5.260925, mean_absolute_error: 7.405048, mean_q: -8.508949
 57332/100000: episode: 249, duration: 3.296s, episode steps: 516, steps per second: 157, episode reward: -65.041, mean reward: -0.126 [-100.000, 50.833], mean action: 1.607 [0.000, 3.000], mean observation: 0.074 [-1.798, 1.396], loss: 6.383955, mean_absolute_error: 7.206980, mean_q: -8.236646
 57977/100000: episode: 250, duration: 4.012s, episode steps: 645, steps per second: 161, episode reward: -190.134, mean reward: -0.295 [-100.000, 25.267], mean action: 1.609 [0.000, 3.000], mean observation: 0.087 [-3.598, 1.439], loss: 7.912577, mean_absolute_error: 6.842162, mean_q: -7.727340
 58279/100000: episode: 251, duration: 1.731s, episode steps: 302, steps per second: 174, episode reward: -12.775, mean reward: -0.042 [-100.000, 30.083], mean action: 1.877 [0.000, 3.000], mean observation: 0.094 [-1.694, 1.407], loss: 5.744425, mean_absolute_error: 6.296009, mean_q: -7.027950
 58781/100000: episode: 252, duration: 2.952s, episode steps: 502, steps per second: 170, episode reward: -142.081, mean reward: -0.283 [-100.000, 12.545], mean action: 1.691 [0.000, 3.000], mean observation: 0.103 [-3.743, 1.480], loss: 6.670281, mean_absolute_error: 6.145840, mean_q: -6.797040
 59234/100000: episode: 253, duration: 2.649s, episode steps: 453, steps per second: 171, episode reward: -221.397, mean reward: -0.489 [-100.000, 14.416], mean action: 1.541 [0.000, 3.000], mean observation: 0.063 [-2.093, 1.544], loss: 7.602507, mean_absolute_error: 5.688910, mean_q: -6.202501
 59694/100000: episode: 254, duration: 2.805s, episode steps: 460, steps per second: 164, episode reward: -68.060, mean reward: -0.148 [-100.000, 20.896], mean action: 1.750 [0.000, 3.000], mean observation: 0.079 [-2.138, 1.389], loss: 6.933789, mean_absolute_error: 5.431507, mean_q: -5.840031
 60112/100000: episode: 255, duration: 2.514s, episode steps: 418, steps per second: 166, episode reward: -197.660, mean reward: -0.473 [-100.000, 24.124], mean action: 1.773 [0.000, 3.000], mean observation: 0.046 [-1.879, 1.517], loss: 7.085709, mean_absolute_error: 5.081927, mean_q: -5.389617
 60776/100000: episode: 256, duration: 4.082s, episode steps: 664, steps per second: 163, episode reward: -120.185, mean reward: -0.181 [-100.000, 20.643], mean action: 1.682 [0.000, 3.000], mean observation: 0.092 [-1.729, 1.503], loss: 6.604423, mean_absolute_error: 5.001742, mean_q: -5.241364
 61185/100000: episode: 257, duration: 2.395s, episode steps: 409, steps per second: 171, episode reward: -145.056, mean reward: -0.355 [-100.000, 14.892], mean action: 1.633 [0.000, 3.000], mean observation: 0.100 [-2.651, 1.423], loss: 7.556918, mean_absolute_error: 4.767483, mean_q: -4.920656
 61669/100000: episode: 258, duration: 2.825s, episode steps: 484, steps per second: 171, episode reward: -166.860, mean reward: -0.345 [-100.000, 13.570], mean action: 1.620 [0.000, 3.000], mean observation: 0.101 [-0.991, 1.745], loss: 6.956589, mean_absolute_error: 4.353456, mean_q: -4.361258
 61940/100000: episode: 259, duration: 1.515s, episode steps: 271, steps per second: 179, episode reward: -99.257, mean reward: -0.366 [-100.000, 7.288], mean action: 1.889 [0.000, 3.000], mean observation: 0.045 [-1.589, 1.387], loss: 5.658518, mean_absolute_error: 4.243400, mean_q: -4.208046
 62424/100000: episode: 260, duration: 3.033s, episode steps: 484, steps per second: 160, episode reward: -124.898, mean reward: -0.258 [-100.000, 17.069], mean action: 1.548 [0.000, 3.000], mean observation: 0.113 [-1.387, 1.443], loss: 5.882452, mean_absolute_error: 4.175374, mean_q: -4.096445
 62876/100000: episode: 261, duration: 2.950s, episode steps: 452, steps per second: 153, episode reward: -126.326, mean reward: -0.279 [-100.000, 18.262], mean action: 1.657 [0.000, 3.000], mean observation: 0.054 [-1.287, 1.715], loss: 5.365093, mean_absolute_error: 3.828378, mean_q: -3.607857
 63876/100000: episode: 262, duration: 6.262s, episode steps: 1000, steps per second: 160, episode reward: -169.568, mean reward: -0.170 [-3.980, 4.461], mean action: 1.605 [0.000, 3.000], mean observation: 0.075 [-0.799, 1.407], loss: 6.573962, mean_absolute_error: 3.582982, mean_q: -3.227227
 64876/100000: episode: 263, duration: 6.827s, episode steps: 1000, steps per second: 146, episode reward: -135.921, mean reward: -0.136 [-4.465, 4.259], mean action: 1.922 [0.000, 3.000], mean observation: 0.056 [-0.784, 1.430], loss: 4.170111, mean_absolute_error: 3.217528, mean_q: -2.583670
 65876/100000: episode: 264, duration: 7.557s, episode steps: 1000, steps per second: 132, episode reward: -141.054, mean reward: -0.141 [-4.281, 4.820], mean action: 1.943 [0.000, 3.000], mean observation: 0.054 [-0.778, 1.460], loss: 6.182375, mean_absolute_error: 3.068948, mean_q: -2.028785
 66876/100000: episode: 265, duration: 7.048s, episode steps: 1000, steps per second: 142, episode reward: -107.022, mean reward: -0.107 [-3.864, 4.994], mean action: 1.929 [0.000, 3.000], mean observation: 0.060 [-0.864, 1.460], loss: 5.552900, mean_absolute_error: 2.936597, mean_q: -1.505602
 67876/100000: episode: 266, duration: 6.670s, episode steps: 1000, steps per second: 150, episode reward: -116.139, mean reward: -0.116 [-3.978, 4.571], mean action: 1.940 [0.000, 3.000], mean observation: 0.048 [-0.795, 1.409], loss: 3.814582, mean_absolute_error: 3.033975, mean_q: -1.224806
 68876/100000: episode: 267, duration: 7.410s, episode steps: 1000, steps per second: 135, episode reward: -131.782, mean reward: -0.132 [-4.404, 3.984], mean action: 1.813 [0.000, 3.000], mean observation: 0.039 [-0.784, 1.410], loss: 3.996461, mean_absolute_error: 3.034428, mean_q: -0.733509
 69876/100000: episode: 268, duration: 6.608s, episode steps: 1000, steps per second: 151, episode reward: -105.892, mean reward: -0.106 [-3.953, 3.965], mean action: 1.746 [0.000, 3.000], mean observation: 0.031 [-0.770, 1.400], loss: 3.556919, mean_absolute_error: 3.136576, mean_q: -0.325696
 70790/100000: episode: 269, duration: 6.265s, episode steps: 914, steps per second: 146, episode reward: -202.963, mean reward: -0.222 [-100.000, 10.086], mean action: 1.658 [0.000, 3.000], mean observation: 0.035 [-0.943, 1.406], loss: 4.187068, mean_absolute_error: 3.207683, mean_q: 0.260526
 71790/100000: episode: 270, duration: 7.819s, episode steps: 1000, steps per second: 128, episode reward: -68.421, mean reward: -0.068 [-4.417, 5.290], mean action: 1.562 [0.000, 3.000], mean observation: 0.026 [-0.808, 1.431], loss: 4.081155, mean_absolute_error: 3.393079, mean_q: 0.700859
 72640/100000: episode: 271, duration: 5.514s, episode steps: 850, steps per second: 154, episode reward: -137.850, mean reward: -0.162 [-100.000, 20.055], mean action: 1.604 [0.000, 3.000], mean observation: 0.045 [-1.167, 1.424], loss: 3.228039, mean_absolute_error: 3.561401, mean_q: 0.920952
 73618/100000: episode: 272, duration: 6.028s, episode steps: 978, steps per second: 162, episode reward: -164.766, mean reward: -0.168 [-100.000, 7.131], mean action: 1.563 [0.000, 3.000], mean observation: 0.029 [-0.820, 1.512], loss: 2.966084, mean_absolute_error: 3.868258, mean_q: 1.307235
 74206/100000: episode: 273, duration: 3.928s, episode steps: 588, steps per second: 150, episode reward: -61.792, mean reward: -0.105 [-100.000, 21.003], mean action: 1.570 [0.000, 3.000], mean observation: 0.036 [-0.979, 1.391], loss: 3.656938, mean_absolute_error: 4.179044, mean_q: 1.644585
 75167/100000: episode: 274, duration: 6.625s, episode steps: 961, steps per second: 145, episode reward: -184.191, mean reward: -0.192 [-100.000, 21.695], mean action: 1.473 [0.000, 3.000], mean observation: 0.047 [-0.953, 1.513], loss: 3.104531, mean_absolute_error: 4.381955, mean_q: 2.085999
 76167/100000: episode: 275, duration: 9.078s, episode steps: 1000, steps per second: 110, episode reward: -27.668, mean reward: -0.028 [-21.322, 10.171], mean action: 1.558 [0.000, 3.000], mean observation: 0.040 [-0.806, 1.401], loss: 3.839504, mean_absolute_error: 4.958872, mean_q: 2.466002
 77167/100000: episode: 276, duration: 6.747s, episode steps: 1000, steps per second: 148, episode reward: -24.646, mean reward: -0.025 [-3.983, 14.606], mean action: 1.397 [0.000, 3.000], mean observation: 0.031 [-0.723, 1.407], loss: 3.100273, mean_absolute_error: 5.337465, mean_q: 2.988278
 78076/100000: episode: 277, duration: 6.150s, episode steps: 909, steps per second: 148, episode reward: -96.877, mean reward: -0.107 [-100.000, 16.110], mean action: 1.479 [0.000, 3.000], mean observation: 0.035 [-0.694, 1.472], loss: 3.347150, mean_absolute_error: 5.780472, mean_q: 3.457445
 79076/100000: episode: 278, duration: 8.334s, episode steps: 1000, steps per second: 120, episode reward: -29.346, mean reward: -0.029 [-12.014, 17.800], mean action: 1.399 [0.000, 3.000], mean observation: 0.033 [-0.679, 1.408], loss: 3.317316, mean_absolute_error: 6.234310, mean_q: 4.023299
 80076/100000: episode: 279, duration: 6.566s, episode steps: 1000, steps per second: 152, episode reward: -20.919, mean reward: -0.021 [-21.364, 12.685], mean action: 1.485 [0.000, 3.000], mean observation: 0.054 [-0.678, 1.392], loss: 2.960386, mean_absolute_error: 6.747249, mean_q: 4.551676
 81076/100000: episode: 280, duration: 6.786s, episode steps: 1000, steps per second: 147, episode reward: -30.908, mean reward: -0.031 [-22.171, 12.442], mean action: 1.813 [0.000, 3.000], mean observation: 0.031 [-0.736, 1.391], loss: 3.223984, mean_absolute_error: 7.413114, mean_q: 5.085600
 82076/100000: episode: 281, duration: 7.176s, episode steps: 1000, steps per second: 139, episode reward: -83.434, mean reward: -0.083 [-3.132, 4.667], mean action: 1.525 [0.000, 3.000], mean observation: 0.030 [-0.685, 1.448], loss: 3.470903, mean_absolute_error: 8.055977, mean_q: 5.512197
 82971/100000: episode: 282, duration: 5.898s, episode steps: 895, steps per second: 152, episode reward: -157.168, mean reward: -0.176 [-100.000, 12.223], mean action: 1.506 [0.000, 3.000], mean observation: 0.042 [-0.668, 1.442], loss: 3.154774, mean_absolute_error: 8.435651, mean_q: 6.383894
 83971/100000: episode: 283, duration: 6.290s, episode steps: 1000, steps per second: 159, episode reward: -64.783, mean reward: -0.065 [-3.424, 4.202], mean action: 1.414 [0.000, 3.000], mean observation: 0.051 [-0.730, 1.456], loss: 3.583617, mean_absolute_error: 9.000367, mean_q: 6.921027
 84971/100000: episode: 284, duration: 7.028s, episode steps: 1000, steps per second: 142, episode reward: -80.813, mean reward: -0.081 [-3.088, 4.046], mean action: 1.478 [0.000, 3.000], mean observation: 0.054 [-0.652, 1.422], loss: 2.614486, mean_absolute_error: 9.436604, mean_q: 7.578523
 85839/100000: episode: 285, duration: 6.813s, episode steps: 868, steps per second: 127, episode reward: -104.284, mean reward: -0.120 [-100.000, 18.806], mean action: 1.470 [0.000, 3.000], mean observation: 0.043 [-0.918, 1.389], loss: 3.235194, mean_absolute_error: 9.918778, mean_q: 8.282813
 86768/100000: episode: 286, duration: 6.651s, episode steps: 929, steps per second: 140, episode reward: 145.379, mean reward: 0.156 [-15.385, 100.000], mean action: 1.280 [0.000, 3.000], mean observation: 0.054 [-1.077, 1.396], loss: 3.026679, mean_absolute_error: 10.210095, mean_q: 8.734180
 87768/100000: episode: 287, duration: 6.351s, episode steps: 1000, steps per second: 157, episode reward: -59.886, mean reward: -0.060 [-3.152, 4.600], mean action: 1.408 [0.000, 3.000], mean observation: 0.042 [-0.596, 1.389], loss: 3.012828, mean_absolute_error: 10.701153, mean_q: 9.256773
 88768/100000: episode: 288, duration: 7.093s, episode steps: 1000, steps per second: 141, episode reward: -55.016, mean reward: -0.055 [-3.225, 4.351], mean action: 1.491 [0.000, 3.000], mean observation: 0.024 [-0.611, 1.393], loss: 3.516977, mean_absolute_error: 11.201547, mean_q: 9.877963
 89768/100000: episode: 289, duration: 6.465s, episode steps: 1000, steps per second: 155, episode reward: -98.875, mean reward: -0.099 [-3.189, 3.984], mean action: 1.576 [0.000, 3.000], mean observation: 0.052 [-0.593, 1.411], loss: 2.991341, mean_absolute_error: 11.635068, mean_q: 10.554809
 90768/100000: episode: 290, duration: 6.707s, episode steps: 1000, steps per second: 149, episode reward: -56.888, mean reward: -0.057 [-3.463, 4.132], mean action: 1.493 [0.000, 3.000], mean observation: 0.061 [-0.626, 1.466], loss: 4.169186, mean_absolute_error: 11.991244, mean_q: 10.947541
 91768/100000: episode: 291, duration: 6.782s, episode steps: 1000, steps per second: 147, episode reward: -59.327, mean reward: -0.059 [-3.372, 4.782], mean action: 1.449 [0.000, 3.000], mean observation: 0.058 [-0.560, 1.413], loss: 2.832477, mean_absolute_error: 12.178699, mean_q: 11.490332
 92768/100000: episode: 292, duration: 7.944s, episode steps: 1000, steps per second: 126, episode reward: -25.126, mean reward: -0.025 [-3.378, 5.108], mean action: 1.552 [0.000, 3.000], mean observation: 0.030 [-0.727, 1.403], loss: 4.097635, mean_absolute_error: 12.371793, mean_q: 11.758039
 93768/100000: episode: 293, duration: 7.280s, episode steps: 1000, steps per second: 137, episode reward: -71.886, mean reward: -0.072 [-3.282, 4.250], mean action: 1.473 [0.000, 3.000], mean observation: 0.051 [-0.468, 1.398], loss: 3.402008, mean_absolute_error: 12.621737, mean_q: 12.278957
 94768/100000: episode: 294, duration: 6.543s, episode steps: 1000, steps per second: 153, episode reward: -70.714, mean reward: -0.071 [-3.366, 4.028], mean action: 1.391 [0.000, 3.000], mean observation: 0.046 [-0.526, 1.392], loss: 3.178296, mean_absolute_error: 12.967559, mean_q: 12.710982
 95768/100000: episode: 295, duration: 6.299s, episode steps: 1000, steps per second: 159, episode reward: -56.335, mean reward: -0.056 [-3.240, 4.787], mean action: 1.503 [0.000, 3.000], mean observation: 0.052 [-0.645, 1.411], loss: 2.650882, mean_absolute_error: 13.241008, mean_q: 13.345623
 96768/100000: episode: 296, duration: 6.750s, episode steps: 1000, steps per second: 148, episode reward: -111.074, mean reward: -0.111 [-3.192, 4.313], mean action: 1.451 [0.000, 3.000], mean observation: 0.067 [-0.518, 1.415], loss: 3.761442, mean_absolute_error: 13.446119, mean_q: 13.657205
 97768/100000: episode: 297, duration: 6.293s, episode steps: 1000, steps per second: 159, episode reward: -51.864, mean reward: -0.052 [-3.176, 4.826], mean action: 1.481 [0.000, 3.000], mean observation: 0.062 [-0.793, 1.465], loss: 2.775283, mean_absolute_error: 13.795844, mean_q: 14.337549
 98768/100000: episode: 298, duration: 7.209s, episode steps: 1000, steps per second: 139, episode reward: -103.069, mean reward: -0.103 [-3.441, 4.856], mean action: 1.567 [0.000, 3.000], mean observation: 0.063 [-0.569, 1.421], loss: 3.007279, mean_absolute_error: 13.991766, mean_q: 14.683012
 99768/100000: episode: 299, duration: 6.261s, episode steps: 1000, steps per second: 160, episode reward: -17.392, mean reward: -0.017 [-4.302, 5.876], mean action: 1.570 [0.000, 3.000], mean observation: 0.016 [-0.674, 1.390], loss: 2.424679, mean_absolute_error: 14.282459, mean_q: 15.127911
done, took 639.889 seconds
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-Result">Evaluation Result<a class="anchor-link" href="#Evaluation-Result">&#182;</a></h2><p>We are testing the above model for 50 episodes and then looking at the mean reward value</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">dqn</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;episode_reward&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Test rewards (#episodes=</span><span class="si">{}</span><span class="s2">): mean=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, std=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, &quot;</span>
           <span class="s2">&quot;min=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, max=</span><span class="si">{:&gt;5.2f}</span><span class="s2">&quot;</span><span class="p">)</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>

<span class="n">rl_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Testing for 50 episodes ...
Episode 1: reward: -56.594, steps: 1000
Episode 2: reward: -78.799, steps: 1000
Episode 3: reward: -74.998, steps: 1000
Episode 4: reward: -54.537, steps: 1000
Episode 5: reward: -45.532, steps: 1000
Episode 6: reward: -87.722, steps: 1000
Episode 7: reward: -90.790, steps: 1000
Episode 8: reward: -88.762, steps: 1000
Episode 9: reward: -99.000, steps: 1000
Episode 10: reward: -73.811, steps: 1000
Episode 11: reward: -83.323, steps: 1000
Episode 12: reward: -48.407, steps: 1000
Episode 13: reward: -120.300, steps: 1000
Episode 14: reward: -95.077, steps: 1000
Episode 15: reward: -100.937, steps: 1000
Episode 16: reward: -81.949, steps: 1000
Episode 17: reward: -48.239, steps: 1000
Episode 18: reward: -68.205, steps: 1000
Episode 19: reward: -113.001, steps: 1000
Episode 20: reward: -117.280, steps: 1000
Episode 21: reward: -83.048, steps: 1000
Episode 22: reward: -73.715, steps: 1000
Episode 23: reward: -102.671, steps: 1000
Episode 24: reward: -49.877, steps: 1000
Episode 25: reward: -46.662, steps: 1000
Episode 26: reward: -100.828, steps: 1000
Episode 27: reward: -92.790, steps: 1000
Episode 28: reward: -86.524, steps: 1000
Episode 29: reward: -60.188, steps: 1000
Episode 30: reward: -95.293, steps: 1000
Episode 31: reward: -56.382, steps: 1000
Episode 32: reward: -100.515, steps: 1000
Episode 33: reward: -80.070, steps: 1000
Episode 34: reward: -107.879, steps: 1000
Episode 35: reward: -99.395, steps: 1000
Episode 36: reward: -86.628, steps: 1000
Episode 37: reward: -50.810, steps: 1000
Episode 38: reward: -46.052, steps: 1000
Episode 39: reward: -58.206, steps: 1000
Episode 40: reward: -71.273, steps: 1000
Episode 41: reward: -64.282, steps: 1000
Episode 42: reward: -38.071, steps: 1000
Episode 43: reward: -70.101, steps: 1000
Episode 44: reward: -109.013, steps: 1000
Episode 45: reward: -41.367, steps: 1000
Episode 46: reward: -63.162, steps: 1000
Episode 47: reward: -23.644, steps: 1000
Episode 48: reward: -83.072, steps: 1000
Episode 49: reward: -107.471, steps: 1000
Episode 50: reward: -26.649, steps: 1000
Test rewards (#episodes=50): mean=-76.06, std=24.21, min=-120.30, max=-23.64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-2">Model 2<a class="anchor-link" href="#Model-2">&#182;</a></h2><p><b> Model Architecture</b></p>
<p>We are using the similar architecture and process as <a href="#task2_model1">Model 1</a> but with different hyper-parameters <br/> 
<b>In this Model, we are changing value of epsilon to 0.2 and learning rate of Adam optimizer is 0.0001 </b></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get the environment and extract the number of actions.</span>
<span class="c1">#env = gym.make(ENV_NAME)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">nb_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Next, we build a very simple model.</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">))</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="c1"># Finally, we configure and compile our agent. You can use every built-in Keras optimizer and</span>
<span class="c1"># even the metrics!</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">SequentialMemory</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">window_length</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">EpsGreedyQPolicy</span><span class="p">(</span><span class="n">eps</span><span class="o">=.</span><span class="mi">2</span><span class="p">)</span>
<span class="n">dqn2</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model2</span><span class="p">,</span> <span class="n">nb_actions</span><span class="o">=</span><span class="n">nb_actions</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="n">nb_steps_warmup</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
               <span class="n">target_model_update</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">)</span>
<span class="n">dqn2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mae&#39;</span><span class="p">])</span>

<span class="c1"># Okay, now it&#39;s time to learn something! We visualize the training here for show, but this</span>
<span class="c1"># slows down training quite a lot. You can always safely abort the training prematurely using</span>
<span class="c1"># Ctrl + C.</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">dqn2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_steps</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">timetaken</span><span class="o">=</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
<span class="n">rl_model_time_comparisons</span><span class="p">[</span><span class="s1">&#39;Model 2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">timetaken</span>

<span class="c1"># After training is done, we save the final weights.</span>
<span class="n">dqn2</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;dqn_</span><span class="si">{}</span><span class="s1">_weights_model2.h5f&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ENV_NAME</span><span class="p">),</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_2 (Flatten)          (None, 8)                 0         
_________________________________________________________________
dense_5 (Dense)              (None, 16)                144       
_________________________________________________________________
activation_5 (Activation)    (None, 16)                0         
_________________________________________________________________
dense_6 (Dense)              (None, 16)                272       
_________________________________________________________________
activation_6 (Activation)    (None, 16)                0         
_________________________________________________________________
dense_7 (Dense)              (None, 16)                272       
_________________________________________________________________
activation_7 (Activation)    (None, 16)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 4)                 68        
_________________________________________________________________
activation_8 (Activation)    (None, 4)                 0         
=================================================================
Total params: 756
Trainable params: 756
Non-trainable params: 0
_________________________________________________________________
None
Training for 100000 steps ...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/anaconda3/lib/python3.6/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!
  warnings.warn(&#39;Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!&#39;)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>    85/100000: episode: 1, duration: 1.970s, episode steps: 85, steps per second: 43, episode reward: -496.174, mean reward: -5.837 [-100.000, 2.760], mean action: 1.506 [0.000, 3.000], mean observation: 0.135 [-1.644, 5.922], loss: 7.509359, mean_absolute_error: 0.862144, mean_q: 0.176180
   152/100000: episode: 2, duration: 0.401s, episode steps: 67, steps per second: 167, episode reward: -514.546, mean reward: -7.680 [-100.000, -0.298], mean action: 1.209 [0.000, 3.000], mean observation: 0.101 [-1.850, 6.149], loss: 45.625061, mean_absolute_error: 1.391521, mean_q: 0.161303
   210/100000: episode: 3, duration: 0.316s, episode steps: 58, steps per second: 183, episode reward: -95.427, mean reward: -1.645 [-100.000, 26.276], mean action: 1.431 [0.000, 3.000], mean observation: 0.036 [-1.762, 1.393], loss: 72.702736, mean_absolute_error: 1.508517, mean_q: 0.076881
   271/100000: episode: 4, duration: 0.356s, episode steps: 61, steps per second: 171, episode reward: -264.963, mean reward: -4.344 [-100.000, 4.121], mean action: 0.672 [0.000, 3.000], mean observation: 0.014 [-1.846, 3.753], loss: 83.380020, mean_absolute_error: 1.470589, mean_q: 0.064531
   342/100000: episode: 5, duration: 0.416s, episode steps: 71, steps per second: 171, episode reward: -292.977, mean reward: -4.126 [-100.000, 20.943], mean action: 1.648 [0.000, 3.000], mean observation: -0.081 [-5.173, 1.409], loss: 79.542625, mean_absolute_error: 1.385773, mean_q: 0.054901
   440/100000: episode: 6, duration: 0.552s, episode steps: 98, steps per second: 178, episode reward: -580.088, mean reward: -5.919 [-100.000, 0.644], mean action: 2.184 [0.000, 3.000], mean observation: -0.101 [-3.453, 1.526], loss: 90.135201, mean_absolute_error: 1.463748, mean_q: 0.037924
   496/100000: episode: 7, duration: 0.327s, episode steps: 56, steps per second: 171, episode reward: -288.936, mean reward: -5.160 [-100.000, 20.484], mean action: 2.304 [0.000, 3.000], mean observation: -0.169 [-6.029, 1.390], loss: 75.681358, mean_absolute_error: 1.474375, mean_q: 0.011120
   577/100000: episode: 8, duration: 0.481s, episode steps: 81, steps per second: 169, episode reward: -306.491, mean reward: -3.784 [-100.000, 1.896], mean action: 1.309 [0.000, 3.000], mean observation: -0.010 [-4.804, 1.424], loss: 78.351288, mean_absolute_error: 1.452004, mean_q: -0.009587
   644/100000: episode: 9, duration: 0.403s, episode steps: 67, steps per second: 166, episode reward: -204.308, mean reward: -3.049 [-100.000, 90.955], mean action: 1.627 [0.000, 3.000], mean observation: -0.064 [-4.454, 1.404], loss: 93.092720, mean_absolute_error: 1.497708, mean_q: -0.026951
   703/100000: episode: 10, duration: 0.347s, episode steps: 59, steps per second: 170, episode reward: -100.794, mean reward: -1.708 [-100.000, 17.801], mean action: 0.864 [0.000, 3.000], mean observation: -0.111 [-1.813, 1.390], loss: 69.098076, mean_absolute_error: 1.389987, mean_q: -0.038331
   754/100000: episode: 11, duration: 0.307s, episode steps: 51, steps per second: 166, episode reward: -87.378, mean reward: -1.713 [-100.000, 34.420], mean action: 0.922 [0.000, 3.000], mean observation: -0.094 [-2.786, 1.386], loss: 82.151588, mean_absolute_error: 1.392031, mean_q: -0.047856
   825/100000: episode: 12, duration: 0.432s, episode steps: 71, steps per second: 164, episode reward: -164.034, mean reward: -2.310 [-100.000, 5.134], mean action: 1.310 [0.000, 3.000], mean observation: -0.042 [-1.681, 6.717], loss: 77.757454, mean_absolute_error: 1.362811, mean_q: -0.055325
   940/100000: episode: 13, duration: 0.630s, episode steps: 115, steps per second: 183, episode reward: -46.032, mean reward: -0.400 [-100.000, 83.949], mean action: 1.104 [0.000, 3.000], mean observation: 0.094 [-2.382, 1.838], loss: 83.955154, mean_absolute_error: 1.382376, mean_q: -0.071349
  1030/100000: episode: 14, duration: 0.471s, episode steps: 90, steps per second: 191, episode reward: -216.676, mean reward: -2.408 [-100.000, 27.043], mean action: 1.011 [0.000, 3.000], mean observation: 0.077 [-1.817, 1.484], loss: 94.011559, mean_absolute_error: 1.463567, mean_q: -0.089605
  1119/100000: episode: 15, duration: 0.454s, episode steps: 89, steps per second: 196, episode reward: -220.591, mean reward: -2.479 [-100.000, 6.459], mean action: 0.315 [0.000, 3.000], mean observation: -0.046 [-4.940, 1.472], loss: 88.808571, mean_absolute_error: 1.422845, mean_q: -0.107640
  1198/100000: episode: 16, duration: 0.402s, episode steps: 79, steps per second: 196, episode reward: -201.666, mean reward: -2.553 [-100.000, 5.247], mean action: 0.418 [0.000, 3.000], mean observation: -0.058 [-1.750, 1.418], loss: 81.455574, mean_absolute_error: 1.409733, mean_q: -0.124507
  1273/100000: episode: 17, duration: 0.422s, episode steps: 75, steps per second: 178, episode reward: -216.161, mean reward: -2.882 [-100.000, 3.008], mean action: 0.747 [0.000, 3.000], mean observation: 0.030 [-7.245, 1.414], loss: 91.754295, mean_absolute_error: 1.496604, mean_q: -0.148090
  1352/100000: episode: 18, duration: 0.468s, episode steps: 79, steps per second: 169, episode reward: -138.527, mean reward: -1.754 [-100.000, 5.438], mean action: 0.873 [0.000, 3.000], mean observation: -0.011 [-1.783, 6.051], loss: 64.457436, mean_absolute_error: 1.350797, mean_q: -0.179319
  1417/100000: episode: 19, duration: 0.386s, episode steps: 65, steps per second: 169, episode reward: -184.651, mean reward: -2.841 [-100.000, 6.208], mean action: 1.338 [0.000, 3.000], mean observation: 0.031 [-1.806, 5.025], loss: 78.921860, mean_absolute_error: 1.462742, mean_q: -0.208243
  1502/100000: episode: 20, duration: 0.439s, episode steps: 85, steps per second: 194, episode reward: -205.278, mean reward: -2.415 [-100.000, 5.702], mean action: 0.788 [0.000, 3.000], mean observation: 0.023 [-1.699, 4.601], loss: 68.848839, mean_absolute_error: 1.443595, mean_q: -0.242816
  1585/100000: episode: 21, duration: 0.430s, episode steps: 83, steps per second: 193, episode reward: -145.418, mean reward: -1.752 [-100.000, 6.187], mean action: 0.723 [0.000, 3.000], mean observation: 0.025 [-1.712, 5.154], loss: 91.144356, mean_absolute_error: 1.571115, mean_q: -0.288087
  1667/100000: episode: 22, duration: 0.431s, episode steps: 82, steps per second: 190, episode reward: -235.737, mean reward: -2.875 [-100.000, 2.925], mean action: 0.561 [0.000, 3.000], mean observation: 0.065 [-6.944, 1.439], loss: 78.272514, mean_absolute_error: 1.538511, mean_q: -0.341739
  1721/100000: episode: 23, duration: 0.323s, episode steps: 54, steps per second: 167, episode reward: -163.824, mean reward: -3.034 [-100.000, 4.621], mean action: 1.093 [0.000, 3.000], mean observation: -0.000 [-1.756, 1.393], loss: 62.707993, mean_absolute_error: 1.486665, mean_q: -0.389161
  1789/100000: episode: 24, duration: 0.400s, episode steps: 68, steps per second: 170, episode reward: -131.216, mean reward: -1.930 [-100.000, 4.850], mean action: 0.912 [0.000, 3.000], mean observation: -0.039 [-1.728, 5.819], loss: 83.106544, mean_absolute_error: 1.627536, mean_q: -0.440755
  1850/100000: episode: 25, duration: 0.366s, episode steps: 61, steps per second: 167, episode reward: -139.079, mean reward: -2.280 [-100.000, 10.507], mean action: 1.098 [0.000, 3.000], mean observation: -0.039 [-1.729, 5.097], loss: 87.739578, mean_absolute_error: 1.683895, mean_q: -0.511476
  1934/100000: episode: 26, duration: 0.497s, episode steps: 84, steps per second: 169, episode reward: -136.409, mean reward: -1.624 [-100.000, 15.268], mean action: 0.548 [0.000, 3.000], mean observation: -0.026 [-4.902, 1.465], loss: 61.200165, mean_absolute_error: 1.569993, mean_q: -0.572420
  2006/100000: episode: 27, duration: 0.386s, episode steps: 72, steps per second: 186, episode reward: -169.431, mean reward: -2.353 [-100.000, 7.910], mean action: 0.986 [0.000, 3.000], mean observation: -0.009 [-1.725, 4.763], loss: 77.219254, mean_absolute_error: 1.742724, mean_q: -0.651990
  2066/100000: episode: 28, duration: 0.344s, episode steps: 60, steps per second: 174, episode reward: -215.025, mean reward: -3.584 [-100.000, 2.537], mean action: 0.967 [0.000, 3.000], mean observation: -0.007 [-2.242, 1.401], loss: 60.365601, mean_absolute_error: 1.695246, mean_q: -0.724985
  2135/100000: episode: 29, duration: 0.407s, episode steps: 69, steps per second: 170, episode reward: -99.508, mean reward: -1.442 [-100.000, 10.773], mean action: 0.986 [0.000, 3.000], mean observation: -0.078 [-1.606, 1.404], loss: 98.012276, mean_absolute_error: 1.941849, mean_q: -0.798363
  2222/100000: episode: 30, duration: 0.534s, episode steps: 87, steps per second: 163, episode reward: -377.733, mean reward: -4.342 [-100.000, 1.458], mean action: 0.874 [0.000, 3.000], mean observation: -0.049 [-2.216, 1.453], loss: 74.833084, mean_absolute_error: 1.905586, mean_q: -0.885092
  2296/100000: episode: 31, duration: 0.442s, episode steps: 74, steps per second: 167, episode reward: -446.168, mean reward: -6.029 [-100.000, -1.463], mean action: 0.946 [0.000, 3.000], mean observation: -0.125 [-3.406, 1.458], loss: 73.009392, mean_absolute_error: 1.998756, mean_q: -0.988584
  2350/100000: episode: 32, duration: 0.327s, episode steps: 54, steps per second: 165, episode reward: -328.990, mean reward: -6.092 [-100.000, 0.862], mean action: 1.315 [0.000, 3.000], mean observation: -0.133 [-2.045, 1.391], loss: 63.946068, mean_absolute_error: 2.031181, mean_q: -1.072173
  2408/100000: episode: 33, duration: 0.348s, episode steps: 58, steps per second: 167, episode reward: -323.006, mean reward: -5.569 [-100.000, -2.516], mean action: 1.224 [0.000, 3.000], mean observation: -0.134 [-1.899, 1.397], loss: 108.704391, mean_absolute_error: 2.324226, mean_q: -1.156016
  2502/100000: episode: 34, duration: 0.517s, episode steps: 94, steps per second: 182, episode reward: -390.055, mean reward: -4.150 [-100.000, 1.192], mean action: 1.457 [0.000, 3.000], mean observation: -0.080 [-2.332, 2.896], loss: 95.117302, mean_absolute_error: 2.393949, mean_q: -1.312340
  2569/100000: episode: 35, duration: 0.408s, episode steps: 67, steps per second: 164, episode reward: -340.243, mean reward: -5.078 [-100.000, -1.278], mean action: 1.582 [0.000, 3.000], mean observation: -0.154 [-1.998, 3.619], loss: 72.592911, mean_absolute_error: 2.436957, mean_q: -1.503036
  2655/100000: episode: 36, duration: 0.522s, episode steps: 86, steps per second: 165, episode reward: -347.788, mean reward: -4.044 [-100.000, 1.901], mean action: 2.105 [0.000, 3.000], mean observation: -0.064 [-2.146, 2.878], loss: 84.966721, mean_absolute_error: 2.659156, mean_q: -1.759038
  2742/100000: episode: 37, duration: 0.531s, episode steps: 87, steps per second: 164, episode reward: -35.018, mean reward: -0.403 [-100.000, 118.209], mean action: 1.609 [0.000, 3.000], mean observation: -0.124 [-2.412, 1.592], loss: 81.424309, mean_absolute_error: 2.852226, mean_q: -2.073721
  2794/100000: episode: 38, duration: 0.290s, episode steps: 52, steps per second: 179, episode reward: -210.478, mean reward: -4.048 [-100.000, 5.386], mean action: 2.442 [0.000, 3.000], mean observation: -0.167 [-5.405, 1.386], loss: 96.573975, mean_absolute_error: 3.135999, mean_q: -2.382721
  2848/100000: episode: 39, duration: 0.323s, episode steps: 54, steps per second: 167, episode reward: -173.747, mean reward: -3.218 [-100.000, 4.427], mean action: 2.296 [0.000, 3.000], mean observation: -0.161 [-1.843, 1.385], loss: 42.089447, mean_absolute_error: 3.032876, mean_q: -2.575229
  2909/100000: episode: 40, duration: 0.358s, episode steps: 61, steps per second: 170, episode reward: -167.406, mean reward: -2.744 [-100.000, 3.154], mean action: 2.328 [0.000, 3.000], mean observation: -0.174 [-1.843, 1.394], loss: 94.273750, mean_absolute_error: 3.445163, mean_q: -2.812530
  2968/100000: episode: 41, duration: 0.323s, episode steps: 59, steps per second: 182, episode reward: -369.135, mean reward: -6.257 [-100.000, 3.041], mean action: 2.373 [1.000, 3.000], mean observation: -0.063 [-3.735, 1.978], loss: 82.457420, mean_absolute_error: 3.605427, mean_q: -3.109448
  3066/100000: episode: 42, duration: 0.536s, episode steps: 98, steps per second: 183, episode reward: -226.762, mean reward: -2.314 [-100.000, 4.822], mean action: 2.194 [0.000, 3.000], mean observation: 0.121 [-2.489, 1.493], loss: 72.325432, mean_absolute_error: 3.829588, mean_q: -3.427967
  3154/100000: episode: 43, duration: 0.479s, episode steps: 88, steps per second: 184, episode reward: -163.477, mean reward: -1.858 [-100.000, 5.795], mean action: 2.125 [0.000, 3.000], mean observation: 0.164 [-1.767, 1.454], loss: 74.435883, mean_absolute_error: 4.201691, mean_q: -3.922481
  3210/100000: episode: 44, duration: 0.303s, episode steps: 56, steps per second: 185, episode reward: -94.953, mean reward: -1.696 [-100.000, 5.537], mean action: 2.071 [0.000, 3.000], mean observation: -0.119 [-1.799, 5.319], loss: 85.030556, mean_absolute_error: 4.626035, mean_q: -4.431218
  3291/100000: episode: 45, duration: 0.435s, episode steps: 81, steps per second: 186, episode reward: -146.017, mean reward: -1.803 [-100.000, 17.659], mean action: 2.025 [0.000, 3.000], mean observation: 0.018 [-6.080, 1.422], loss: 62.486099, mean_absolute_error: 4.857174, mean_q: -4.932382
  3370/100000: episode: 46, duration: 0.428s, episode steps: 79, steps per second: 185, episode reward: -136.086, mean reward: -1.723 [-100.000, 5.578], mean action: 1.962 [0.000, 3.000], mean observation: 0.143 [-5.058, 1.413], loss: 67.590553, mean_absolute_error: 5.331913, mean_q: -5.537119
  3437/100000: episode: 47, duration: 0.361s, episode steps: 67, steps per second: 186, episode reward: -124.020, mean reward: -1.851 [-100.000, 10.160], mean action: 2.045 [0.000, 3.000], mean observation: 0.101 [-1.723, 1.402], loss: 67.472374, mean_absolute_error: 5.727261, mean_q: -6.093133
  3529/100000: episode: 48, duration: 0.497s, episode steps: 92, steps per second: 185, episode reward: -223.636, mean reward: -2.431 [-100.000, 25.287], mean action: 1.989 [0.000, 3.000], mean observation: 0.107 [-1.682, 4.662], loss: 74.241623, mean_absolute_error: 6.234244, mean_q: -6.710402
  3583/100000: episode: 49, duration: 0.294s, episode steps: 54, steps per second: 184, episode reward: -131.298, mean reward: -2.431 [-100.000, 15.578], mean action: 2.056 [0.000, 3.000], mean observation: -0.047 [-5.148, 1.388], loss: 47.532879, mean_absolute_error: 6.548821, mean_q: -7.318066
  3664/100000: episode: 50, duration: 0.442s, episode steps: 81, steps per second: 183, episode reward: -317.315, mean reward: -3.917 [-100.000, 109.638], mean action: 2.111 [0.000, 3.000], mean observation: 0.100 [-1.537, 3.026], loss: 63.176178, mean_absolute_error: 6.981388, mean_q: -7.827960
  3754/100000: episode: 51, duration: 0.490s, episode steps: 90, steps per second: 184, episode reward: -411.694, mean reward: -4.574 [-100.000, 1.364], mean action: 1.722 [0.000, 3.000], mean observation: 0.094 [-2.451, 1.518], loss: 62.643646, mean_absolute_error: 7.604454, mean_q: -8.681496
  3880/100000: episode: 52, duration: 0.682s, episode steps: 126, steps per second: 185, episode reward: -627.899, mean reward: -4.983 [-100.000, 3.256], mean action: 1.841 [0.000, 3.000], mean observation: 0.153 [-3.450, 1.855], loss: 66.869064, mean_absolute_error: 8.322585, mean_q: -9.518408
  3958/100000: episode: 53, duration: 0.430s, episode steps: 78, steps per second: 181, episode reward: -496.123, mean reward: -6.361 [-100.000, 0.168], mean action: 1.885 [0.000, 3.000], mean observation: 0.141 [-2.721, 1.858], loss: 63.819962, mean_absolute_error: 9.107839, mean_q: -10.532722
  4042/100000: episode: 54, duration: 0.455s, episode steps: 84, steps per second: 185, episode reward: -614.900, mean reward: -7.320 [-100.000, -0.355], mean action: 1.762 [0.000, 3.000], mean observation: 0.279 [-2.584, 2.969], loss: 55.812359, mean_absolute_error: 9.772084, mean_q: -11.393816
  4119/100000: episode: 55, duration: 0.423s, episode steps: 77, steps per second: 182, episode reward: -404.507, mean reward: -5.253 [-100.000, 1.396], mean action: 1.779 [0.000, 3.000], mean observation: 0.025 [-2.519, 1.396], loss: 78.686920, mean_absolute_error: 10.674080, mean_q: -12.511920
  4312/100000: episode: 56, duration: 1.164s, episode steps: 193, steps per second: 166, episode reward: -214.959, mean reward: -1.114 [-100.000, 20.379], mean action: 1.902 [0.000, 3.000], mean observation: 0.192 [-2.305, 1.393], loss: 47.419086, mean_absolute_error: 11.742308, mean_q: -14.270629
  4418/100000: episode: 57, duration: 0.603s, episode steps: 106, steps per second: 176, episode reward: -112.964, mean reward: -1.066 [-100.000, 10.512], mean action: 1.840 [0.000, 3.000], mean observation: -0.110 [-0.988, 1.856], loss: 40.884914, mean_absolute_error: 12.997679, mean_q: -16.047676
  4510/100000: episode: 58, duration: 0.499s, episode steps: 92, steps per second: 184, episode reward: -67.199, mean reward: -0.730 [-100.000, 22.486], mean action: 1.674 [0.000, 3.000], mean observation: 0.191 [-1.472, 1.518], loss: 52.290798, mean_absolute_error: 14.032763, mean_q: -17.275284
  4568/100000: episode: 59, duration: 0.313s, episode steps: 58, steps per second: 185, episode reward: -128.928, mean reward: -2.223 [-100.000, 5.244], mean action: 1.931 [0.000, 3.000], mean observation: -0.053 [-1.712, 5.347], loss: 39.986607, mean_absolute_error: 14.633445, mean_q: -18.183823
  4648/100000: episode: 60, duration: 0.432s, episode steps: 80, steps per second: 185, episode reward: -105.117, mean reward: -1.314 [-100.000, 13.191], mean action: 1.425 [0.000, 3.000], mean observation: -0.055 [-1.689, 1.415], loss: 47.141052, mean_absolute_error: 15.374481, mean_q: -19.076618
  4719/100000: episode: 61, duration: 0.389s, episode steps: 71, steps per second: 183, episode reward: -68.028, mean reward: -0.958 [-100.000, 21.346], mean action: 1.620 [0.000, 3.000], mean observation: 0.050 [-3.826, 1.402], loss: 53.758987, mean_absolute_error: 16.210865, mean_q: -20.155701
  4782/100000: episode: 62, duration: 0.355s, episode steps: 63, steps per second: 177, episode reward: -30.818, mean reward: -0.489 [-100.000, 9.880], mean action: 1.714 [0.000, 3.000], mean observation: -0.021 [-1.352, 3.522], loss: 57.879665, mean_absolute_error: 16.820871, mean_q: -20.940342
  4842/100000: episode: 63, duration: 0.323s, episode steps: 60, steps per second: 186, episode reward: -39.381, mean reward: -0.656 [-100.000, 10.914], mean action: 1.700 [0.000, 3.000], mean observation: -0.126 [-1.412, 3.718], loss: 41.823387, mean_absolute_error: 17.221750, mean_q: -21.587454
  5175/100000: episode: 64, duration: 2.021s, episode steps: 333, steps per second: 165, episode reward: -544.778, mean reward: -1.636 [-100.000, 15.922], mean action: 1.814 [0.000, 3.000], mean observation: 0.054 [-1.547, 3.044], loss: 36.469131, mean_absolute_error: 18.944984, mean_q: -23.878012
  5448/100000: episode: 65, duration: 1.515s, episode steps: 273, steps per second: 180, episode reward: -140.712, mean reward: -0.515 [-100.000, 8.754], mean action: 1.322 [0.000, 3.000], mean observation: 0.042 [-2.225, 1.505], loss: 34.367981, mean_absolute_error: 21.269045, mean_q: -26.854099
  5512/100000: episode: 66, duration: 0.344s, episode steps: 64, steps per second: 186, episode reward: -40.312, mean reward: -0.630 [-100.000, 6.324], mean action: 1.641 [0.000, 3.000], mean observation: -0.146 [-1.229, 3.587], loss: 35.386765, mean_absolute_error: 22.725275, mean_q: -28.768333
  5664/100000: episode: 67, duration: 0.832s, episode steps: 152, steps per second: 183, episode reward: -435.124, mean reward: -2.863 [-100.000, 6.604], mean action: 1.855 [0.000, 3.000], mean observation: 0.032 [-1.123, 2.999], loss: 31.177214, mean_absolute_error: 23.518972, mean_q: -29.787842
  5761/100000: episode: 68, duration: 0.516s, episode steps: 97, steps per second: 188, episode reward: -41.378, mean reward: -0.427 [-100.000, 31.255], mean action: 1.330 [0.000, 3.000], mean observation: -0.048 [-1.202, 3.042], loss: 29.599733, mean_absolute_error: 24.514214, mean_q: -31.132561
  5902/100000: episode: 69, duration: 0.766s, episode steps: 141, steps per second: 184, episode reward: -550.376, mean reward: -3.903 [-100.000, 5.285], mean action: 1.730 [0.000, 3.000], mean observation: 0.037 [-2.171, 3.103], loss: 34.241524, mean_absolute_error: 25.216091, mean_q: -32.034042
  6548/100000: episode: 70, duration: 4.333s, episode steps: 646, steps per second: 149, episode reward: -89.661, mean reward: -0.139 [-100.000, 14.114], mean action: 1.446 [0.000, 3.000], mean observation: 0.150 [-0.914, 1.485], loss: 20.320185, mean_absolute_error: 27.574989, mean_q: -35.233089
  6657/100000: episode: 71, duration: 0.581s, episode steps: 109, steps per second: 188, episode reward: -191.676, mean reward: -1.758 [-100.000, 5.890], mean action: 0.890 [0.000, 3.000], mean observation: 0.016 [-1.312, 1.531], loss: 17.887165, mean_absolute_error: 29.478106, mean_q: -37.784817
  6919/100000: episode: 72, duration: 1.455s, episode steps: 262, steps per second: 180, episode reward: -286.761, mean reward: -1.095 [-100.000, 9.278], mean action: 1.340 [0.000, 3.000], mean observation: 0.181 [-2.062, 6.322], loss: 18.479887, mean_absolute_error: 30.566614, mean_q: -39.185993
  7027/100000: episode: 73, duration: 0.557s, episode steps: 108, steps per second: 194, episode reward: -198.325, mean reward: -1.836 [-100.000, 10.171], mean action: 0.759 [0.000, 3.000], mean observation: -0.030 [-3.053, 1.472], loss: 19.302294, mean_absolute_error: 31.217403, mean_q: -39.931786
  7143/100000: episode: 74, duration: 0.630s, episode steps: 116, steps per second: 184, episode reward: -210.574, mean reward: -1.815 [-100.000, 34.014], mean action: 1.233 [0.000, 3.000], mean observation: 0.067 [-0.906, 2.668], loss: 18.064713, mean_absolute_error: 31.963667, mean_q: -40.956924
  7477/100000: episode: 75, duration: 1.928s, episode steps: 334, steps per second: 173, episode reward: -219.142, mean reward: -0.656 [-100.000, 7.067], mean action: 1.377 [0.000, 3.000], mean observation: 0.215 [-3.491, 2.216], loss: 15.391939, mean_absolute_error: 33.321014, mean_q: -42.795853
  7562/100000: episode: 76, duration: 0.457s, episode steps: 85, steps per second: 186, episode reward: -101.100, mean reward: -1.189 [-100.000, 7.770], mean action: 1.082 [0.000, 3.000], mean observation: -0.116 [-3.917, 1.388], loss: 16.419285, mean_absolute_error: 34.324112, mean_q: -44.174408
  7645/100000: episode: 77, duration: 0.440s, episode steps: 83, steps per second: 189, episode reward: -193.819, mean reward: -2.335 [-100.000, 8.217], mean action: 0.771 [0.000, 3.000], mean observation: -0.075 [-4.644, 1.418], loss: 16.633520, mean_absolute_error: 34.412617, mean_q: -44.421291
  7852/100000: episode: 78, duration: 1.177s, episode steps: 207, steps per second: 176, episode reward: -183.796, mean reward: -0.888 [-100.000, 38.179], mean action: 1.478 [0.000, 3.000], mean observation: 0.219 [-4.704, 1.936], loss: 10.010043, mean_absolute_error: 35.071644, mean_q: -45.338760
  7965/100000: episode: 79, duration: 0.612s, episode steps: 113, steps per second: 185, episode reward: -93.267, mean reward: -0.825 [-100.000, 13.829], mean action: 1.283 [0.000, 3.000], mean observation: 0.002 [-0.952, 1.390], loss: 11.818496, mean_absolute_error: 35.829952, mean_q: -46.362045
  8140/100000: episode: 80, duration: 0.975s, episode steps: 175, steps per second: 180, episode reward: -106.517, mean reward: -0.609 [-100.000, 14.017], mean action: 1.549 [0.000, 3.000], mean observation: 0.087 [-1.142, 2.847], loss: 10.981761, mean_absolute_error: 36.548779, mean_q: -47.309837
  8460/100000: episode: 81, duration: 1.895s, episode steps: 320, steps per second: 169, episode reward: -161.084, mean reward: -0.503 [-100.000, 6.452], mean action: 1.497 [0.000, 3.000], mean observation: 0.095 [-1.295, 2.134], loss: 11.113052, mean_absolute_error: 37.568840, mean_q: -48.678551
  8653/100000: episode: 82, duration: 1.076s, episode steps: 193, steps per second: 179, episode reward: -226.787, mean reward: -1.175 [-100.000, 8.091], mean action: 1.482 [0.000, 3.000], mean observation: 0.104 [-3.924, 1.545], loss: 13.892039, mean_absolute_error: 38.485859, mean_q: -49.836987
  8742/100000: episode: 83, duration: 0.467s, episode steps: 89, steps per second: 191, episode reward: -106.160, mean reward: -1.193 [-100.000, 42.117], mean action: 0.966 [0.000, 3.000], mean observation: -0.071 [-3.394, 1.435], loss: 9.257145, mean_absolute_error: 38.871605, mean_q: -50.411510
  8933/100000: episode: 84, duration: 1.075s, episode steps: 191, steps per second: 178, episode reward: -119.425, mean reward: -0.625 [-100.000, 15.410], mean action: 1.545 [0.000, 3.000], mean observation: 0.051 [-0.729, 1.797], loss: 10.540301, mean_absolute_error: 39.378967, mean_q: -51.093567
  9066/100000: episode: 85, duration: 0.724s, episode steps: 133, steps per second: 184, episode reward: -83.944, mean reward: -0.631 [-100.000, 9.403], mean action: 1.466 [0.000, 3.000], mean observation: 0.073 [-1.144, 1.533], loss: 9.914922, mean_absolute_error: 39.745251, mean_q: -51.576157
  9382/100000: episode: 86, duration: 1.881s, episode steps: 316, steps per second: 168, episode reward: -119.606, mean reward: -0.379 [-100.000, 12.088], mean action: 1.541 [0.000, 3.000], mean observation: 0.049 [-0.910, 1.431], loss: 13.881024, mean_absolute_error: 40.305462, mean_q: -52.244370
  9816/100000: episode: 87, duration: 2.659s, episode steps: 434, steps per second: 163, episode reward: -84.966, mean reward: -0.196 [-100.000, 9.674], mean action: 1.525 [0.000, 3.000], mean observation: 0.117 [-1.699, 2.040], loss: 10.655510, mean_absolute_error: 40.643757, mean_q: -52.662010
 10027/100000: episode: 88, duration: 1.186s, episode steps: 211, steps per second: 178, episode reward: -139.327, mean reward: -0.660 [-100.000, 15.966], mean action: 1.422 [0.000, 3.000], mean observation: 0.099 [-1.194, 3.046], loss: 11.605427, mean_absolute_error: 40.843254, mean_q: -52.868961
 10221/100000: episode: 89, duration: 1.082s, episode steps: 194, steps per second: 179, episode reward: -181.112, mean reward: -0.934 [-100.000, 7.156], mean action: 1.366 [0.000, 3.000], mean observation: -0.001 [-0.971, 2.906], loss: 9.208873, mean_absolute_error: 41.082932, mean_q: -53.200989
 10493/100000: episode: 90, duration: 1.572s, episode steps: 272, steps per second: 173, episode reward: -126.656, mean reward: -0.466 [-100.000, 12.664], mean action: 1.456 [0.000, 3.000], mean observation: 0.141 [-1.081, 3.028], loss: 11.347886, mean_absolute_error: 40.847202, mean_q: -52.820099
 10913/100000: episode: 91, duration: 2.616s, episode steps: 420, steps per second: 161, episode reward: -836.935, mean reward: -1.993 [-100.000, 2.459], mean action: 1.479 [0.000, 3.000], mean observation: 0.446 [-0.659, 4.947], loss: 10.192596, mean_absolute_error: 41.088448, mean_q: -53.136833
 11254/100000: episode: 92, duration: 1.970s, episode steps: 341, steps per second: 173, episode reward: -592.138, mean reward: -1.736 [-100.000, 2.811], mean action: 1.557 [0.000, 3.000], mean observation: 0.404 [-0.563, 4.050], loss: 10.470092, mean_absolute_error: 41.868412, mean_q: -54.136639
 11767/100000: episode: 93, duration: 3.412s, episode steps: 513, steps per second: 150, episode reward: -163.086, mean reward: -0.318 [-100.000, 13.261], mean action: 1.559 [0.000, 3.000], mean observation: 0.093 [-1.344, 2.183], loss: 10.135358, mean_absolute_error: 42.127895, mean_q: -54.546909
 12405/100000: episode: 94, duration: 4.299s, episode steps: 638, steps per second: 148, episode reward: -182.659, mean reward: -0.286 [-100.000, 14.572], mean action: 1.704 [0.000, 3.000], mean observation: 0.043 [-0.853, 1.397], loss: 10.213642, mean_absolute_error: 41.747574, mean_q: -54.055996
 13005/100000: episode: 95, duration: 3.700s, episode steps: 600, steps per second: 162, episode reward: -536.570, mean reward: -0.894 [-100.000, 4.139], mean action: 1.703 [0.000, 3.000], mean observation: 0.290 [-0.765, 3.754], loss: 9.125996, mean_absolute_error: 40.903805, mean_q: -52.947208
 13778/100000: episode: 96, duration: 5.111s, episode steps: 773, steps per second: 151, episode reward: -349.702, mean reward: -0.452 [-100.000, 4.937], mean action: 1.858 [0.000, 3.000], mean observation: 0.439 [-0.500, 3.442], loss: 8.923134, mean_absolute_error: 40.884872, mean_q: -52.904968
 14519/100000: episode: 97, duration: 5.084s, episode steps: 741, steps per second: 146, episode reward: -426.819, mean reward: -0.576 [-100.000, 4.504], mean action: 1.876 [0.000, 3.000], mean observation: 0.294 [-0.219, 3.344], loss: 11.050471, mean_absolute_error: 39.982292, mean_q: -51.653004
 15519/100000: episode: 98, duration: 9.870s, episode steps: 1000, steps per second: 101, episode reward: -142.513, mean reward: -0.143 [-4.969, 4.304], mean action: 1.864 [0.000, 3.000], mean observation: 0.168 [-0.379, 1.396], loss: 9.961865, mean_absolute_error: 38.516361, mean_q: -49.732811
 16519/100000: episode: 99, duration: 7.723s, episode steps: 1000, steps per second: 129, episode reward: -214.256, mean reward: -0.214 [-5.249, 4.225], mean action: 1.900 [0.000, 3.000], mean observation: 0.295 [-0.191, 2.264], loss: 8.113672, mean_absolute_error: 36.570984, mean_q: -47.213234
 17519/100000: episode: 100, duration: 6.674s, episode steps: 1000, steps per second: 150, episode reward: -80.229, mean reward: -0.080 [-4.627, 4.704], mean action: 1.748 [0.000, 3.000], mean observation: 0.078 [-0.474, 1.465], loss: 9.306758, mean_absolute_error: 34.882206, mean_q: -44.950691
 18519/100000: episode: 101, duration: 7.747s, episode steps: 1000, steps per second: 129, episode reward: -192.206, mean reward: -0.192 [-5.184, 5.336], mean action: 1.645 [0.000, 3.000], mean observation: 0.225 [-0.228, 1.919], loss: 8.001728, mean_absolute_error: 32.614624, mean_q: -41.952919
 19519/100000: episode: 102, duration: 8.430s, episode steps: 1000, steps per second: 119, episode reward: -149.860, mean reward: -0.150 [-5.185, 4.276], mean action: 1.655 [0.000, 3.000], mean observation: 0.187 [-0.224, 1.701], loss: 7.571596, mean_absolute_error: 31.106390, mean_q: -39.992249
 20519/100000: episode: 103, duration: 8.774s, episode steps: 1000, steps per second: 114, episode reward: -183.150, mean reward: -0.183 [-4.785, 3.772], mean action: 1.591 [0.000, 3.000], mean observation: 0.184 [-0.207, 1.618], loss: 8.822678, mean_absolute_error: 29.261557, mean_q: -37.522648
 21312/100000: episode: 104, duration: 6.000s, episode steps: 793, steps per second: 132, episode reward: -120.370, mean reward: -0.152 [-100.000, 15.283], mean action: 1.584 [0.000, 3.000], mean observation: 0.128 [-0.969, 1.503], loss: 8.886503, mean_absolute_error: 27.841906, mean_q: -35.635132
 21631/100000: episode: 105, duration: 1.835s, episode steps: 319, steps per second: 174, episode reward: -58.449, mean reward: -0.183 [-100.000, 14.623], mean action: 1.542 [0.000, 3.000], mean observation: 0.029 [-0.555, 2.892], loss: 7.027214, mean_absolute_error: 26.978622, mean_q: -34.489208
 21734/100000: episode: 106, duration: 0.551s, episode steps: 103, steps per second: 187, episode reward: -145.024, mean reward: -1.408 [-100.000, 2.851], mean action: 1.485 [0.000, 3.000], mean observation: -0.089 [-1.229, 1.465], loss: 3.594192, mean_absolute_error: 26.690765, mean_q: -34.134651
 22446/100000: episode: 107, duration: 5.204s, episode steps: 712, steps per second: 137, episode reward: -165.631, mean reward: -0.233 [-100.000, 7.021], mean action: 1.572 [0.000, 3.000], mean observation: 0.031 [-1.529, 1.389], loss: 8.729105, mean_absolute_error: 26.342928, mean_q: -33.613087
 22820/100000: episode: 108, duration: 2.315s, episode steps: 374, steps per second: 162, episode reward: -66.253, mean reward: -0.177 [-100.000, 9.201], mean action: 1.623 [0.000, 3.000], mean observation: 0.035 [-0.853, 1.976], loss: 8.487418, mean_absolute_error: 25.165747, mean_q: -32.088375
 23820/100000: episode: 109, duration: 7.553s, episode steps: 1000, steps per second: 132, episode reward: -120.812, mean reward: -0.121 [-4.751, 4.708], mean action: 1.507 [0.000, 3.000], mean observation: 0.106 [-0.483, 1.391], loss: 8.381135, mean_absolute_error: 24.347425, mean_q: -30.991711
 24385/100000: episode: 110, duration: 3.839s, episode steps: 565, steps per second: 147, episode reward: -97.682, mean reward: -0.173 [-100.000, 18.023], mean action: 1.465 [0.000, 3.000], mean observation: 0.113 [-0.963, 1.445], loss: 6.604419, mean_absolute_error: 23.049816, mean_q: -29.294973
 24623/100000: episode: 111, duration: 1.354s, episode steps: 238, steps per second: 176, episode reward: -18.682, mean reward: -0.078 [-100.000, 13.391], mean action: 1.668 [0.000, 3.000], mean observation: 0.074 [-1.069, 1.401], loss: 8.703721, mean_absolute_error: 22.224504, mean_q: -28.182137
 25623/100000: episode: 112, duration: 6.745s, episode steps: 1000, steps per second: 148, episode reward: -99.847, mean reward: -0.100 [-5.074, 5.084], mean action: 1.547 [0.000, 3.000], mean observation: 0.206 [-0.334, 1.541], loss: 7.750052, mean_absolute_error: 21.456755, mean_q: -27.174786
 26623/100000: episode: 113, duration: 7.764s, episode steps: 1000, steps per second: 129, episode reward: -37.292, mean reward: -0.037 [-4.928, 5.097], mean action: 1.626 [0.000, 3.000], mean observation: 0.106 [-0.686, 1.450], loss: 6.857171, mean_absolute_error: 19.770977, mean_q: -24.966337
 27623/100000: episode: 114, duration: 7.374s, episode steps: 1000, steps per second: 136, episode reward: -86.517, mean reward: -0.087 [-4.823, 5.022], mean action: 1.622 [0.000, 3.000], mean observation: 0.093 [-0.381, 1.412], loss: 6.031517, mean_absolute_error: 18.495363, mean_q: -23.264389
 27982/100000: episode: 115, duration: 2.127s, episode steps: 359, steps per second: 169, episode reward: -28.499, mean reward: -0.079 [-100.000, 13.435], mean action: 1.571 [0.000, 3.000], mean observation: 0.059 [-1.051, 1.658], loss: 8.058652, mean_absolute_error: 17.620312, mean_q: -22.061445
 28982/100000: episode: 116, duration: 8.551s, episode steps: 1000, steps per second: 117, episode reward: -80.492, mean reward: -0.080 [-4.488, 5.153], mean action: 1.565 [0.000, 3.000], mean observation: 0.064 [-0.532, 1.389], loss: 7.050536, mean_absolute_error: 16.685282, mean_q: -20.827250
 29197/100000: episode: 117, duration: 1.290s, episode steps: 215, steps per second: 167, episode reward: -242.246, mean reward: -1.127 [-100.000, 10.490], mean action: 1.419 [0.000, 3.000], mean observation: -0.005 [-1.131, 3.698], loss: 7.158813, mean_absolute_error: 16.285381, mean_q: -20.171349
 29382/100000: episode: 118, duration: 1.138s, episode steps: 185, steps per second: 163, episode reward: -84.695, mean reward: -0.458 [-100.000, 13.944], mean action: 1.351 [0.000, 3.000], mean observation: -0.003 [-0.948, 1.474], loss: 6.135688, mean_absolute_error: 15.860389, mean_q: -19.647154
 29703/100000: episode: 119, duration: 1.947s, episode steps: 321, steps per second: 165, episode reward: -157.893, mean reward: -0.492 [-100.000, 25.866], mean action: 1.414 [0.000, 3.000], mean observation: 0.071 [-0.925, 3.130], loss: 6.691281, mean_absolute_error: 15.600494, mean_q: -19.295624
 30703/100000: episode: 120, duration: 9.061s, episode steps: 1000, steps per second: 110, episode reward: -62.825, mean reward: -0.063 [-5.261, 7.049], mean action: 1.609 [0.000, 3.000], mean observation: 0.037 [-0.669, 1.387], loss: 6.423352, mean_absolute_error: 14.878936, mean_q: -18.314386
 30947/100000: episode: 121, duration: 1.432s, episode steps: 244, steps per second: 170, episode reward: -103.595, mean reward: -0.425 [-100.000, 11.405], mean action: 1.582 [0.000, 3.000], mean observation: 0.040 [-1.118, 1.400], loss: 8.406450, mean_absolute_error: 14.348416, mean_q: -17.583712
 31947/100000: episode: 122, duration: 8.312s, episode steps: 1000, steps per second: 120, episode reward: -51.672, mean reward: -0.052 [-4.505, 5.711], mean action: 1.559 [0.000, 3.000], mean observation: 0.027 [-0.819, 1.392], loss: 7.505977, mean_absolute_error: 13.771447, mean_q: -16.834167
 32947/100000: episode: 123, duration: 7.080s, episode steps: 1000, steps per second: 141, episode reward: -121.909, mean reward: -0.122 [-4.973, 5.882], mean action: 1.504 [0.000, 3.000], mean observation: 0.066 [-0.826, 1.401], loss: 6.022405, mean_absolute_error: 12.760248, mean_q: -15.544143
 33947/100000: episode: 124, duration: 7.655s, episode steps: 1000, steps per second: 131, episode reward: -84.047, mean reward: -0.084 [-4.280, 5.016], mean action: 1.526 [0.000, 3.000], mean observation: 0.050 [-0.748, 1.457], loss: 6.620716, mean_absolute_error: 11.990590, mean_q: -14.523689
 34176/100000: episode: 125, duration: 1.313s, episode steps: 229, steps per second: 174, episode reward: -206.267, mean reward: -0.901 [-100.000, 13.555], mean action: 1.463 [0.000, 3.000], mean observation: 0.047 [-1.974, 1.536], loss: 6.715192, mean_absolute_error: 11.680752, mean_q: -14.104633
 34667/100000: episode: 126, duration: 3.030s, episode steps: 491, steps per second: 162, episode reward: 223.089, mean reward: 0.454 [-22.502, 100.000], mean action: 1.493 [0.000, 3.000], mean observation: 0.011 [-0.832, 1.395], loss: 5.195635, mean_absolute_error: 11.529403, mean_q: -13.915683
 35060/100000: episode: 127, duration: 2.328s, episode steps: 393, steps per second: 169, episode reward: -74.253, mean reward: -0.189 [-100.000, 17.669], mean action: 1.608 [0.000, 3.000], mean observation: 0.001 [-0.959, 1.775], loss: 7.132040, mean_absolute_error: 11.559713, mean_q: -13.949166
 35279/100000: episode: 128, duration: 1.228s, episode steps: 219, steps per second: 178, episode reward: -72.369, mean reward: -0.330 [-100.000, 12.657], mean action: 1.470 [0.000, 3.000], mean observation: 0.044 [-0.989, 2.045], loss: 5.720737, mean_absolute_error: 10.916391, mean_q: -13.115125
 35609/100000: episode: 129, duration: 1.927s, episode steps: 330, steps per second: 171, episode reward: -3.547, mean reward: -0.011 [-100.000, 15.247], mean action: 1.491 [0.000, 3.000], mean observation: 0.068 [-1.129, 1.420], loss: 4.038933, mean_absolute_error: 10.617670, mean_q: -12.719898
 35855/100000: episode: 130, duration: 1.372s, episode steps: 246, steps per second: 179, episode reward: -223.767, mean reward: -0.910 [-100.000, 35.543], mean action: 1.411 [0.000, 3.000], mean observation: -0.000 [-1.921, 1.498], loss: 7.460119, mean_absolute_error: 10.846063, mean_q: -12.972331
 36388/100000: episode: 131, duration: 3.401s, episode steps: 533, steps per second: 157, episode reward: -113.123, mean reward: -0.212 [-100.000, 15.133], mean action: 1.488 [0.000, 3.000], mean observation: 0.030 [-0.775, 1.406], loss: 5.293627, mean_absolute_error: 10.730134, mean_q: -12.845162
 37388/100000: episode: 132, duration: 7.570s, episode steps: 1000, steps per second: 132, episode reward: -41.645, mean reward: -0.042 [-17.029, 15.243], mean action: 1.494 [0.000, 3.000], mean observation: 0.039 [-0.964, 1.396], loss: 6.408814, mean_absolute_error: 10.432918, mean_q: -12.447016
 37844/100000: episode: 133, duration: 2.961s, episode steps: 456, steps per second: 154, episode reward: -66.073, mean reward: -0.145 [-100.000, 40.840], mean action: 1.689 [0.000, 3.000], mean observation: 0.056 [-0.951, 1.448], loss: 6.492218, mean_absolute_error: 10.250961, mean_q: -12.183157
 38217/100000: episode: 134, duration: 2.276s, episode steps: 373, steps per second: 164, episode reward: -178.348, mean reward: -0.478 [-100.000, 48.317], mean action: 1.574 [0.000, 3.000], mean observation: 0.003 [-1.675, 1.429], loss: 7.511337, mean_absolute_error: 9.873623, mean_q: -11.715136
 39217/100000: episode: 135, duration: 6.913s, episode steps: 1000, steps per second: 145, episode reward: -88.083, mean reward: -0.088 [-5.128, 5.619], mean action: 1.541 [0.000, 3.000], mean observation: 0.110 [-0.877, 1.441], loss: 6.077030, mean_absolute_error: 9.389603, mean_q: -11.069319
 40217/100000: episode: 136, duration: 7.792s, episode steps: 1000, steps per second: 128, episode reward: -88.555, mean reward: -0.089 [-5.069, 5.392], mean action: 1.465 [0.000, 3.000], mean observation: 0.095 [-0.588, 1.415], loss: 5.746026, mean_absolute_error: 8.704699, mean_q: -10.165657
 40655/100000: episode: 137, duration: 2.611s, episode steps: 438, steps per second: 168, episode reward: -105.682, mean reward: -0.241 [-100.000, 15.505], mean action: 1.507 [0.000, 3.000], mean observation: 0.125 [-1.164, 1.422], loss: 6.427177, mean_absolute_error: 8.536669, mean_q: -9.937667
 41655/100000: episode: 138, duration: 6.568s, episode steps: 1000, steps per second: 152, episode reward: 30.173, mean reward: 0.030 [-18.975, 19.640], mean action: 1.369 [0.000, 3.000], mean observation: 0.099 [-0.618, 1.468], loss: 7.171126, mean_absolute_error: 8.205617, mean_q: -9.467627
 41883/100000: episode: 139, duration: 1.295s, episode steps: 228, steps per second: 176, episode reward: -39.304, mean reward: -0.172 [-100.000, 14.617], mean action: 1.667 [0.000, 3.000], mean observation: 0.096 [-0.894, 2.678], loss: 5.261469, mean_absolute_error: 8.683637, mean_q: -10.044781
 42133/100000: episode: 140, duration: 1.451s, episode steps: 250, steps per second: 172, episode reward: 44.668, mean reward: 0.179 [-100.000, 18.579], mean action: 1.736 [0.000, 3.000], mean observation: 0.104 [-0.932, 1.957], loss: 4.613227, mean_absolute_error: 8.333694, mean_q: -9.569508
 43133/100000: episode: 141, duration: 6.844s, episode steps: 1000, steps per second: 146, episode reward: -36.799, mean reward: -0.037 [-4.673, 5.719], mean action: 1.509 [0.000, 3.000], mean observation: 0.083 [-0.991, 1.520], loss: 5.838775, mean_absolute_error: 7.635527, mean_q: -8.629654
 43497/100000: episode: 142, duration: 2.261s, episode steps: 364, steps per second: 161, episode reward: -3.802, mean reward: -0.010 [-100.000, 15.114], mean action: 1.736 [0.000, 3.000], mean observation: 0.101 [-0.981, 1.422], loss: 5.559634, mean_absolute_error: 7.207600, mean_q: -8.019509
 43854/100000: episode: 143, duration: 2.121s, episode steps: 357, steps per second: 168, episode reward: 20.042, mean reward: 0.056 [-100.000, 12.346], mean action: 1.697 [0.000, 3.000], mean observation: 0.108 [-1.010, 1.386], loss: 4.241858, mean_absolute_error: 6.817430, mean_q: -7.501275
 44138/100000: episode: 144, duration: 1.655s, episode steps: 284, steps per second: 172, episode reward: -98.783, mean reward: -0.348 [-100.000, 12.232], mean action: 1.623 [0.000, 3.000], mean observation: 0.139 [-1.150, 2.504], loss: 6.283000, mean_absolute_error: 6.874244, mean_q: -7.516883
 45138/100000: episode: 145, duration: 6.931s, episode steps: 1000, steps per second: 144, episode reward: -1.937, mean reward: -0.002 [-4.575, 5.110], mean action: 1.592 [0.000, 3.000], mean observation: 0.040 [-0.785, 1.385], loss: 6.203756, mean_absolute_error: 6.377017, mean_q: -6.801795
 45588/100000: episode: 146, duration: 2.837s, episode steps: 450, steps per second: 159, episode reward: -94.360, mean reward: -0.210 [-100.000, 22.030], mean action: 1.524 [0.000, 3.000], mean observation: 0.161 [-1.853, 1.386], loss: 7.109221, mean_absolute_error: 6.145218, mean_q: -6.387138
 46012/100000: episode: 147, duration: 2.591s, episode steps: 424, steps per second: 164, episode reward: -256.874, mean reward: -0.606 [-100.000, 38.061], mean action: 1.540 [0.000, 3.000], mean observation: 0.032 [-1.956, 1.399], loss: 8.408507, mean_absolute_error: 6.033937, mean_q: -6.198424
 46188/100000: episode: 148, duration: 0.984s, episode steps: 176, steps per second: 179, episode reward: -59.372, mean reward: -0.337 [-100.000, 13.650], mean action: 1.807 [0.000, 3.000], mean observation: 0.196 [-1.290, 1.689], loss: 4.842243, mean_absolute_error: 5.638916, mean_q: -5.671453
 46640/100000: episode: 149, duration: 3.004s, episode steps: 452, steps per second: 150, episode reward: -48.320, mean reward: -0.107 [-100.000, 12.544], mean action: 1.743 [0.000, 3.000], mean observation: 0.067 [-0.832, 1.548], loss: 5.827467, mean_absolute_error: 5.845020, mean_q: -5.839132
 47127/100000: episode: 150, duration: 3.046s, episode steps: 487, steps per second: 160, episode reward: -76.889, mean reward: -0.158 [-100.000, 27.440], mean action: 1.485 [0.000, 3.000], mean observation: 0.178 [-0.868, 2.064], loss: 7.927571, mean_absolute_error: 5.801541, mean_q: -5.705093
 47343/100000: episode: 151, duration: 1.209s, episode steps: 216, steps per second: 179, episode reward: -165.165, mean reward: -0.765 [-100.000, 36.410], mean action: 1.731 [0.000, 3.000], mean observation: -0.013 [-1.747, 1.486], loss: 5.042819, mean_absolute_error: 6.002584, mean_q: -5.898858
 47705/100000: episode: 152, duration: 2.149s, episode steps: 362, steps per second: 168, episode reward: -64.498, mean reward: -0.178 [-100.000, 17.563], mean action: 1.541 [0.000, 3.000], mean observation: 0.119 [-1.052, 1.438], loss: 4.520366, mean_absolute_error: 5.596391, mean_q: -5.253055
 48148/100000: episode: 153, duration: 2.814s, episode steps: 443, steps per second: 157, episode reward: -53.871, mean reward: -0.122 [-100.000, 18.344], mean action: 1.648 [0.000, 3.000], mean observation: 0.090 [-1.117, 1.474], loss: 5.161355, mean_absolute_error: 5.907504, mean_q: -5.508118
 49148/100000: episode: 154, duration: 8.343s, episode steps: 1000, steps per second: 120, episode reward: -125.827, mean reward: -0.126 [-4.576, 6.945], mean action: 1.540 [0.000, 3.000], mean observation: 0.109 [-0.852, 1.574], loss: 6.102278, mean_absolute_error: 5.616156, mean_q: -4.953984
 50148/100000: episode: 155, duration: 7.317s, episode steps: 1000, steps per second: 137, episode reward: 28.973, mean reward: 0.029 [-11.191, 13.296], mean action: 1.639 [0.000, 3.000], mean observation: 0.052 [-0.784, 1.392], loss: 6.408299, mean_absolute_error: 5.349495, mean_q: -4.244273
 51148/100000: episode: 156, duration: 7.964s, episode steps: 1000, steps per second: 126, episode reward: -196.482, mean reward: -0.196 [-4.628, 4.630], mean action: 1.464 [0.000, 3.000], mean observation: 0.059 [-0.795, 1.472], loss: 4.963492, mean_absolute_error: 4.955458, mean_q: -3.375099
 51386/100000: episode: 157, duration: 1.361s, episode steps: 238, steps per second: 175, episode reward: -32.617, mean reward: -0.137 [-100.000, 15.884], mean action: 1.777 [0.000, 3.000], mean observation: 0.064 [-1.207, 1.593], loss: 6.558220, mean_absolute_error: 4.565988, mean_q: -2.543966
 52386/100000: episode: 158, duration: 6.741s, episode steps: 1000, steps per second: 148, episode reward: -118.815, mean reward: -0.119 [-5.341, 5.050], mean action: 1.560 [0.000, 3.000], mean observation: 0.028 [-0.686, 1.387], loss: 5.156436, mean_absolute_error: 4.644614, mean_q: -2.433547
 52741/100000: episode: 159, duration: 2.163s, episode steps: 355, steps per second: 164, episode reward: -254.087, mean reward: -0.716 [-100.000, 34.476], mean action: 1.518 [0.000, 3.000], mean observation: 0.076 [-2.067, 1.458], loss: 4.016006, mean_absolute_error: 4.402621, mean_q: -1.940979
 53143/100000: episode: 160, duration: 2.498s, episode steps: 402, steps per second: 161, episode reward: -149.496, mean reward: -0.372 [-100.000, 11.999], mean action: 1.530 [0.000, 3.000], mean observation: 0.171 [-3.069, 1.396], loss: 5.433742, mean_absolute_error: 4.487052, mean_q: -1.823950
 53357/100000: episode: 161, duration: 1.223s, episode steps: 214, steps per second: 175, episode reward: -44.362, mean reward: -0.207 [-100.000, 15.916], mean action: 1.752 [0.000, 3.000], mean observation: 0.057 [-1.109, 1.667], loss: 7.007883, mean_absolute_error: 4.446270, mean_q: -1.713067
 53639/100000: episode: 162, duration: 1.631s, episode steps: 282, steps per second: 173, episode reward: -236.800, mean reward: -0.840 [-100.000, 26.552], mean action: 1.897 [0.000, 3.000], mean observation: 0.133 [-0.789, 2.157], loss: 3.983952, mean_absolute_error: 4.207100, mean_q: -1.216158
 54075/100000: episode: 163, duration: 2.700s, episode steps: 436, steps per second: 161, episode reward: -79.600, mean reward: -0.183 [-100.000, 33.929], mean action: 1.569 [0.000, 3.000], mean observation: 0.136 [-1.322, 1.449], loss: 4.593194, mean_absolute_error: 4.216542, mean_q: -1.076076
 54329/100000: episode: 164, duration: 1.471s, episode steps: 254, steps per second: 173, episode reward: -36.064, mean reward: -0.142 [-100.000, 20.739], mean action: 1.740 [0.000, 3.000], mean observation: 0.096 [-1.146, 2.157], loss: 3.263426, mean_absolute_error: 4.084731, mean_q: -0.651635
 55329/100000: episode: 165, duration: 6.731s, episode steps: 1000, steps per second: 149, episode reward: -2.577, mean reward: -0.003 [-5.248, 6.458], mean action: 1.800 [0.000, 3.000], mean observation: 0.031 [-0.761, 1.452], loss: 4.563906, mean_absolute_error: 4.162117, mean_q: -0.575928
 56329/100000: episode: 166, duration: 7.247s, episode steps: 1000, steps per second: 138, episode reward: 20.425, mean reward: 0.020 [-20.961, 23.060], mean action: 1.389 [0.000, 3.000], mean observation: 0.087 [-0.886, 1.428], loss: 4.284342, mean_absolute_error: 4.099236, mean_q: -0.048093
 56528/100000: episode: 167, duration: 1.133s, episode steps: 199, steps per second: 176, episode reward: -71.775, mean reward: -0.361 [-100.000, 14.229], mean action: 1.749 [0.000, 3.000], mean observation: 0.165 [-1.662, 1.387], loss: 3.384633, mean_absolute_error: 4.460155, mean_q: -0.158110
 56672/100000: episode: 168, duration: 0.796s, episode steps: 144, steps per second: 181, episode reward: -79.391, mean reward: -0.551 [-100.000, 7.307], mean action: 1.958 [0.000, 3.000], mean observation: 0.109 [-1.278, 3.176], loss: 2.637912, mean_absolute_error: 4.350470, mean_q: 0.109600
 56842/100000: episode: 169, duration: 0.954s, episode steps: 170, steps per second: 178, episode reward: -180.485, mean reward: -1.062 [-100.000, 7.516], mean action: 1.865 [0.000, 3.000], mean observation: 0.036 [-2.159, 1.421], loss: 4.626225, mean_absolute_error: 4.561907, mean_q: -0.181407
 57098/100000: episode: 170, duration: 1.487s, episode steps: 256, steps per second: 172, episode reward: -105.982, mean reward: -0.414 [-100.000, 16.810], mean action: 1.887 [0.000, 3.000], mean observation: 0.063 [-1.125, 1.837], loss: 4.253767, mean_absolute_error: 4.480081, mean_q: 0.165542
 57294/100000: episode: 171, duration: 1.109s, episode steps: 196, steps per second: 177, episode reward: -237.895, mean reward: -1.214 [-100.000, 23.450], mean action: 1.918 [0.000, 3.000], mean observation: -0.015 [-2.171, 1.420], loss: 3.287149, mean_absolute_error: 4.273017, mean_q: 0.536910
 58294/100000: episode: 172, duration: 7.001s, episode steps: 1000, steps per second: 143, episode reward: -12.223, mean reward: -0.012 [-21.561, 21.387], mean action: 1.582 [0.000, 3.000], mean observation: 0.039 [-0.797, 1.405], loss: 3.947077, mean_absolute_error: 4.511778, mean_q: 0.679219
 58599/100000: episode: 173, duration: 1.806s, episode steps: 305, steps per second: 169, episode reward: -209.031, mean reward: -0.685 [-100.000, 12.174], mean action: 1.869 [0.000, 3.000], mean observation: -0.050 [-1.715, 1.390], loss: 3.283130, mean_absolute_error: 4.933286, mean_q: 0.512881
 58853/100000: episode: 174, duration: 1.443s, episode steps: 254, steps per second: 176, episode reward: -175.639, mean reward: -0.691 [-100.000, 17.916], mean action: 1.591 [0.000, 3.000], mean observation: 0.094 [-2.461, 1.593], loss: 3.060729, mean_absolute_error: 4.894723, mean_q: 0.801620
 59853/100000: episode: 175, duration: 7.513s, episode steps: 1000, steps per second: 133, episode reward: 25.996, mean reward: 0.026 [-18.369, 23.918], mean action: 1.530 [0.000, 3.000], mean observation: 0.048 [-0.716, 1.398], loss: 3.868205, mean_absolute_error: 4.869021, mean_q: 1.202796
 60127/100000: episode: 176, duration: 1.604s, episode steps: 274, steps per second: 171, episode reward: -104.863, mean reward: -0.383 [-100.000, 12.436], mean action: 1.872 [0.000, 3.000], mean observation: 0.043 [-1.097, 1.408], loss: 3.036893, mean_absolute_error: 4.904178, mean_q: 1.678169
 60266/100000: episode: 177, duration: 0.770s, episode steps: 139, steps per second: 181, episode reward: -128.421, mean reward: -0.924 [-100.000, 10.619], mean action: 1.799 [0.000, 3.000], mean observation: 0.030 [-1.263, 1.435], loss: 4.073393, mean_absolute_error: 5.026080, mean_q: 1.644836
 60515/100000: episode: 178, duration: 1.411s, episode steps: 249, steps per second: 176, episode reward: -186.060, mean reward: -0.747 [-100.000, 39.978], mean action: 1.614 [0.000, 3.000], mean observation: 0.079 [-1.943, 2.055], loss: 4.270826, mean_absolute_error: 5.156907, mean_q: 1.599955
 60709/100000: episode: 179, duration: 1.088s, episode steps: 194, steps per second: 178, episode reward: -234.394, mean reward: -1.208 [-100.000, 8.506], mean action: 1.845 [0.000, 3.000], mean observation: -0.028 [-3.842, 1.676], loss: 5.866884, mean_absolute_error: 5.114013, mean_q: 1.702514
 60875/100000: episode: 180, duration: 0.943s, episode steps: 166, steps per second: 176, episode reward: -54.358, mean reward: -0.327 [-100.000, 18.346], mean action: 1.934 [0.000, 3.000], mean observation: 0.031 [-1.028, 1.531], loss: 4.019486, mean_absolute_error: 5.180405, mean_q: 1.804810
 61839/100000: episode: 181, duration: 6.383s, episode steps: 964, steps per second: 151, episode reward: -239.519, mean reward: -0.248 [-100.000, 13.587], mean action: 1.596 [0.000, 3.000], mean observation: -0.013 [-1.003, 1.398], loss: 4.181617, mean_absolute_error: 5.217927, mean_q: 2.040563
 62121/100000: episode: 182, duration: 1.707s, episode steps: 282, steps per second: 165, episode reward: -117.181, mean reward: -0.416 [-100.000, 20.832], mean action: 1.968 [0.000, 3.000], mean observation: 0.037 [-0.929, 1.400], loss: 3.526949, mean_absolute_error: 5.325686, mean_q: 2.194742
 62308/100000: episode: 183, duration: 1.051s, episode steps: 187, steps per second: 178, episode reward: -234.726, mean reward: -1.255 [-100.000, 7.122], mean action: 1.759 [0.000, 3.000], mean observation: -0.027 [-2.358, 1.502], loss: 5.757232, mean_absolute_error: 5.417476, mean_q: 2.142405
 62617/100000: episode: 184, duration: 1.825s, episode steps: 309, steps per second: 169, episode reward: -201.392, mean reward: -0.652 [-100.000, 24.357], mean action: 1.867 [0.000, 3.000], mean observation: 0.108 [-1.134, 1.845], loss: 2.706115, mean_absolute_error: 5.492299, mean_q: 2.233248
 62758/100000: episode: 185, duration: 0.800s, episode steps: 141, steps per second: 176, episode reward: -134.401, mean reward: -0.953 [-100.000, 38.351], mean action: 1.993 [0.000, 3.000], mean observation: 0.184 [-3.074, 1.397], loss: 4.296680, mean_absolute_error: 5.489664, mean_q: 2.522866
 62997/100000: episode: 186, duration: 1.385s, episode steps: 239, steps per second: 173, episode reward: -170.865, mean reward: -0.715 [-100.000, 18.456], mean action: 1.791 [0.000, 3.000], mean observation: 0.057 [-1.141, 1.608], loss: 3.243313, mean_absolute_error: 5.560287, mean_q: 2.571554
 63445/100000: episode: 187, duration: 2.947s, episode steps: 448, steps per second: 152, episode reward: -45.048, mean reward: -0.101 [-100.000, 14.249], mean action: 1.830 [0.000, 3.000], mean observation: 0.048 [-1.184, 1.403], loss: 4.202952, mean_absolute_error: 5.732636, mean_q: 2.773688
 63580/100000: episode: 188, duration: 0.759s, episode steps: 135, steps per second: 178, episode reward: -253.502, mean reward: -1.878 [-100.000, 34.390], mean action: 1.904 [0.000, 3.000], mean observation: 0.286 [-1.406, 5.501], loss: 6.695112, mean_absolute_error: 5.835284, mean_q: 2.776104
 63781/100000: episode: 189, duration: 1.116s, episode steps: 201, steps per second: 180, episode reward: -306.005, mean reward: -1.522 [-100.000, 3.909], mean action: 1.841 [0.000, 3.000], mean observation: -0.044 [-2.801, 1.505], loss: 3.542787, mean_absolute_error: 5.772792, mean_q: 2.907382
 64483/100000: episode: 190, duration: 4.538s, episode steps: 702, steps per second: 155, episode reward: 162.904, mean reward: 0.232 [-10.763, 100.000], mean action: 1.489 [0.000, 3.000], mean observation: 0.030 [-0.866, 1.435], loss: 4.999084, mean_absolute_error: 5.889846, mean_q: 2.931699
 64789/100000: episode: 191, duration: 1.827s, episode steps: 306, steps per second: 168, episode reward: -128.460, mean reward: -0.420 [-100.000, 13.591], mean action: 1.732 [0.000, 3.000], mean observation: 0.089 [-2.845, 1.493], loss: 3.224551, mean_absolute_error: 5.899613, mean_q: 3.110093
 64959/100000: episode: 192, duration: 0.957s, episode steps: 170, steps per second: 178, episode reward: -70.598, mean reward: -0.415 [-100.000, 9.437], mean action: 1.924 [0.000, 3.000], mean observation: 0.145 [-1.589, 1.400], loss: 4.466480, mean_absolute_error: 6.068717, mean_q: 2.930143
 65193/100000: episode: 193, duration: 1.350s, episode steps: 234, steps per second: 173, episode reward: -101.909, mean reward: -0.436 [-100.000, 12.062], mean action: 2.038 [0.000, 3.000], mean observation: 0.035 [-1.254, 1.398], loss: 5.469210, mean_absolute_error: 5.974043, mean_q: 3.206075
 65396/100000: episode: 194, duration: 1.134s, episode steps: 203, steps per second: 179, episode reward: -43.446, mean reward: -0.214 [-100.000, 17.948], mean action: 1.901 [0.000, 3.000], mean observation: 0.052 [-1.181, 1.500], loss: 3.570972, mean_absolute_error: 6.061902, mean_q: 3.238486
 65559/100000: episode: 195, duration: 0.914s, episode steps: 163, steps per second: 178, episode reward: -95.531, mean reward: -0.586 [-100.000, 8.156], mean action: 1.975 [0.000, 3.000], mean observation: 0.088 [-1.386, 1.424], loss: 6.944221, mean_absolute_error: 6.094457, mean_q: 3.466058
 65956/100000: episode: 196, duration: 2.358s, episode steps: 397, steps per second: 168, episode reward: -17.805, mean reward: -0.045 [-100.000, 16.731], mean action: 1.695 [0.000, 3.000], mean observation: 0.042 [-1.255, 1.439], loss: 5.263918, mean_absolute_error: 6.216295, mean_q: 3.459252
 66213/100000: episode: 197, duration: 1.456s, episode steps: 257, steps per second: 177, episode reward: -184.387, mean reward: -0.717 [-100.000, 11.591], mean action: 1.837 [0.000, 3.000], mean observation: 0.081 [-1.030, 4.015], loss: 4.366523, mean_absolute_error: 6.182321, mean_q: 3.672399
 66328/100000: episode: 198, duration: 0.630s, episode steps: 115, steps per second: 183, episode reward: -194.163, mean reward: -1.688 [-100.000, 4.857], mean action: 1.774 [0.000, 3.000], mean observation: 0.309 [-0.729, 1.388], loss: 3.543612, mean_absolute_error: 6.222280, mean_q: 3.809273
 66683/100000: episode: 199, duration: 2.184s, episode steps: 355, steps per second: 163, episode reward: -108.731, mean reward: -0.306 [-100.000, 17.700], mean action: 1.808 [0.000, 3.000], mean observation: 0.041 [-1.158, 1.607], loss: 3.715802, mean_absolute_error: 6.282385, mean_q: 3.781513
 67084/100000: episode: 200, duration: 2.518s, episode steps: 401, steps per second: 159, episode reward: -85.237, mean reward: -0.213 [-100.000, 13.627], mean action: 1.746 [0.000, 3.000], mean observation: 0.056 [-0.912, 1.389], loss: 5.265260, mean_absolute_error: 6.324148, mean_q: 3.804324
 67463/100000: episode: 201, duration: 2.309s, episode steps: 379, steps per second: 164, episode reward: -90.574, mean reward: -0.239 [-100.000, 22.282], mean action: 1.639 [0.000, 3.000], mean observation: 0.072 [-1.140, 1.509], loss: 4.701603, mean_absolute_error: 6.404043, mean_q: 4.024817
 67641/100000: episode: 202, duration: 1.010s, episode steps: 178, steps per second: 176, episode reward: -130.398, mean reward: -0.733 [-100.000, 14.072], mean action: 1.876 [0.000, 3.000], mean observation: 0.237 [-1.546, 1.413], loss: 4.866889, mean_absolute_error: 6.562009, mean_q: 4.143667
 68042/100000: episode: 203, duration: 2.537s, episode steps: 401, steps per second: 158, episode reward: -114.796, mean reward: -0.286 [-100.000, 14.386], mean action: 1.778 [0.000, 3.000], mean observation: 0.075 [-2.212, 1.449], loss: 3.883276, mean_absolute_error: 6.509865, mean_q: 4.466805
 68303/100000: episode: 204, duration: 1.481s, episode steps: 261, steps per second: 176, episode reward: -84.137, mean reward: -0.322 [-100.000, 8.771], mean action: 1.801 [0.000, 3.000], mean observation: 0.079 [-1.396, 1.492], loss: 6.319822, mean_absolute_error: 6.622748, mean_q: 4.586000
 68913/100000: episode: 205, duration: 3.733s, episode steps: 610, steps per second: 163, episode reward: -60.964, mean reward: -0.100 [-100.000, 13.764], mean action: 1.630 [0.000, 3.000], mean observation: 0.101 [-1.054, 1.492], loss: 4.955133, mean_absolute_error: 6.696211, mean_q: 4.838145
 69913/100000: episode: 206, duration: 6.797s, episode steps: 1000, steps per second: 147, episode reward: 68.618, mean reward: 0.069 [-19.182, 23.053], mean action: 1.368 [0.000, 3.000], mean observation: 0.096 [-0.761, 1.408], loss: 5.271590, mean_absolute_error: 6.883385, mean_q: 4.914868
 70582/100000: episode: 207, duration: 4.146s, episode steps: 669, steps per second: 161, episode reward: -332.635, mean reward: -0.497 [-100.000, 27.429], mean action: 1.507 [0.000, 3.000], mean observation: 0.035 [-2.643, 1.431], loss: 6.087029, mean_absolute_error: 7.175456, mean_q: 5.211786
 70816/100000: episode: 208, duration: 1.352s, episode steps: 234, steps per second: 173, episode reward: -234.119, mean reward: -1.001 [-100.000, 15.882], mean action: 1.812 [0.000, 3.000], mean observation: 0.140 [-1.039, 3.094], loss: 6.605455, mean_absolute_error: 7.362989, mean_q: 5.260626
 71376/100000: episode: 209, duration: 3.878s, episode steps: 560, steps per second: 144, episode reward: -125.359, mean reward: -0.224 [-100.000, 16.941], mean action: 1.663 [0.000, 3.000], mean observation: 0.128 [-1.701, 1.425], loss: 6.076363, mean_absolute_error: 7.518318, mean_q: 5.408260
 71770/100000: episode: 210, duration: 2.422s, episode steps: 394, steps per second: 163, episode reward: -96.547, mean reward: -0.245 [-100.000, 16.923], mean action: 1.652 [0.000, 3.000], mean observation: 0.165 [-1.858, 1.494], loss: 5.885393, mean_absolute_error: 7.529609, mean_q: 5.766635
 72051/100000: episode: 211, duration: 1.637s, episode steps: 281, steps per second: 172, episode reward: -251.578, mean reward: -0.895 [-100.000, 47.478], mean action: 1.744 [0.000, 3.000], mean observation: 0.149 [-1.059, 2.056], loss: 5.200677, mean_absolute_error: 7.703440, mean_q: 5.775480
 72633/100000: episode: 212, duration: 3.771s, episode steps: 582, steps per second: 154, episode reward: 181.798, mean reward: 0.312 [-11.041, 100.000], mean action: 1.500 [0.000, 3.000], mean observation: 0.112 [-0.745, 1.397], loss: 5.749427, mean_absolute_error: 7.842609, mean_q: 6.029662
 73250/100000: episode: 213, duration: 4.470s, episode steps: 617, steps per second: 138, episode reward: -40.439, mean reward: -0.066 [-100.000, 14.049], mean action: 1.801 [0.000, 3.000], mean observation: 0.098 [-0.809, 1.803], loss: 6.321824, mean_absolute_error: 7.990722, mean_q: 6.547195
 73490/100000: episode: 214, duration: 1.382s, episode steps: 240, steps per second: 174, episode reward: 0.571, mean reward: 0.002 [-100.000, 42.499], mean action: 2.017 [0.000, 3.000], mean observation: 0.102 [-1.276, 1.398], loss: 4.408961, mean_absolute_error: 8.132546, mean_q: 6.899589
 74024/100000: episode: 215, duration: 3.773s, episode steps: 534, steps per second: 142, episode reward: -64.807, mean reward: -0.121 [-100.000, 15.246], mean action: 1.622 [0.000, 3.000], mean observation: 0.056 [-1.060, 1.388], loss: 5.436836, mean_absolute_error: 8.295796, mean_q: 6.927127
 74397/100000: episode: 216, duration: 2.263s, episode steps: 373, steps per second: 165, episode reward: -98.434, mean reward: -0.264 [-100.000, 12.113], mean action: 1.651 [0.000, 3.000], mean observation: 0.094 [-0.896, 1.426], loss: 5.066792, mean_absolute_error: 8.339780, mean_q: 7.232502
 75397/100000: episode: 217, duration: 7.492s, episode steps: 1000, steps per second: 133, episode reward: 75.357, mean reward: 0.075 [-18.346, 23.146], mean action: 1.318 [0.000, 3.000], mean observation: 0.124 [-0.489, 1.392], loss: 6.770389, mean_absolute_error: 8.683635, mean_q: 7.176678
 75691/100000: episode: 218, duration: 1.730s, episode steps: 294, steps per second: 170, episode reward: -86.895, mean reward: -0.296 [-100.000, 15.913], mean action: 1.738 [0.000, 3.000], mean observation: 0.141 [-0.702, 1.396], loss: 7.430393, mean_absolute_error: 8.884692, mean_q: 7.506159
 76310/100000: episode: 219, duration: 3.928s, episode steps: 619, steps per second: 158, episode reward: -69.961, mean reward: -0.113 [-100.000, 15.570], mean action: 1.598 [0.000, 3.000], mean observation: 0.110 [-1.202, 1.525], loss: 6.515829, mean_absolute_error: 8.994798, mean_q: 7.543964
 76955/100000: episode: 220, duration: 4.395s, episode steps: 645, steps per second: 147, episode reward: -85.011, mean reward: -0.132 [-100.000, 9.488], mean action: 1.611 [0.000, 3.000], mean observation: 0.102 [-1.256, 1.401], loss: 5.717853, mean_absolute_error: 9.262845, mean_q: 7.868280
 77733/100000: episode: 221, duration: 5.109s, episode steps: 778, steps per second: 152, episode reward: -130.534, mean reward: -0.168 [-100.000, 14.149], mean action: 1.605 [0.000, 3.000], mean observation: 0.040 [-0.486, 1.405], loss: 6.102471, mean_absolute_error: 9.403701, mean_q: 8.325656
 78322/100000: episode: 222, duration: 4.060s, episode steps: 589, steps per second: 145, episode reward: -136.309, mean reward: -0.231 [-100.000, 15.342], mean action: 1.553 [0.000, 3.000], mean observation: 0.054 [-1.057, 1.407], loss: 5.289975, mean_absolute_error: 9.562851, mean_q: 8.635397
 79322/100000: episode: 223, duration: 6.992s, episode steps: 1000, steps per second: 143, episode reward: 52.043, mean reward: 0.052 [-11.398, 13.874], mean action: 1.517 [0.000, 3.000], mean observation: 0.086 [-0.462, 1.548], loss: 6.370112, mean_absolute_error: 9.833560, mean_q: 9.015492
 80322/100000: episode: 224, duration: 7.224s, episode steps: 1000, steps per second: 138, episode reward: 76.563, mean reward: 0.077 [-23.859, 23.200], mean action: 1.411 [0.000, 3.000], mean observation: 0.138 [-0.502, 1.478], loss: 5.560996, mean_absolute_error: 10.179121, mean_q: 9.629660
 80782/100000: episode: 225, duration: 2.995s, episode steps: 460, steps per second: 154, episode reward: -98.276, mean reward: -0.214 [-100.000, 14.904], mean action: 1.793 [0.000, 3.000], mean observation: 0.130 [-1.126, 1.400], loss: 6.231629, mean_absolute_error: 10.469499, mean_q: 9.963514
 81782/100000: episode: 226, duration: 7.196s, episode steps: 1000, steps per second: 139, episode reward: 52.606, mean reward: 0.053 [-23.603, 26.224], mean action: 1.332 [0.000, 3.000], mean observation: 0.150 [-0.588, 1.408], loss: 5.428951, mean_absolute_error: 10.683931, mean_q: 10.164370
 82782/100000: episode: 227, duration: 7.438s, episode steps: 1000, steps per second: 134, episode reward: -59.505, mean reward: -0.060 [-3.881, 5.796], mean action: 1.534 [0.000, 3.000], mean observation: 0.143 [-0.457, 1.477], loss: 6.648597, mean_absolute_error: 10.934643, mean_q: 10.592723
 83782/100000: episode: 228, duration: 6.941s, episode steps: 1000, steps per second: 144, episode reward: 74.313, mean reward: 0.074 [-18.180, 23.187], mean action: 1.276 [0.000, 3.000], mean observation: 0.127 [-0.629, 1.429], loss: 5.401444, mean_absolute_error: 11.284474, mean_q: 10.968166
 84782/100000: episode: 229, duration: 7.173s, episode steps: 1000, steps per second: 139, episode reward: 26.854, mean reward: 0.027 [-3.866, 11.363], mean action: 1.680 [0.000, 3.000], mean observation: 0.125 [-0.410, 1.446], loss: 6.202092, mean_absolute_error: 11.591043, mean_q: 11.377491
 85359/100000: episode: 230, duration: 3.923s, episode steps: 577, steps per second: 147, episode reward: -27.930, mean reward: -0.048 [-100.000, 15.155], mean action: 1.745 [0.000, 3.000], mean observation: 0.078 [-0.937, 1.532], loss: 7.035203, mean_absolute_error: 11.802716, mean_q: 11.694221
 85611/100000: episode: 231, duration: 1.458s, episode steps: 252, steps per second: 173, episode reward: -44.999, mean reward: -0.179 [-100.000, 15.630], mean action: 1.861 [0.000, 3.000], mean observation: 0.081 [-1.322, 1.507], loss: 6.275127, mean_absolute_error: 11.919759, mean_q: 12.194871
 86095/100000: episode: 232, duration: 3.089s, episode steps: 484, steps per second: 157, episode reward: -43.747, mean reward: -0.090 [-100.000, 15.092], mean action: 1.674 [0.000, 3.000], mean observation: 0.122 [-1.127, 1.393], loss: 8.661185, mean_absolute_error: 11.984596, mean_q: 12.170343
 87095/100000: episode: 233, duration: 8.154s, episode steps: 1000, steps per second: 123, episode reward: -72.911, mean reward: -0.073 [-3.949, 4.271], mean action: 1.487 [0.000, 3.000], mean observation: 0.100 [-0.322, 1.426], loss: 6.884915, mean_absolute_error: 12.075159, mean_q: 12.712380
 88095/100000: episode: 234, duration: 7.510s, episode steps: 1000, steps per second: 133, episode reward: 93.941, mean reward: 0.094 [-23.508, 17.571], mean action: 1.442 [0.000, 3.000], mean observation: 0.162 [-0.894, 1.495], loss: 6.604553, mean_absolute_error: 12.349811, mean_q: 13.270686
 89095/100000: episode: 235, duration: 7.617s, episode steps: 1000, steps per second: 131, episode reward: -77.182, mean reward: -0.077 [-3.559, 4.207], mean action: 1.528 [0.000, 3.000], mean observation: 0.128 [-0.501, 1.388], loss: 7.096506, mean_absolute_error: 12.470009, mean_q: 13.518285
 90095/100000: episode: 236, duration: 7.048s, episode steps: 1000, steps per second: 142, episode reward: -52.763, mean reward: -0.053 [-4.267, 3.775], mean action: 1.506 [0.000, 3.000], mean observation: 0.104 [-0.384, 1.449], loss: 4.697298, mean_absolute_error: 12.826839, mean_q: 14.175403
 90940/100000: episode: 237, duration: 5.743s, episode steps: 845, steps per second: 147, episode reward: 177.605, mean reward: 0.210 [-19.923, 100.000], mean action: 1.272 [0.000, 3.000], mean observation: 0.141 [-0.691, 1.387], loss: 5.990143, mean_absolute_error: 13.065608, mean_q: 14.295190
 91552/100000: episode: 238, duration: 4.246s, episode steps: 612, steps per second: 144, episode reward: 221.301, mean reward: 0.362 [-18.663, 100.000], mean action: 1.243 [0.000, 3.000], mean observation: 0.130 [-0.968, 1.401], loss: 6.146264, mean_absolute_error: 13.121575, mean_q: 14.490557
 92503/100000: episode: 239, duration: 7.440s, episode steps: 951, steps per second: 128, episode reward: -185.120, mean reward: -0.195 [-100.000, 10.293], mean action: 1.755 [0.000, 3.000], mean observation: 0.136 [-0.452, 1.397], loss: 6.310174, mean_absolute_error: 13.522318, mean_q: 15.061868
 93503/100000: episode: 240, duration: 7.037s, episode steps: 1000, steps per second: 142, episode reward: -111.271, mean reward: -0.111 [-3.615, 4.751], mean action: 1.531 [0.000, 3.000], mean observation: 0.146 [-0.398, 1.426], loss: 7.670017, mean_absolute_error: 13.875424, mean_q: 15.252559
 94503/100000: episode: 241, duration: 8.567s, episode steps: 1000, steps per second: 117, episode reward: -83.759, mean reward: -0.084 [-4.130, 4.692], mean action: 1.436 [0.000, 3.000], mean observation: 0.111 [-0.283, 1.397], loss: 5.838986, mean_absolute_error: 14.023858, mean_q: 15.651916
 95503/100000: episode: 242, duration: 7.830s, episode steps: 1000, steps per second: 128, episode reward: -119.107, mean reward: -0.119 [-4.298, 4.270], mean action: 1.552 [0.000, 3.000], mean observation: 0.135 [-0.398, 1.397], loss: 7.658455, mean_absolute_error: 14.316568, mean_q: 15.726053
 96503/100000: episode: 243, duration: 6.852s, episode steps: 1000, steps per second: 146, episode reward: -90.531, mean reward: -0.091 [-4.622, 3.886], mean action: 1.757 [0.000, 3.000], mean observation: 0.130 [-0.483, 1.402], loss: 5.831259, mean_absolute_error: 14.550336, mean_q: 16.331995
 97425/100000: episode: 244, duration: 5.996s, episode steps: 922, steps per second: 154, episode reward: -170.102, mean reward: -0.184 [-100.000, 23.083], mean action: 1.711 [0.000, 3.000], mean observation: 0.193 [-0.674, 1.394], loss: 5.303855, mean_absolute_error: 14.837045, mean_q: 16.739174
 98425/100000: episode: 245, duration: 6.746s, episode steps: 1000, steps per second: 148, episode reward: -97.653, mean reward: -0.098 [-4.505, 4.595], mean action: 1.716 [0.000, 3.000], mean observation: 0.135 [-0.475, 1.432], loss: 8.037268, mean_absolute_error: 15.051863, mean_q: 17.146820
 99425/100000: episode: 246, duration: 7.986s, episode steps: 1000, steps per second: 125, episode reward: -89.094, mean reward: -0.089 [-4.845, 4.316], mean action: 1.669 [0.000, 3.000], mean observation: 0.206 [-0.360, 1.411], loss: 6.439528, mean_absolute_error: 15.014941, mean_q: 17.430836
done, took 683.986 seconds
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-Result">Evaluation Result<a class="anchor-link" href="#Evaluation-Result">&#182;</a></h2><p>We are testing the above model for 50 episodes and then looking at the mean reward value</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Finally, evaluate our algorithm for 50 episodes.</span>

<span class="c1">#dqn2.test(env, nb_episodes=50, visualize=False)</span>

<span class="c1"># Finally, evaluate the agent</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">dqn2</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;episode_reward&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Test rewards (#episodes=</span><span class="si">{}</span><span class="s2">): mean=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, std=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, &quot;</span>
           <span class="s2">&quot;min=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, max=</span><span class="si">{:&gt;5.2f}</span><span class="s2">&quot;</span><span class="p">)</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>

<span class="n">rl_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Testing for 50 episodes ...
Episode 1: reward: -124.292, steps: 1000
Episode 2: reward: -128.521, steps: 1000
Episode 3: reward: -149.815, steps: 1000
Episode 4: reward: -111.980, steps: 1000
Episode 5: reward: -130.389, steps: 1000
Episode 6: reward: -159.117, steps: 1000
Episode 7: reward: -55.007, steps: 1000
Episode 8: reward: -181.105, steps: 855
Episode 9: reward: -136.369, steps: 1000
Episode 10: reward: -154.247, steps: 1000
Episode 11: reward: -162.554, steps: 1000
Episode 12: reward: -111.477, steps: 1000
Episode 13: reward: -88.013, steps: 1000
Episode 14: reward: -146.472, steps: 1000
Episode 15: reward: -68.793, steps: 1000
Episode 16: reward: -134.974, steps: 1000
Episode 17: reward: -112.135, steps: 1000
Episode 18: reward: -124.836, steps: 1000
Episode 19: reward: -126.504, steps: 1000
Episode 20: reward: -166.332, steps: 1000
Episode 21: reward: -82.429, steps: 1000
Episode 22: reward: -110.298, steps: 1000
Episode 23: reward: -161.058, steps: 741
Episode 24: reward: -105.822, steps: 1000
Episode 25: reward: -98.374, steps: 1000
Episode 26: reward: -125.891, steps: 1000
Episode 27: reward: -120.507, steps: 1000
Episode 28: reward: -112.063, steps: 1000
Episode 29: reward: -122.309, steps: 1000
Episode 30: reward: -208.239, steps: 974
Episode 31: reward: -137.720, steps: 1000
Episode 32: reward: -120.857, steps: 1000
Episode 33: reward: -100.614, steps: 1000
Episode 34: reward: -123.986, steps: 1000
Episode 35: reward: -88.754, steps: 1000
Episode 36: reward: -136.860, steps: 1000
Episode 37: reward: -141.733, steps: 1000
Episode 38: reward: -167.395, steps: 1000
Episode 39: reward: -126.314, steps: 1000
Episode 40: reward: -107.395, steps: 1000
Episode 41: reward: -100.090, steps: 1000
Episode 42: reward: -140.787, steps: 1000
Episode 43: reward: -112.282, steps: 1000
Episode 44: reward: -137.015, steps: 1000
Episode 45: reward: -103.668, steps: 1000
Episode 46: reward: -107.523, steps: 1000
Episode 47: reward: -149.967, steps: 1000
Episode 48: reward: -94.733, steps: 1000
Episode 49: reward: -129.840, steps: 1000
Episode 50: reward: -134.059, steps: 1000
Test rewards (#episodes=50): mean=-125.63, std=28.03, min=-208.24, max=-55.01
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-3">Model 3<a class="anchor-link" href="#Model-3">&#182;</a></h2><p><b> Model Architecture</b></p>
<p>We are using the similar architecture and process as <a href="#task2_model1">Model 1</a> but with different hyper-parameters <br/> 
<b>In this Model, we are changing value of learning rate of Adam optimizer to 0.001 and epsilon to 0.1</b></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get the environment and extract the number of actions.</span>
<span class="c1">#env = gym.make(ENV_NAME)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">nb_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Next, we build a very simple model.</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">))</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model3</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="c1"># Finally, we configure and compile our agent. You can use every built-in Keras optimizer and</span>
<span class="c1"># even the metrics!</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">SequentialMemory</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">window_length</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">EpsGreedyQPolicy</span><span class="p">()</span>
<span class="n">dqn3</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model3</span><span class="p">,</span> <span class="n">nb_actions</span><span class="o">=</span><span class="n">nb_actions</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="n">nb_steps_warmup</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
               <span class="n">target_model_update</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">)</span>
<span class="n">dqn3</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mae&#39;</span><span class="p">])</span>

<span class="c1"># Okay, now it&#39;s time to learn something! We visualize the training here for show, but this</span>
<span class="c1"># slows down training quite a lot. You can always safely abort the training prematurely using</span>
<span class="c1"># Ctrl + C.</span>
<span class="n">start</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">dqn3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_steps</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">timetaken</span><span class="o">=</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
<span class="n">rl_model_time_comparisons</span><span class="p">[</span><span class="s1">&#39;Model 3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">timetaken</span>
<span class="c1"># After training is done, we save the final weights.</span>
<span class="n">dqn3</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;dqn_</span><span class="si">{}</span><span class="s1">_weights_model3.h5f&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ENV_NAME</span><span class="p">),</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_3 (Flatten)          (None, 8)                 0         
_________________________________________________________________
dense_9 (Dense)              (None, 16)                144       
_________________________________________________________________
activation_9 (Activation)    (None, 16)                0         
_________________________________________________________________
dense_10 (Dense)             (None, 16)                272       
_________________________________________________________________
activation_10 (Activation)   (None, 16)                0         
_________________________________________________________________
dense_11 (Dense)             (None, 16)                272       
_________________________________________________________________
activation_11 (Activation)   (None, 16)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 4)                 68        
_________________________________________________________________
activation_12 (Activation)   (None, 4)                 0         
=================================================================
Total params: 756
Trainable params: 756
Non-trainable params: 0
_________________________________________________________________
None
Training for 100000 steps ...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/anaconda3/lib/python3.6/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!
  warnings.warn(&#39;Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!&#39;)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   100/100000: episode: 1, duration: 2.089s, episode steps: 100, steps per second: 48, episode reward: -426.740, mean reward: -4.267 [-100.000, 36.449], mean action: 1.320 [0.000, 3.000], mean observation: 0.129 [-1.482, 3.255], loss: 7.285984, mean_absolute_error: 0.768169, mean_q: 0.135859
   192/100000: episode: 2, duration: 0.495s, episode steps: 92, steps per second: 186, episode reward: 15.020, mean reward: 0.163 [-100.000, 130.422], mean action: 0.152 [0.000, 3.000], mean observation: 0.006 [-1.701, 2.188], loss: 56.370140, mean_absolute_error: 1.537257, mean_q: -0.057817
   277/100000: episode: 3, duration: 0.452s, episode steps: 85, steps per second: 188, episode reward: -136.845, mean reward: -1.610 [-100.000, 13.186], mean action: 0.082 [0.000, 3.000], mean observation: 0.109 [-1.729, 5.046], loss: 82.552452, mean_absolute_error: 2.254117, mean_q: -0.313259
   338/100000: episode: 4, duration: 0.333s, episode steps: 61, steps per second: 183, episode reward: -102.065, mean reward: -1.673 [-100.000, 18.179], mean action: 0.115 [0.000, 3.000], mean observation: -0.016 [-1.839, 1.400], loss: 89.166130, mean_absolute_error: 2.716983, mean_q: -0.104383
   397/100000: episode: 5, duration: 0.325s, episode steps: 59, steps per second: 182, episode reward: -201.190, mean reward: -3.410 [-100.000, 2.253], mean action: 1.085 [0.000, 3.000], mean observation: 0.057 [-1.831, 4.041], loss: 86.098839, mean_absolute_error: 2.835973, mean_q: 0.292144
   461/100000: episode: 6, duration: 0.340s, episode steps: 64, steps per second: 188, episode reward: -123.522, mean reward: -1.930 [-100.000, 7.235], mean action: 0.203 [0.000, 3.000], mean observation: 0.036 [-1.804, 6.117], loss: 77.736862, mean_absolute_error: 2.642088, mean_q: 0.036160
   574/100000: episode: 7, duration: 0.626s, episode steps: 113, steps per second: 180, episode reward: -387.798, mean reward: -3.432 [-100.000, 4.572], mean action: 1.177 [0.000, 3.000], mean observation: 0.246 [-3.407, 1.848], loss: 69.352364, mean_absolute_error: 2.892924, mean_q: -0.383478
   655/100000: episode: 8, duration: 0.451s, episode steps: 81, steps per second: 179, episode reward: -750.617, mean reward: -9.267 [-100.000, 0.920], mean action: 1.025 [0.000, 3.000], mean observation: 0.404 [-4.336, 6.168], loss: 73.335960, mean_absolute_error: 4.298668, mean_q: -1.437383
   761/100000: episode: 9, duration: 0.563s, episode steps: 106, steps per second: 188, episode reward: -89.332, mean reward: -0.843 [-100.000, 60.301], mean action: 0.585 [0.000, 3.000], mean observation: 0.175 [-1.370, 3.755], loss: 59.307713, mean_absolute_error: 5.708951, mean_q: -3.868017
   845/100000: episode: 10, duration: 0.445s, episode steps: 84, steps per second: 189, episode reward: -137.363, mean reward: -1.635 [-100.000, 8.579], mean action: 0.167 [0.000, 2.000], mean observation: 0.067 [-6.198, 1.448], loss: 53.210308, mean_absolute_error: 6.079564, mean_q: -4.882594
   927/100000: episode: 11, duration: 0.431s, episode steps: 82, steps per second: 190, episode reward: -186.167, mean reward: -2.270 [-100.000, 5.844], mean action: 0.195 [0.000, 3.000], mean observation: -0.098 [-6.041, 1.419], loss: 66.158813, mean_absolute_error: 7.121297, mean_q: -5.796024
  1018/100000: episode: 12, duration: 0.485s, episode steps: 91, steps per second: 188, episode reward: -158.919, mean reward: -1.746 [-100.000, 6.729], mean action: 0.143 [0.000, 3.000], mean observation: -0.017 [-3.802, 1.516], loss: 53.018173, mean_absolute_error: 7.822955, mean_q: -6.355954
  1093/100000: episode: 13, duration: 0.423s, episode steps: 75, steps per second: 177, episode reward: -123.250, mean reward: -1.643 [-100.000, 14.622], mean action: 0.107 [0.000, 3.000], mean observation: -0.003 [-1.814, 1.420], loss: 45.269184, mean_absolute_error: 8.043222, mean_q: -6.993055
  1175/100000: episode: 14, duration: 0.448s, episode steps: 82, steps per second: 183, episode reward: -99.108, mean reward: -1.209 [-100.000, 12.494], mean action: 0.195 [0.000, 3.000], mean observation: 0.011 [-1.683, 1.431], loss: 48.819424, mean_absolute_error: 8.641807, mean_q: -7.719529
  1243/100000: episode: 15, duration: 0.366s, episode steps: 68, steps per second: 186, episode reward: -227.913, mean reward: -3.352 [-100.000, 4.992], mean action: 0.574 [0.000, 3.000], mean observation: 0.214 [-1.714, 7.346], loss: 57.629932, mean_absolute_error: 9.670111, mean_q: -8.885226
  1315/100000: episode: 16, duration: 0.392s, episode steps: 72, steps per second: 184, episode reward: -141.828, mean reward: -1.970 [-100.000, 9.655], mean action: 0.167 [0.000, 3.000], mean observation: 0.012 [-1.783, 6.193], loss: 30.653568, mean_absolute_error: 9.905499, mean_q: -9.020989
  1368/100000: episode: 17, duration: 0.283s, episode steps: 53, steps per second: 187, episode reward: -100.251, mean reward: -1.892 [-100.000, 9.473], mean action: 0.057 [0.000, 2.000], mean observation: -0.027 [-1.883, 1.387], loss: 52.737740, mean_absolute_error: 10.329674, mean_q: -9.887527
  1429/100000: episode: 18, duration: 0.319s, episode steps: 61, steps per second: 191, episode reward: -147.287, mean reward: -2.415 [-100.000, 5.911], mean action: 0.148 [0.000, 3.000], mean observation: -0.055 [-1.853, 1.397], loss: 58.303055, mean_absolute_error: 10.889544, mean_q: -10.975442
  1516/100000: episode: 19, duration: 0.459s, episode steps: 87, steps per second: 190, episode reward: -217.542, mean reward: -2.500 [-100.000, 6.384], mean action: 0.172 [0.000, 3.000], mean observation: 0.017 [-1.801, 8.258], loss: 37.695732, mean_absolute_error: 11.102585, mean_q: -11.417349
  1572/100000: episode: 20, duration: 0.296s, episode steps: 56, steps per second: 189, episode reward: -78.599, mean reward: -1.404 [-100.000, 10.643], mean action: 0.250 [0.000, 2.000], mean observation: -0.007 [-1.794, 1.387], loss: 43.559780, mean_absolute_error: 12.558545, mean_q: -12.975066
  1646/100000: episode: 21, duration: 0.391s, episode steps: 74, steps per second: 189, episode reward: -151.904, mean reward: -2.053 [-100.000, 39.798], mean action: 0.095 [0.000, 2.000], mean observation: -0.019 [-2.493, 1.417], loss: 36.221001, mean_absolute_error: 12.575675, mean_q: -12.995601
  1726/100000: episode: 22, duration: 0.433s, episode steps: 80, steps per second: 185, episode reward: -280.631, mean reward: -3.508 [-100.000, 1.372], mean action: 0.350 [0.000, 3.000], mean observation: 0.200 [-1.851, 1.555], loss: 31.979895, mean_absolute_error: 13.044690, mean_q: -13.985666
  1817/100000: episode: 23, duration: 0.498s, episode steps: 91, steps per second: 183, episode reward: -432.991, mean reward: -4.758 [-100.000, 123.431], mean action: 0.473 [0.000, 3.000], mean observation: 0.240 [-1.717, 4.490], loss: 34.159443, mean_absolute_error: 13.990264, mean_q: -15.420136
  1896/100000: episode: 24, duration: 0.425s, episode steps: 79, steps per second: 186, episode reward: -232.615, mean reward: -2.944 [-100.000, 6.880], mean action: 0.215 [0.000, 3.000], mean observation: 0.094 [-1.762, 7.699], loss: 32.813595, mean_absolute_error: 14.533398, mean_q: -16.177616
  1970/100000: episode: 25, duration: 0.407s, episode steps: 74, steps per second: 182, episode reward: -234.440, mean reward: -3.168 [-100.000, 6.037], mean action: 0.284 [0.000, 3.000], mean observation: -0.001 [-1.823, 5.120], loss: 35.894947, mean_absolute_error: 15.445769, mean_q: -17.302990
  2024/100000: episode: 26, duration: 0.292s, episode steps: 54, steps per second: 185, episode reward: -178.025, mean reward: -3.297 [-100.000, 5.833], mean action: 0.167 [0.000, 2.000], mean observation: -0.044 [-5.210, 1.388], loss: 29.936218, mean_absolute_error: 15.874327, mean_q: -17.731022
  2081/100000: episode: 27, duration: 0.317s, episode steps: 57, steps per second: 180, episode reward: -183.631, mean reward: -3.222 [-100.000, 90.877], mean action: 0.561 [0.000, 3.000], mean observation: 0.097 [-1.831, 3.561], loss: 30.303873, mean_absolute_error: 16.999046, mean_q: -19.437492
  2174/100000: episode: 28, duration: 0.524s, episode steps: 93, steps per second: 178, episode reward: -129.290, mean reward: -1.390 [-100.000, 13.351], mean action: 1.495 [0.000, 3.000], mean observation: 0.164 [-1.770, 1.505], loss: 38.095009, mean_absolute_error: 17.315613, mean_q: -19.959579
  2278/100000: episode: 29, duration: 0.575s, episode steps: 104, steps per second: 181, episode reward: -130.431, mean reward: -1.254 [-100.000, 6.752], mean action: 0.885 [0.000, 3.000], mean observation: 0.003 [-1.829, 1.539], loss: 22.781019, mean_absolute_error: 18.434752, mean_q: -21.812496
  2348/100000: episode: 30, duration: 0.385s, episode steps: 70, steps per second: 182, episode reward: -157.980, mean reward: -2.257 [-100.000, 12.443], mean action: 1.471 [0.000, 3.000], mean observation: -0.088 [-1.692, 4.737], loss: 24.335604, mean_absolute_error: 17.715227, mean_q: -20.583763
  2424/100000: episode: 31, duration: 0.433s, episode steps: 76, steps per second: 176, episode reward: -222.597, mean reward: -2.929 [-100.000, 6.289], mean action: 1.250 [0.000, 3.000], mean observation: 0.161 [-1.839, 4.168], loss: 29.643311, mean_absolute_error: 17.841946, mean_q: -20.829298
  2516/100000: episode: 32, duration: 0.515s, episode steps: 92, steps per second: 179, episode reward: -229.895, mean reward: -2.499 [-100.000, 14.882], mean action: 1.022 [0.000, 3.000], mean observation: 0.110 [-1.761, 5.272], loss: 34.023937, mean_absolute_error: 19.642078, mean_q: -22.839199
  2590/100000: episode: 33, duration: 0.413s, episode steps: 74, steps per second: 179, episode reward: -137.401, mean reward: -1.857 [-100.000, 7.188], mean action: 1.419 [0.000, 3.000], mean observation: -0.040 [-5.965, 1.421], loss: 22.215099, mean_absolute_error: 20.415436, mean_q: -24.518059
  2669/100000: episode: 34, duration: 0.446s, episode steps: 79, steps per second: 177, episode reward: -128.334, mean reward: -1.624 [-100.000, 8.323], mean action: 1.582 [0.000, 3.000], mean observation: -0.093 [-1.662, 5.232], loss: 29.428059, mean_absolute_error: 19.835709, mean_q: -23.378366
  2732/100000: episode: 35, duration: 0.362s, episode steps: 63, steps per second: 174, episode reward: -118.957, mean reward: -1.888 [-100.000, 10.768], mean action: 2.016 [0.000, 3.000], mean observation: 0.076 [-2.601, 1.400], loss: 26.812803, mean_absolute_error: 19.708044, mean_q: -23.444372
  2810/100000: episode: 36, duration: 0.449s, episode steps: 78, steps per second: 174, episode reward: -119.184, mean reward: -1.528 [-100.000, 54.306], mean action: 1.538 [0.000, 3.000], mean observation: 0.170 [-2.746, 1.417], loss: 19.569475, mean_absolute_error: 19.654110, mean_q: -23.726179
  2863/100000: episode: 37, duration: 0.307s, episode steps: 53, steps per second: 173, episode reward: -76.172, mean reward: -1.437 [-100.000, 12.746], mean action: 1.113 [0.000, 3.000], mean observation: -0.111 [-1.788, 1.385], loss: 25.389118, mean_absolute_error: 20.116581, mean_q: -24.223001
  2954/100000: episode: 38, duration: 0.539s, episode steps: 91, steps per second: 169, episode reward: -89.231, mean reward: -0.981 [-100.000, 11.601], mean action: 1.626 [0.000, 3.000], mean observation: -0.074 [-1.733, 1.492], loss: 30.775917, mean_absolute_error: 20.534843, mean_q: -24.839298
  3033/100000: episode: 39, duration: 0.458s, episode steps: 79, steps per second: 173, episode reward: -173.412, mean reward: -2.195 [-100.000, 6.207], mean action: 1.266 [0.000, 3.000], mean observation: 0.064 [-4.620, 1.574], loss: 33.630268, mean_absolute_error: 21.504660, mean_q: -25.778433
  3104/100000: episode: 40, duration: 0.408s, episode steps: 71, steps per second: 174, episode reward: -142.896, mean reward: -2.013 [-100.000, 6.014], mean action: 1.380 [0.000, 3.000], mean observation: 0.063 [-1.768, 1.409], loss: 27.731464, mean_absolute_error: 21.438578, mean_q: -25.547384
  3156/100000: episode: 41, duration: 0.309s, episode steps: 52, steps per second: 168, episode reward: -73.770, mean reward: -1.419 [-100.000, 17.352], mean action: 1.115 [0.000, 3.000], mean observation: -0.030 [-1.849, 1.385], loss: 24.408293, mean_absolute_error: 21.426064, mean_q: -25.355021
  3246/100000: episode: 42, duration: 0.545s, episode steps: 90, steps per second: 165, episode reward: -157.137, mean reward: -1.746 [-100.000, 10.425], mean action: 1.522 [0.000, 3.000], mean observation: 0.043 [-1.667, 1.481], loss: 22.365396, mean_absolute_error: 21.771252, mean_q: -25.976788
  3327/100000: episode: 43, duration: 0.489s, episode steps: 81, steps per second: 166, episode reward: -148.936, mean reward: -1.839 [-100.000, 20.823], mean action: 2.111 [0.000, 3.000], mean observation: 0.016 [-1.676, 2.599], loss: 25.312069, mean_absolute_error: 21.722637, mean_q: -26.043243
  3418/100000: episode: 44, duration: 0.543s, episode steps: 91, steps per second: 168, episode reward: -452.677, mean reward: -4.974 [-100.000, 58.871], mean action: 1.440 [0.000, 3.000], mean observation: -0.131 [-3.063, 1.398], loss: 23.699682, mean_absolute_error: 21.369625, mean_q: -25.495163
  3520/100000: episode: 45, duration: 0.607s, episode steps: 102, steps per second: 168, episode reward: -260.725, mean reward: -2.556 [-100.000, 12.019], mean action: 1.696 [0.000, 3.000], mean observation: -0.026 [-1.682, 5.828], loss: 31.636335, mean_absolute_error: 22.430113, mean_q: -27.027363
  3578/100000: episode: 46, duration: 0.322s, episode steps: 58, steps per second: 180, episode reward: -99.838, mean reward: -1.721 [-100.000, 19.175], mean action: 1.172 [0.000, 3.000], mean observation: 0.007 [-1.832, 1.394], loss: 35.805595, mean_absolute_error: 22.051970, mean_q: -26.475548
  3647/100000: episode: 47, duration: 0.402s, episode steps: 69, steps per second: 171, episode reward: -144.941, mean reward: -2.101 [-100.000, 16.724], mean action: 1.290 [0.000, 3.000], mean observation: 0.164 [-1.440, 5.228], loss: 21.713205, mean_absolute_error: 22.600386, mean_q: -27.458296
  3716/100000: episode: 48, duration: 0.413s, episode steps: 69, steps per second: 167, episode reward: -138.378, mean reward: -2.005 [-100.000, 44.512], mean action: 2.145 [0.000, 3.000], mean observation: 0.049 [-3.883, 1.404], loss: 23.883112, mean_absolute_error: 23.253799, mean_q: -28.252575
  3796/100000: episode: 49, duration: 0.467s, episode steps: 80, steps per second: 171, episode reward: -536.775, mean reward: -6.710 [-100.000, 0.799], mean action: 2.038 [1.000, 3.000], mean observation: -0.229 [-3.689, 5.274], loss: 30.277639, mean_absolute_error: 23.362782, mean_q: -27.686970
  3887/100000: episode: 50, duration: 0.564s, episode steps: 91, steps per second: 161, episode reward: -222.999, mean reward: -2.451 [-100.000, 21.762], mean action: 1.626 [0.000, 3.000], mean observation: -0.139 [-3.668, 1.407], loss: 30.750097, mean_absolute_error: 23.773228, mean_q: -28.880342
  3969/100000: episode: 51, duration: 0.463s, episode steps: 82, steps per second: 177, episode reward: -165.668, mean reward: -2.020 [-100.000, 25.012], mean action: 1.427 [0.000, 3.000], mean observation: -0.195 [-4.937, 1.420], loss: 28.604095, mean_absolute_error: 24.205000, mean_q: -29.555197
  4061/100000: episode: 52, duration: 0.579s, episode steps: 92, steps per second: 159, episode reward: -326.687, mean reward: -3.551 [-100.000, 1.682], mean action: 1.402 [0.000, 3.000], mean observation: 0.148 [-4.522, 1.915], loss: 13.374709, mean_absolute_error: 25.145502, mean_q: -31.047419
  4136/100000: episode: 53, duration: 0.510s, episode steps: 75, steps per second: 147, episode reward: -181.658, mean reward: -2.422 [-100.000, 26.503], mean action: 2.067 [0.000, 3.000], mean observation: -0.086 [-4.486, 1.391], loss: 19.859270, mean_absolute_error: 25.398945, mean_q: -31.238548
  4207/100000: episode: 54, duration: 0.410s, episode steps: 71, steps per second: 173, episode reward: -142.362, mean reward: -2.005 [-100.000, 24.526], mean action: 1.085 [0.000, 3.000], mean observation: 0.052 [-1.607, 6.126], loss: 19.977402, mean_absolute_error: 26.802361, mean_q: -32.952312
  4283/100000: episode: 55, duration: 0.466s, episode steps: 76, steps per second: 163, episode reward: -349.440, mean reward: -4.598 [-100.000, 1.644], mean action: 2.079 [0.000, 3.000], mean observation: -0.294 [-2.470, 4.228], loss: 28.795141, mean_absolute_error: 26.623053, mean_q: -32.583855
  4334/100000: episode: 56, duration: 0.316s, episode steps: 51, steps per second: 162, episode reward: -338.679, mean reward: -6.641 [-100.000, 0.323], mean action: 1.039 [0.000, 3.000], mean observation: 0.209 [-2.014, 2.343], loss: 39.308102, mean_absolute_error: 28.194614, mean_q: -34.076946
  4394/100000: episode: 57, duration: 0.345s, episode steps: 60, steps per second: 174, episode reward: -294.513, mean reward: -4.909 [-100.000, 7.870], mean action: 1.400 [0.000, 3.000], mean observation: 0.126 [-1.717, 1.980], loss: 24.069763, mean_absolute_error: 28.583464, mean_q: -35.172279
  4453/100000: episode: 58, duration: 0.328s, episode steps: 59, steps per second: 180, episode reward: -132.806, mean reward: -2.251 [-100.000, 13.834], mean action: 1.322 [0.000, 3.000], mean observation: -0.178 [-1.603, 3.880], loss: 36.040363, mean_absolute_error: 29.118935, mean_q: -35.948257
  4583/100000: episode: 59, duration: 0.735s, episode steps: 130, steps per second: 177, episode reward: -122.788, mean reward: -0.945 [-100.000, 8.095], mean action: 1.600 [0.000, 3.000], mean observation: 0.129 [-1.637, 1.501], loss: 19.784435, mean_absolute_error: 29.491381, mean_q: -36.647778
  4786/100000: episode: 60, duration: 1.226s, episode steps: 203, steps per second: 166, episode reward: -105.689, mean reward: -0.521 [-100.000, 4.393], mean action: 2.074 [0.000, 3.000], mean observation: 0.098 [-1.195, 2.948], loss: 23.231813, mean_absolute_error: 29.240084, mean_q: -36.111443
  4977/100000: episode: 61, duration: 1.200s, episode steps: 191, steps per second: 159, episode reward: -116.445, mean reward: -0.610 [-100.000, 8.461], mean action: 1.660 [0.000, 3.000], mean observation: 0.099 [-1.357, 4.230], loss: 28.825472, mean_absolute_error: 30.303082, mean_q: -37.628220
  5113/100000: episode: 62, duration: 0.818s, episode steps: 136, steps per second: 166, episode reward: -19.238, mean reward: -0.141 [-100.000, 23.403], mean action: 1.713 [0.000, 3.000], mean observation: 0.098 [-2.463, 1.539], loss: 18.387230, mean_absolute_error: 31.516989, mean_q: -39.077499
  5402/100000: episode: 63, duration: 1.908s, episode steps: 289, steps per second: 151, episode reward: -121.747, mean reward: -0.421 [-100.000, 5.867], mean action: 1.900 [0.000, 3.000], mean observation: 0.137 [-1.026, 1.388], loss: 24.860727, mean_absolute_error: 31.290434, mean_q: -38.711952
  5589/100000: episode: 64, duration: 1.104s, episode steps: 187, steps per second: 169, episode reward: -334.510, mean reward: -1.789 [-100.000, 7.010], mean action: 1.941 [0.000, 3.000], mean observation: 0.248 [-0.744, 2.011], loss: 23.299786, mean_absolute_error: 31.673918, mean_q: -38.901112
  6017/100000: episode: 65, duration: 3.027s, episode steps: 428, steps per second: 141, episode reward: -316.136, mean reward: -0.739 [-100.000, 14.942], mean action: 1.839 [0.000, 3.000], mean observation: 0.165 [-1.248, 3.913], loss: 19.761385, mean_absolute_error: 30.827791, mean_q: -37.924370
  6460/100000: episode: 66, duration: 2.865s, episode steps: 443, steps per second: 155, episode reward: -128.721, mean reward: -0.291 [-100.000, 12.464], mean action: 1.894 [0.000, 3.000], mean observation: 0.134 [-2.466, 1.429], loss: 20.466158, mean_absolute_error: 29.361712, mean_q: -35.653999
  6561/100000: episode: 67, duration: 0.570s, episode steps: 101, steps per second: 177, episode reward: -155.580, mean reward: -1.540 [-100.000, 3.313], mean action: 1.881 [0.000, 3.000], mean observation: 0.282 [-0.496, 1.400], loss: 18.032621, mean_absolute_error: 28.231815, mean_q: -34.171978
  6893/100000: episode: 68, duration: 2.026s, episode steps: 332, steps per second: 164, episode reward: -192.902, mean reward: -0.581 [-100.000, 11.857], mean action: 1.994 [0.000, 3.000], mean observation: 0.196 [-4.843, 1.541], loss: 18.999884, mean_absolute_error: 27.169668, mean_q: -32.811531
  7195/100000: episode: 69, duration: 1.828s, episode steps: 302, steps per second: 165, episode reward: -420.011, mean reward: -1.391 [-100.000, 6.765], mean action: 1.762 [0.000, 3.000], mean observation: 0.242 [-1.658, 3.747], loss: 20.099710, mean_absolute_error: 26.526403, mean_q: -31.713411
  7274/100000: episode: 70, duration: 0.436s, episode steps: 79, steps per second: 181, episode reward: -154.060, mean reward: -1.950 [-100.000, 29.007], mean action: 1.494 [0.000, 3.000], mean observation: -0.069 [-4.366, 1.390], loss: 18.502384, mean_absolute_error: 26.228559, mean_q: -31.252333
  7717/100000: episode: 71, duration: 2.917s, episode steps: 443, steps per second: 152, episode reward: -225.575, mean reward: -0.509 [-100.000, 19.618], mean action: 1.953 [0.000, 3.000], mean observation: 0.194 [-1.297, 1.410], loss: 18.214153, mean_absolute_error: 24.982708, mean_q: -29.262556
  8487/100000: episode: 72, duration: 5.577s, episode steps: 770, steps per second: 138, episode reward: -223.827, mean reward: -0.291 [-100.000, 4.649], mean action: 1.814 [0.000, 3.000], mean observation: 0.219 [-0.204, 1.518], loss: 17.507719, mean_absolute_error: 21.928026, mean_q: -24.816473
  8725/100000: episode: 73, duration: 1.387s, episode steps: 238, steps per second: 172, episode reward: -62.218, mean reward: -0.261 [-100.000, 5.952], mean action: 1.727 [0.000, 3.000], mean observation: 0.021 [-1.000, 3.186], loss: 15.477931, mean_absolute_error: 20.623777, mean_q: -22.486198
  8922/100000: episode: 74, duration: 1.130s, episode steps: 197, steps per second: 174, episode reward: -46.797, mean reward: -0.238 [-100.000, 18.383], mean action: 1.792 [0.000, 3.000], mean observation: 0.011 [-1.091, 1.435], loss: 14.902919, mean_absolute_error: 19.582840, mean_q: -20.678951
  9440/100000: episode: 75, duration: 3.320s, episode steps: 518, steps per second: 156, episode reward: -153.497, mean reward: -0.296 [-100.000, 4.485], mean action: 1.805 [0.000, 3.000], mean observation: 0.193 [-0.400, 1.407], loss: 15.833879, mean_absolute_error: 19.212492, mean_q: -19.488115
  9696/100000: episode: 76, duration: 1.605s, episode steps: 256, steps per second: 159, episode reward: -87.567, mean reward: -0.342 [-100.000, 4.611], mean action: 1.793 [0.000, 3.000], mean observation: 0.211 [-0.422, 1.402], loss: 11.242956, mean_absolute_error: 18.896919, mean_q: -18.228294
  9831/100000: episode: 77, duration: 0.808s, episode steps: 135, steps per second: 167, episode reward: -313.045, mean reward: -2.319 [-100.000, 9.308], mean action: 2.044 [0.000, 3.000], mean observation: 0.039 [-1.354, 3.264], loss: 13.705917, mean_absolute_error: 18.828701, mean_q: -17.323536
 10003/100000: episode: 78, duration: 1.042s, episode steps: 172, steps per second: 165, episode reward: -21.202, mean reward: -0.123 [-100.000, 55.007], mean action: 1.256 [0.000, 3.000], mean observation: 0.042 [-1.720, 1.401], loss: 15.715207, mean_absolute_error: 19.385431, mean_q: -17.416286
 10193/100000: episode: 79, duration: 1.196s, episode steps: 190, steps per second: 159, episode reward: -97.913, mean reward: -0.515 [-100.000, 6.316], mean action: 1.968 [0.000, 3.000], mean observation: 0.006 [-1.121, 2.398], loss: 15.428726, mean_absolute_error: 19.341543, mean_q: -16.697489
 10447/100000: episode: 80, duration: 1.700s, episode steps: 254, steps per second: 149, episode reward: -160.332, mean reward: -0.631 [-100.000, 8.533], mean action: 1.622 [0.000, 3.000], mean observation: 0.149 [-1.521, 1.405], loss: 14.781997, mean_absolute_error: 19.207834, mean_q: -15.786685
 10711/100000: episode: 81, duration: 1.537s, episode steps: 264, steps per second: 172, episode reward: -147.964, mean reward: -0.560 [-100.000, 4.891], mean action: 1.591 [0.000, 3.000], mean observation: 0.170 [-0.521, 1.424], loss: 13.610994, mean_absolute_error: 19.736572, mean_q: -14.882178
 10881/100000: episode: 82, duration: 0.971s, episode steps: 170, steps per second: 175, episode reward: -394.811, mean reward: -2.322 [-100.000, 3.516], mean action: 1.624 [0.000, 3.000], mean observation: 0.024 [-1.790, 1.719], loss: 15.007901, mean_absolute_error: 20.035797, mean_q: -14.267121
 11076/100000: episode: 83, duration: 1.088s, episode steps: 195, steps per second: 179, episode reward: -61.271, mean reward: -0.314 [-100.000, 11.841], mean action: 1.385 [0.000, 3.000], mean observation: 0.176 [-0.490, 1.515], loss: 9.707619, mean_absolute_error: 20.328764, mean_q: -13.187783
 11608/100000: episode: 84, duration: 3.289s, episode steps: 532, steps per second: 162, episode reward: -165.211, mean reward: -0.311 [-100.000, 19.492], mean action: 1.329 [0.000, 3.000], mean observation: 0.201 [-0.768, 1.391], loss: 14.164211, mean_absolute_error: 21.785795, mean_q: -12.771998
 11872/100000: episode: 85, duration: 1.610s, episode steps: 264, steps per second: 164, episode reward: -199.004, mean reward: -0.754 [-100.000, 22.476], mean action: 1.598 [0.000, 3.000], mean observation: 0.044 [-1.362, 1.632], loss: 13.861224, mean_absolute_error: 22.986057, mean_q: -11.673425
 12124/100000: episode: 86, duration: 1.627s, episode steps: 252, steps per second: 155, episode reward: -181.967, mean reward: -0.722 [-100.000, 25.295], mean action: 1.528 [0.000, 3.000], mean observation: 0.127 [-0.648, 1.862], loss: 13.100877, mean_absolute_error: 24.212549, mean_q: -11.751440
 12315/100000: episode: 87, duration: 1.133s, episode steps: 191, steps per second: 169, episode reward: -102.115, mean reward: -0.535 [-100.000, 6.404], mean action: 1.660 [0.000, 3.000], mean observation: 0.032 [-1.007, 3.572], loss: 11.950295, mean_absolute_error: 24.343264, mean_q: -10.444625
 12423/100000: episode: 88, duration: 0.607s, episode steps: 108, steps per second: 178, episode reward: -39.003, mean reward: -0.361 [-100.000, 8.828], mean action: 1.593 [0.000, 3.000], mean observation: 0.128 [-0.965, 3.255], loss: 10.336190, mean_absolute_error: 24.693388, mean_q: -9.077114
 12596/100000: episode: 89, duration: 1.039s, episode steps: 173, steps per second: 166, episode reward: -109.153, mean reward: -0.631 [-100.000, 9.749], mean action: 1.503 [0.000, 3.000], mean observation: 0.012 [-0.963, 1.398], loss: 9.962363, mean_absolute_error: 25.475729, mean_q: -9.014016
 12815/100000: episode: 90, duration: 1.402s, episode steps: 219, steps per second: 156, episode reward: -204.238, mean reward: -0.933 [-100.000, 11.210], mean action: 1.384 [0.000, 3.000], mean observation: 0.008 [-4.012, 1.431], loss: 9.964092, mean_absolute_error: 25.410248, mean_q: -7.997221
 13069/100000: episode: 91, duration: 1.518s, episode steps: 254, steps per second: 167, episode reward: 225.833, mean reward: 0.889 [-10.034, 100.000], mean action: 1.382 [0.000, 3.000], mean observation: 0.180 [-0.688, 1.416], loss: 12.963989, mean_absolute_error: 26.127735, mean_q: -6.610162
 13277/100000: episode: 92, duration: 1.265s, episode steps: 208, steps per second: 164, episode reward: -142.700, mean reward: -0.686 [-100.000, 14.134], mean action: 1.837 [0.000, 3.000], mean observation: -0.018 [-1.218, 2.883], loss: 13.181193, mean_absolute_error: 26.772888, mean_q: -7.585190
 13442/100000: episode: 93, duration: 0.932s, episode steps: 165, steps per second: 177, episode reward: -41.013, mean reward: -0.249 [-100.000, 12.288], mean action: 1.582 [0.000, 3.000], mean observation: 0.058 [-0.907, 3.130], loss: 14.763350, mean_absolute_error: 26.930285, mean_q: -6.441266
 13641/100000: episode: 94, duration: 1.139s, episode steps: 199, steps per second: 175, episode reward: -15.300, mean reward: -0.077 [-100.000, 23.895], mean action: 1.497 [0.000, 3.000], mean observation: 0.089 [-0.680, 2.220], loss: 10.857529, mean_absolute_error: 26.803308, mean_q: -3.990478
 13817/100000: episode: 95, duration: 1.010s, episode steps: 176, steps per second: 174, episode reward: -112.956, mean reward: -0.642 [-100.000, 7.411], mean action: 1.716 [0.000, 3.000], mean observation: -0.007 [-3.769, 1.390], loss: 13.495068, mean_absolute_error: 27.391851, mean_q: -5.287620
 14003/100000: episode: 96, duration: 1.071s, episode steps: 186, steps per second: 174, episode reward: -115.329, mean reward: -0.620 [-100.000, 13.791], mean action: 1.995 [0.000, 3.000], mean observation: -0.060 [-1.211, 3.278], loss: 11.914493, mean_absolute_error: 27.746813, mean_q: -4.037453
 14255/100000: episode: 97, duration: 1.468s, episode steps: 252, steps per second: 172, episode reward: -26.357, mean reward: -0.105 [-100.000, 11.685], mean action: 1.651 [0.000, 3.000], mean observation: 0.055 [-0.752, 1.403], loss: 17.834158, mean_absolute_error: 28.084679, mean_q: -3.604181
 14473/100000: episode: 98, duration: 1.251s, episode steps: 218, steps per second: 174, episode reward: -56.136, mean reward: -0.258 [-100.000, 14.544], mean action: 1.482 [0.000, 3.000], mean observation: 0.030 [-1.176, 1.399], loss: 10.907537, mean_absolute_error: 28.276945, mean_q: -2.257443
 14773/100000: episode: 99, duration: 1.769s, episode steps: 300, steps per second: 170, episode reward: -0.905, mean reward: -0.003 [-100.000, 13.675], mean action: 1.473 [0.000, 3.000], mean observation: 0.094 [-1.136, 1.471], loss: 15.484267, mean_absolute_error: 28.592552, mean_q: -2.353463
 14910/100000: episode: 100, duration: 0.773s, episode steps: 137, steps per second: 177, episode reward: -213.646, mean reward: -1.559 [-100.000, 3.601], mean action: 2.058 [0.000, 3.000], mean observation: -0.112 [-1.255, 1.387], loss: 16.085499, mean_absolute_error: 29.043903, mean_q: -2.667163
 15307/100000: episode: 101, duration: 2.517s, episode steps: 397, steps per second: 158, episode reward: -322.717, mean reward: -0.813 [-100.000, 4.553], mean action: 1.542 [0.000, 3.000], mean observation: 0.069 [-1.083, 4.108], loss: 13.250874, mean_absolute_error: 29.119745, mean_q: -1.061473
 16054/100000: episode: 102, duration: 5.432s, episode steps: 747, steps per second: 138, episode reward: -199.539, mean reward: -0.267 [-100.000, 5.522], mean action: 1.533 [0.000, 3.000], mean observation: 0.130 [-0.583, 1.420], loss: 14.305826, mean_absolute_error: 29.487591, mean_q: -2.164987
 16533/100000: episode: 103, duration: 3.032s, episode steps: 479, steps per second: 158, episode reward: -149.458, mean reward: -0.312 [-100.000, 4.684], mean action: 1.466 [0.000, 3.000], mean observation: 0.142 [-0.432, 1.392], loss: 15.831345, mean_absolute_error: 29.811216, mean_q: -2.360536
 17062/100000: episode: 104, duration: 3.792s, episode steps: 529, steps per second: 139, episode reward: -231.552, mean reward: -0.438 [-100.000, 35.128], mean action: 1.681 [0.000, 3.000], mean observation: 0.090 [-0.599, 1.621], loss: 11.270816, mean_absolute_error: 29.762716, mean_q: -1.589888
 17275/100000: episode: 105, duration: 1.237s, episode steps: 213, steps per second: 172, episode reward: -197.179, mean reward: -0.926 [-100.000, 3.175], mean action: 1.700 [0.000, 3.000], mean observation: 0.052 [-1.052, 1.558], loss: 13.128593, mean_absolute_error: 30.300068, mean_q: -1.057948
 17421/100000: episode: 106, duration: 0.831s, episode steps: 146, steps per second: 176, episode reward: -185.989, mean reward: -1.274 [-100.000, 1.739], mean action: 1.767 [0.000, 3.000], mean observation: 0.033 [-1.005, 1.505], loss: 11.863013, mean_absolute_error: 29.956406, mean_q: -0.375490
 18421/100000: episode: 107, duration: 6.831s, episode steps: 1000, steps per second: 146, episode reward: -76.711, mean reward: -0.077 [-5.366, 4.596], mean action: 1.496 [0.000, 3.000], mean observation: 0.117 [-0.407, 1.395], loss: 13.018821, mean_absolute_error: 30.020823, mean_q: -0.306718
 18848/100000: episode: 108, duration: 2.746s, episode steps: 427, steps per second: 156, episode reward: -120.759, mean reward: -0.283 [-100.000, 71.325], mean action: 1.649 [0.000, 3.000], mean observation: 0.052 [-1.097, 1.430], loss: 10.177641, mean_absolute_error: 29.844486, mean_q: 0.084620
 19085/100000: episode: 109, duration: 1.360s, episode steps: 237, steps per second: 174, episode reward: -236.492, mean reward: -0.998 [-100.000, 3.993], mean action: 1.557 [0.000, 3.000], mean observation: -0.000 [-2.918, 1.658], loss: 13.372624, mean_absolute_error: 30.382170, mean_q: 0.202586
 19288/100000: episode: 110, duration: 1.151s, episode steps: 203, steps per second: 176, episode reward: -162.809, mean reward: -0.802 [-100.000, 3.210], mean action: 1.695 [0.000, 3.000], mean observation: 0.005 [-1.001, 1.425], loss: 8.836501, mean_absolute_error: 29.890451, mean_q: 0.846874
 19621/100000: episode: 111, duration: 2.030s, episode steps: 333, steps per second: 164, episode reward: -447.384, mean reward: -1.343 [-100.000, 8.872], mean action: 1.396 [0.000, 3.000], mean observation: 0.066 [-0.905, 2.836], loss: 11.568899, mean_absolute_error: 30.348780, mean_q: 0.795349
 19939/100000: episode: 112, duration: 1.844s, episode steps: 318, steps per second: 172, episode reward: -203.166, mean reward: -0.639 [-100.000, 4.282], mean action: 1.522 [0.000, 3.000], mean observation: 0.031 [-2.918, 1.485], loss: 13.889842, mean_absolute_error: 30.611246, mean_q: 1.294122
 20612/100000: episode: 113, duration: 4.273s, episode steps: 673, steps per second: 157, episode reward: -183.614, mean reward: -0.273 [-100.000, 6.239], mean action: 1.617 [0.000, 3.000], mean observation: 0.096 [-0.709, 1.440], loss: 11.026102, mean_absolute_error: 30.562449, mean_q: 0.677762
 20995/100000: episode: 114, duration: 2.426s, episode steps: 383, steps per second: 158, episode reward: -120.824, mean reward: -0.315 [-100.000, 15.572], mean action: 1.462 [0.000, 3.000], mean observation: 0.039 [-0.923, 1.400], loss: 14.154320, mean_absolute_error: 30.515732, mean_q: 0.969476
 21267/100000: episode: 115, duration: 1.598s, episode steps: 272, steps per second: 170, episode reward: -188.637, mean reward: -0.694 [-100.000, 5.476], mean action: 1.691 [0.000, 3.000], mean observation: 0.044 [-1.298, 1.439], loss: 10.864378, mean_absolute_error: 30.884504, mean_q: 1.720683
 21510/100000: episode: 116, duration: 1.400s, episode steps: 243, steps per second: 174, episode reward: -206.075, mean reward: -0.848 [-100.000, 3.581], mean action: 1.757 [0.000, 3.000], mean observation: 0.000 [-1.480, 1.581], loss: 10.711714, mean_absolute_error: 31.021183, mean_q: 0.632367
 21652/100000: episode: 117, duration: 0.807s, episode steps: 142, steps per second: 176, episode reward: -139.638, mean reward: -0.983 [-100.000, 8.566], mean action: 1.535 [0.000, 3.000], mean observation: -0.067 [-1.135, 3.237], loss: 13.279248, mean_absolute_error: 30.870701, mean_q: 0.627568
 21913/100000: episode: 118, duration: 1.554s, episode steps: 261, steps per second: 168, episode reward: -159.901, mean reward: -0.613 [-100.000, 4.576], mean action: 1.544 [0.000, 3.000], mean observation: 0.026 [-0.934, 3.140], loss: 14.383519, mean_absolute_error: 31.400324, mean_q: 1.272660
 22537/100000: episode: 119, duration: 4.324s, episode steps: 624, steps per second: 144, episode reward: -194.461, mean reward: -0.312 [-100.000, 12.197], mean action: 1.585 [0.000, 3.000], mean observation: 0.100 [-0.975, 3.195], loss: 10.520239, mean_absolute_error: 31.106876, mean_q: 1.515560
 22909/100000: episode: 120, duration: 2.297s, episode steps: 372, steps per second: 162, episode reward: -252.963, mean reward: -0.680 [-100.000, 4.209], mean action: 1.707 [0.000, 3.000], mean observation: 0.026 [-1.007, 1.478], loss: 13.633538, mean_absolute_error: 31.046232, mean_q: 1.358089
 23255/100000: episode: 121, duration: 2.239s, episode steps: 346, steps per second: 155, episode reward: -125.643, mean reward: -0.363 [-100.000, 13.048], mean action: 1.728 [0.000, 3.000], mean observation: 0.063 [-3.531, 1.397], loss: 13.873871, mean_absolute_error: 30.681660, mean_q: 1.779513
 23693/100000: episode: 122, duration: 2.689s, episode steps: 438, steps per second: 163, episode reward: -66.288, mean reward: -0.151 [-100.000, 13.246], mean action: 1.623 [0.000, 3.000], mean observation: 0.090 [-2.606, 1.498], loss: 15.206935, mean_absolute_error: 31.136339, mean_q: 2.206749
 24017/100000: episode: 123, duration: 1.915s, episode steps: 324, steps per second: 169, episode reward: -133.950, mean reward: -0.413 [-100.000, 13.855], mean action: 1.562 [0.000, 3.000], mean observation: 0.048 [-1.036, 1.434], loss: 15.176764, mean_absolute_error: 31.072308, mean_q: 2.845327
 24162/100000: episode: 124, duration: 0.804s, episode steps: 145, steps per second: 180, episode reward: -146.013, mean reward: -1.007 [-100.000, 2.798], mean action: 1.428 [0.000, 3.000], mean observation: 0.023 [-1.005, 1.567], loss: 15.756213, mean_absolute_error: 31.081249, mean_q: 2.457952
 24409/100000: episode: 125, duration: 1.448s, episode steps: 247, steps per second: 171, episode reward: -141.144, mean reward: -0.571 [-100.000, 9.227], mean action: 1.607 [0.000, 3.000], mean observation: 0.002 [-1.144, 2.927], loss: 10.464010, mean_absolute_error: 31.437637, mean_q: 2.242891
 24645/100000: episode: 126, duration: 1.371s, episode steps: 236, steps per second: 172, episode reward: -174.301, mean reward: -0.739 [-100.000, 3.048], mean action: 1.771 [0.000, 3.000], mean observation: 0.040 [-1.001, 1.613], loss: 13.420691, mean_absolute_error: 31.509903, mean_q: 2.457837
 25005/100000: episode: 127, duration: 2.226s, episode steps: 360, steps per second: 162, episode reward: -283.233, mean reward: -0.787 [-100.000, 4.625], mean action: 1.447 [0.000, 3.000], mean observation: 0.008 [-1.002, 1.397], loss: 11.550898, mean_absolute_error: 32.028049, mean_q: 1.479589
 25261/100000: episode: 128, duration: 1.522s, episode steps: 256, steps per second: 168, episode reward: -146.653, mean reward: -0.573 [-100.000, 9.532], mean action: 1.520 [0.000, 3.000], mean observation: 0.040 [-3.199, 1.402], loss: 13.252505, mean_absolute_error: 32.304382, mean_q: 2.135409
 25409/100000: episode: 129, duration: 0.840s, episode steps: 148, steps per second: 176, episode reward: -114.142, mean reward: -0.771 [-100.000, 10.661], mean action: 1.514 [0.000, 3.000], mean observation: -0.025 [-1.638, 1.399], loss: 17.482145, mean_absolute_error: 32.601406, mean_q: 0.092357
 25689/100000: episode: 130, duration: 1.624s, episode steps: 280, steps per second: 172, episode reward: -182.360, mean reward: -0.651 [-100.000, 4.436], mean action: 1.614 [0.000, 3.000], mean observation: 0.033 [-1.001, 1.757], loss: 11.998352, mean_absolute_error: 31.900858, mean_q: 2.183753
 25818/100000: episode: 131, duration: 0.731s, episode steps: 129, steps per second: 176, episode reward: 19.381, mean reward: 0.150 [-100.000, 15.295], mean action: 1.876 [0.000, 3.000], mean observation: 0.096 [-0.797, 1.412], loss: 9.137892, mean_absolute_error: 32.490372, mean_q: 1.181835
 26258/100000: episode: 132, duration: 2.699s, episode steps: 440, steps per second: 163, episode reward: -52.306, mean reward: -0.119 [-100.000, 10.009], mean action: 1.739 [0.000, 3.000], mean observation: 0.109 [-1.565, 1.520], loss: 13.338822, mean_absolute_error: 32.495312, mean_q: 2.040927
 26415/100000: episode: 133, duration: 0.892s, episode steps: 157, steps per second: 176, episode reward: -172.372, mean reward: -1.098 [-100.000, 10.991], mean action: 1.688 [0.000, 3.000], mean observation: -0.027 [-1.075, 2.607], loss: 14.133049, mean_absolute_error: 32.052170, mean_q: 3.126763
 26713/100000: episode: 134, duration: 1.792s, episode steps: 298, steps per second: 166, episode reward: -244.065, mean reward: -0.819 [-100.000, 4.332], mean action: 1.497 [0.000, 3.000], mean observation: 0.028 [-1.092, 1.685], loss: 12.155900, mean_absolute_error: 31.970835, mean_q: 2.460702
 27208/100000: episode: 135, duration: 3.297s, episode steps: 495, steps per second: 150, episode reward: -63.799, mean reward: -0.129 [-100.000, 10.173], mean action: 1.598 [0.000, 3.000], mean observation: 0.095 [-1.272, 1.443], loss: 10.648131, mean_absolute_error: 31.858980, mean_q: 2.917724
 27419/100000: episode: 136, duration: 1.206s, episode steps: 211, steps per second: 175, episode reward: -83.989, mean reward: -0.398 [-100.000, 18.140], mean action: 1.716 [0.000, 3.000], mean observation: 0.029 [-0.848, 1.401], loss: 11.535435, mean_absolute_error: 32.318687, mean_q: 2.815346
 27617/100000: episode: 137, duration: 1.135s, episode steps: 198, steps per second: 174, episode reward: -145.058, mean reward: -0.733 [-100.000, 17.531], mean action: 1.657 [0.000, 3.000], mean observation: 0.003 [-0.928, 3.062], loss: 10.159924, mean_absolute_error: 31.837446, mean_q: 3.774839
 27784/100000: episode: 138, duration: 0.964s, episode steps: 167, steps per second: 173, episode reward: 22.755, mean reward: 0.136 [-100.000, 13.402], mean action: 1.844 [0.000, 3.000], mean observation: 0.019 [-0.814, 1.389], loss: 16.100533, mean_absolute_error: 32.207977, mean_q: 2.307668
 27983/100000: episode: 139, duration: 1.127s, episode steps: 199, steps per second: 177, episode reward: -139.753, mean reward: -0.702 [-100.000, 12.180], mean action: 1.367 [0.000, 3.000], mean observation: 0.013 [-1.116, 1.673], loss: 12.278478, mean_absolute_error: 31.903551, mean_q: 2.461509
 28090/100000: episode: 140, duration: 0.606s, episode steps: 107, steps per second: 177, episode reward: 17.095, mean reward: 0.160 [-100.000, 13.761], mean action: 2.009 [0.000, 3.000], mean observation: 0.059 [-1.046, 1.562], loss: 10.214728, mean_absolute_error: 32.131748, mean_q: 2.724796
 28272/100000: episode: 141, duration: 1.050s, episode steps: 182, steps per second: 173, episode reward: -57.382, mean reward: -0.315 [-100.000, 10.391], mean action: 1.797 [0.000, 3.000], mean observation: -0.045 [-2.334, 1.397], loss: 9.310972, mean_absolute_error: 31.992407, mean_q: 1.772550
 28373/100000: episode: 142, duration: 0.574s, episode steps: 101, steps per second: 176, episode reward: 2.352, mean reward: 0.023 [-100.000, 14.493], mean action: 1.970 [0.000, 3.000], mean observation: 0.057 [-0.876, 1.392], loss: 14.768788, mean_absolute_error: 32.295799, mean_q: 2.759585
 28667/100000: episode: 143, duration: 1.734s, episode steps: 294, steps per second: 170, episode reward: 4.181, mean reward: 0.014 [-100.000, 11.779], mean action: 1.650 [0.000, 3.000], mean observation: 0.050 [-1.245, 1.407], loss: 8.649396, mean_absolute_error: 32.733009, mean_q: 1.531260
 28785/100000: episode: 144, duration: 0.657s, episode steps: 118, steps per second: 180, episode reward: -116.367, mean reward: -0.986 [-100.000, 12.813], mean action: 1.610 [0.000, 3.000], mean observation: -0.109 [-1.004, 3.514], loss: 9.890672, mean_absolute_error: 32.814774, mean_q: 2.516142
 29781/100000: episode: 145, duration: 8.091s, episode steps: 996, steps per second: 123, episode reward: 131.747, mean reward: 0.132 [-10.450, 100.000], mean action: 1.576 [0.000, 3.000], mean observation: 0.091 [-0.497, 1.454], loss: 12.288110, mean_absolute_error: 32.223152, mean_q: 1.514033
 30048/100000: episode: 146, duration: 1.617s, episode steps: 267, steps per second: 165, episode reward: 28.701, mean reward: 0.107 [-100.000, 11.479], mean action: 1.753 [0.000, 3.000], mean observation: 0.036 [-0.752, 1.386], loss: 12.998160, mean_absolute_error: 31.775822, mean_q: 2.311049
 30340/100000: episode: 147, duration: 1.730s, episode steps: 292, steps per second: 169, episode reward: -188.847, mean reward: -0.647 [-100.000, 4.830], mean action: 1.613 [0.000, 3.000], mean observation: 0.023 [-1.006, 1.403], loss: 9.371074, mean_absolute_error: 31.612408, mean_q: 1.331208
 30903/100000: episode: 148, duration: 3.744s, episode steps: 563, steps per second: 150, episode reward: -248.538, mean reward: -0.441 [-100.000, 36.675], mean action: 1.584 [0.000, 3.000], mean observation: 0.074 [-1.050, 1.580], loss: 13.152475, mean_absolute_error: 31.582979, mean_q: 1.840672
 31283/100000: episode: 149, duration: 2.402s, episode steps: 380, steps per second: 158, episode reward: -229.017, mean reward: -0.603 [-100.000, 55.177], mean action: 1.745 [0.000, 3.000], mean observation: 0.057 [-1.124, 1.515], loss: 10.753635, mean_absolute_error: 31.526573, mean_q: 0.515709
 31506/100000: episode: 150, duration: 1.301s, episode steps: 223, steps per second: 171, episode reward: -67.229, mean reward: -0.301 [-100.000, 11.545], mean action: 1.646 [0.000, 3.000], mean observation: 0.012 [-0.694, 1.412], loss: 12.768796, mean_absolute_error: 31.356922, mean_q: 0.206387
 31724/100000: episode: 151, duration: 1.257s, episode steps: 218, steps per second: 173, episode reward: -248.521, mean reward: -1.140 [-100.000, 3.988], mean action: 1.564 [0.000, 3.000], mean observation: -0.007 [-1.486, 1.404], loss: 10.403226, mean_absolute_error: 31.508839, mean_q: -1.236665
 31980/100000: episode: 152, duration: 1.518s, episode steps: 256, steps per second: 169, episode reward: -176.918, mean reward: -0.691 [-100.000, 8.098], mean action: 1.633 [0.000, 3.000], mean observation: 0.035 [-1.052, 1.554], loss: 10.685646, mean_absolute_error: 31.367680, mean_q: -0.115073
 32137/100000: episode: 153, duration: 0.882s, episode steps: 157, steps per second: 178, episode reward: -12.424, mean reward: -0.079 [-100.000, 16.159], mean action: 1.554 [0.000, 3.000], mean observation: 0.016 [-2.742, 1.494], loss: 11.023026, mean_absolute_error: 31.325401, mean_q: 1.139079
 32343/100000: episode: 154, duration: 1.179s, episode steps: 206, steps per second: 175, episode reward: -53.946, mean reward: -0.262 [-100.000, 20.852], mean action: 1.481 [0.000, 3.000], mean observation: 0.015 [-0.777, 1.401], loss: 8.274715, mean_absolute_error: 31.044971, mean_q: -0.197373
 32622/100000: episode: 155, duration: 1.649s, episode steps: 279, steps per second: 169, episode reward: -88.116, mean reward: -0.316 [-100.000, 9.603], mean action: 1.677 [0.000, 3.000], mean observation: 0.036 [-1.990, 1.403], loss: 8.273821, mean_absolute_error: 31.046795, mean_q: 1.005527
 32808/100000: episode: 156, duration: 1.076s, episode steps: 186, steps per second: 173, episode reward: -30.022, mean reward: -0.161 [-100.000, 38.963], mean action: 1.694 [0.000, 3.000], mean observation: -0.027 [-0.787, 2.104], loss: 9.591952, mean_absolute_error: 31.465815, mean_q: 0.300689
 33068/100000: episode: 157, duration: 1.556s, episode steps: 260, steps per second: 167, episode reward: -148.186, mean reward: -0.570 [-100.000, 9.294], mean action: 1.550 [0.000, 3.000], mean observation: 0.042 [-1.484, 1.408], loss: 9.868870, mean_absolute_error: 31.116341, mean_q: 0.084258
 33273/100000: episode: 158, duration: 1.199s, episode steps: 205, steps per second: 171, episode reward: -2.776, mean reward: -0.014 [-100.000, 41.607], mean action: 1.844 [0.000, 3.000], mean observation: 0.010 [-0.915, 1.687], loss: 6.032109, mean_absolute_error: 30.898489, mean_q: 0.699931
 33504/100000: episode: 159, duration: 1.342s, episode steps: 231, steps per second: 172, episode reward: -66.534, mean reward: -0.288 [-100.000, 19.230], mean action: 1.727 [0.000, 3.000], mean observation: -0.010 [-2.527, 1.597], loss: 8.881094, mean_absolute_error: 30.868126, mean_q: 1.017870
 33780/100000: episode: 160, duration: 1.689s, episode steps: 276, steps per second: 163, episode reward: -88.167, mean reward: -0.319 [-100.000, 8.575], mean action: 1.623 [0.000, 3.000], mean observation: 0.033 [-1.020, 1.410], loss: 9.750190, mean_absolute_error: 31.034523, mean_q: -0.080511
 34073/100000: episode: 161, duration: 1.801s, episode steps: 293, steps per second: 163, episode reward: -67.815, mean reward: -0.231 [-100.000, 9.339], mean action: 1.710 [0.000, 3.000], mean observation: 0.013 [-0.683, 1.399], loss: 11.937078, mean_absolute_error: 30.859512, mean_q: 0.023073
 34258/100000: episode: 162, duration: 1.058s, episode steps: 185, steps per second: 175, episode reward: -98.027, mean reward: -0.530 [-100.000, 18.307], mean action: 1.535 [0.000, 3.000], mean observation: 0.009 [-0.646, 1.412], loss: 9.158692, mean_absolute_error: 30.788340, mean_q: 1.603614
 34770/100000: episode: 163, duration: 3.209s, episode steps: 512, steps per second: 160, episode reward: -7.865, mean reward: -0.015 [-100.000, 10.726], mean action: 1.598 [0.000, 3.000], mean observation: 0.082 [-0.457, 1.390], loss: 11.779144, mean_absolute_error: 29.876253, mean_q: 1.808774
 35302/100000: episode: 164, duration: 3.481s, episode steps: 532, steps per second: 153, episode reward: 133.208, mean reward: 0.250 [-9.214, 100.000], mean action: 1.477 [0.000, 3.000], mean observation: 0.002 [-0.700, 1.462], loss: 10.086408, mean_absolute_error: 29.863417, mean_q: 1.731570
 35514/100000: episode: 165, duration: 1.228s, episode steps: 212, steps per second: 173, episode reward: -61.150, mean reward: -0.288 [-100.000, 14.293], mean action: 1.637 [0.000, 3.000], mean observation: -0.028 [-0.669, 1.573], loss: 10.741826, mean_absolute_error: 29.695774, mean_q: 2.322326
 35811/100000: episode: 166, duration: 1.773s, episode steps: 297, steps per second: 168, episode reward: -223.845, mean reward: -0.754 [-100.000, 4.806], mean action: 1.700 [0.000, 3.000], mean observation: 0.010 [-1.024, 1.405], loss: 9.819550, mean_absolute_error: 29.916706, mean_q: 1.995553
 36022/100000: episode: 167, duration: 1.225s, episode steps: 211, steps per second: 172, episode reward: -124.298, mean reward: -0.589 [-100.000, 5.067], mean action: 1.815 [0.000, 3.000], mean observation: -0.058 [-1.002, 1.397], loss: 10.082790, mean_absolute_error: 30.009090, mean_q: 1.997601
 36330/100000: episode: 168, duration: 1.868s, episode steps: 308, steps per second: 165, episode reward: -137.059, mean reward: -0.445 [-100.000, 9.019], mean action: 1.831 [0.000, 3.000], mean observation: 0.013 [-0.902, 1.398], loss: 12.523440, mean_absolute_error: 29.871386, mean_q: 1.482177
 36661/100000: episode: 169, duration: 1.985s, episode steps: 331, steps per second: 167, episode reward: -75.939, mean reward: -0.229 [-100.000, 13.308], mean action: 1.782 [0.000, 3.000], mean observation: 0.050 [-0.625, 1.524], loss: 10.147756, mean_absolute_error: 29.488264, mean_q: 3.037578
 37234/100000: episode: 170, duration: 3.730s, episode steps: 573, steps per second: 154, episode reward: -39.114, mean reward: -0.068 [-100.000, 14.387], mean action: 1.749 [0.000, 3.000], mean observation: 0.067 [-0.653, 1.469], loss: 10.437757, mean_absolute_error: 29.533705, mean_q: 2.767088
 37500/100000: episode: 171, duration: 1.607s, episode steps: 266, steps per second: 165, episode reward: -3.233, mean reward: -0.012 [-100.000, 22.039], mean action: 1.880 [0.000, 3.000], mean observation: -0.000 [-0.610, 1.405], loss: 9.787977, mean_absolute_error: 29.324926, mean_q: 4.105457
 37739/100000: episode: 172, duration: 1.422s, episode steps: 239, steps per second: 168, episode reward: -186.216, mean reward: -0.779 [-100.000, 10.025], mean action: 1.996 [0.000, 3.000], mean observation: -0.039 [-0.934, 1.419], loss: 10.861734, mean_absolute_error: 29.035793, mean_q: 4.498489
 38416/100000: episode: 173, duration: 4.873s, episode steps: 677, steps per second: 139, episode reward: -89.709, mean reward: -0.133 [-100.000, 8.818], mean action: 1.610 [0.000, 3.000], mean observation: 0.067 [-0.855, 1.598], loss: 9.087137, mean_absolute_error: 29.217060, mean_q: 4.856658
 38581/100000: episode: 174, duration: 0.933s, episode steps: 165, steps per second: 177, episode reward: -157.023, mean reward: -0.952 [-100.000, 3.144], mean action: 1.691 [0.000, 3.000], mean observation: -0.046 [-1.171, 1.393], loss: 12.914749, mean_absolute_error: 28.691799, mean_q: 5.059086
 39517/100000: episode: 175, duration: 7.093s, episode steps: 936, steps per second: 132, episode reward: -149.473, mean reward: -0.160 [-100.000, 18.077], mean action: 1.744 [0.000, 3.000], mean observation: 0.075 [-0.884, 1.834], loss: 11.494485, mean_absolute_error: 29.014719, mean_q: 5.641517
 39956/100000: episode: 176, duration: 2.881s, episode steps: 439, steps per second: 152, episode reward: -61.017, mean reward: -0.139 [-100.000, 13.893], mean action: 1.702 [0.000, 3.000], mean observation: 0.042 [-0.748, 1.388], loss: 9.499560, mean_absolute_error: 29.039593, mean_q: 6.220827
 40263/100000: episode: 177, duration: 1.826s, episode steps: 307, steps per second: 168, episode reward: -22.823, mean reward: -0.074 [-100.000, 9.090], mean action: 1.879 [0.000, 3.000], mean observation: -0.001 [-0.850, 1.682], loss: 8.817764, mean_absolute_error: 28.729202, mean_q: 6.711466
 40888/100000: episode: 178, duration: 4.130s, episode steps: 625, steps per second: 151, episode reward: 161.381, mean reward: 0.258 [-20.065, 100.000], mean action: 1.405 [0.000, 3.000], mean observation: 0.036 [-0.931, 1.393], loss: 11.131942, mean_absolute_error: 28.930754, mean_q: 6.807594
 41303/100000: episode: 179, duration: 2.678s, episode steps: 415, steps per second: 155, episode reward: -73.288, mean reward: -0.177 [-100.000, 17.514], mean action: 1.733 [0.000, 3.000], mean observation: -0.033 [-0.821, 1.615], loss: 7.264413, mean_absolute_error: 28.414124, mean_q: 7.240335
 41794/100000: episode: 180, duration: 3.432s, episode steps: 491, steps per second: 143, episode reward: -203.127, mean reward: -0.414 [-100.000, 5.570], mean action: 1.886 [0.000, 3.000], mean observation: -0.009 [-1.001, 1.393], loss: 9.938654, mean_absolute_error: 28.568279, mean_q: 7.538612
 42455/100000: episode: 181, duration: 5.166s, episode steps: 661, steps per second: 128, episode reward: -230.370, mean reward: -0.349 [-100.000, 21.978], mean action: 1.735 [0.000, 3.000], mean observation: 0.035 [-1.038, 1.415], loss: 10.275243, mean_absolute_error: 28.546133, mean_q: 7.732100
 42723/100000: episode: 182, duration: 1.706s, episode steps: 268, steps per second: 157, episode reward: -141.805, mean reward: -0.529 [-100.000, 4.986], mean action: 1.396 [0.000, 3.000], mean observation: -0.049 [-1.005, 1.403], loss: 8.308197, mean_absolute_error: 28.433573, mean_q: 9.129791
 43449/100000: episode: 183, duration: 4.990s, episode steps: 726, steps per second: 145, episode reward: -277.719, mean reward: -0.383 [-100.000, 5.577], mean action: 1.704 [0.000, 3.000], mean observation: 0.047 [-1.003, 1.410], loss: 10.748200, mean_absolute_error: 28.346960, mean_q: 9.079392
 44099/100000: episode: 184, duration: 4.623s, episode steps: 650, steps per second: 141, episode reward: -162.929, mean reward: -0.251 [-100.000, 14.595], mean action: 1.848 [0.000, 3.000], mean observation: -0.031 [-1.000, 1.453], loss: 13.379183, mean_absolute_error: 28.363104, mean_q: 9.744786
 45099/100000: episode: 185, duration: 7.415s, episode steps: 1000, steps per second: 135, episode reward: -152.868, mean reward: -0.153 [-6.563, 6.188], mean action: 1.595 [0.000, 3.000], mean observation: 0.036 [-0.929, 1.401], loss: 11.156569, mean_absolute_error: 27.954754, mean_q: 10.428661
 46099/100000: episode: 186, duration: 7.925s, episode steps: 1000, steps per second: 126, episode reward: -90.543, mean reward: -0.091 [-5.252, 4.760], mean action: 1.580 [0.000, 3.000], mean observation: 0.094 [-0.361, 1.457], loss: 10.082624, mean_absolute_error: 27.511623, mean_q: 11.593110
 46371/100000: episode: 187, duration: 1.644s, episode steps: 272, steps per second: 165, episode reward: -143.452, mean reward: -0.527 [-100.000, 5.827], mean action: 1.886 [0.000, 3.000], mean observation: -0.031 [-1.004, 1.395], loss: 9.336368, mean_absolute_error: 26.848619, mean_q: 12.376066
 46616/100000: episode: 188, duration: 1.407s, episode steps: 245, steps per second: 174, episode reward: -39.636, mean reward: -0.162 [-100.000, 15.253], mean action: 1.612 [0.000, 3.000], mean observation: 0.183 [-1.771, 1.498], loss: 13.210854, mean_absolute_error: 26.405460, mean_q: 12.912992
 47089/100000: episode: 189, duration: 3.054s, episode steps: 473, steps per second: 155, episode reward: 183.812, mean reward: 0.389 [-11.049, 100.000], mean action: 1.531 [0.000, 3.000], mean observation: 0.012 [-0.639, 1.430], loss: 8.204461, mean_absolute_error: 26.584703, mean_q: 13.715393
 48089/100000: episode: 190, duration: 8.261s, episode steps: 1000, steps per second: 121, episode reward: -75.102, mean reward: -0.075 [-20.324, 16.566], mean action: 1.513 [0.000, 3.000], mean observation: 0.074 [-1.258, 1.431], loss: 10.377076, mean_absolute_error: 26.312248, mean_q: 14.925930
 48714/100000: episode: 191, duration: 4.420s, episode steps: 625, steps per second: 141, episode reward: -217.795, mean reward: -0.348 [-100.000, 4.528], mean action: 1.770 [0.000, 3.000], mean observation: -0.021 [-1.004, 1.414], loss: 12.871840, mean_absolute_error: 25.954563, mean_q: 15.609814
 49714/100000: episode: 192, duration: 8.971s, episode steps: 1000, steps per second: 111, episode reward: -88.521, mean reward: -0.089 [-5.483, 5.379], mean action: 1.714 [0.000, 3.000], mean observation: 0.035 [-0.549, 1.388], loss: 9.943463, mean_absolute_error: 26.026699, mean_q: 16.486809
 50714/100000: episode: 193, duration: 9.184s, episode steps: 1000, steps per second: 109, episode reward: -75.431, mean reward: -0.075 [-5.797, 5.348], mean action: 1.715 [0.000, 3.000], mean observation: 0.076 [-0.509, 1.474], loss: 10.181046, mean_absolute_error: 25.477839, mean_q: 17.950918
 51714/100000: episode: 194, duration: 7.153s, episode steps: 1000, steps per second: 140, episode reward: -87.141, mean reward: -0.087 [-5.175, 4.783], mean action: 1.544 [0.000, 3.000], mean observation: 0.071 [-0.723, 1.424], loss: 9.284171, mean_absolute_error: 24.429188, mean_q: 19.114168
 51872/100000: episode: 195, duration: 0.917s, episode steps: 158, steps per second: 172, episode reward: -108.767, mean reward: -0.688 [-100.000, 4.725], mean action: 1.968 [1.000, 3.000], mean observation: 0.263 [-0.481, 1.486], loss: 10.583474, mean_absolute_error: 24.536366, mean_q: 18.566059
 52762/100000: episode: 196, duration: 6.509s, episode steps: 890, steps per second: 137, episode reward: -240.439, mean reward: -0.270 [-100.000, 18.392], mean action: 1.582 [0.000, 3.000], mean observation: -0.014 [-0.717, 1.406], loss: 11.446634, mean_absolute_error: 24.342363, mean_q: 19.169558
 53762/100000: episode: 197, duration: 8.928s, episode steps: 1000, steps per second: 112, episode reward: -84.948, mean reward: -0.085 [-6.117, 5.254], mean action: 1.680 [0.000, 3.000], mean observation: 0.071 [-0.760, 1.386], loss: 7.939304, mean_absolute_error: 23.309713, mean_q: 19.248926
 54201/100000: episode: 198, duration: 2.704s, episode steps: 439, steps per second: 162, episode reward: -213.396, mean reward: -0.486 [-100.000, 20.823], mean action: 1.733 [0.000, 3.000], mean observation: -0.019 [-0.999, 1.438], loss: 9.802689, mean_absolute_error: 23.355740, mean_q: 20.004827
 55201/100000: episode: 199, duration: 6.990s, episode steps: 1000, steps per second: 143, episode reward: -35.557, mean reward: -0.036 [-5.088, 4.443], mean action: 1.551 [0.000, 3.000], mean observation: 0.039 [-0.642, 1.403], loss: 8.683346, mean_absolute_error: 23.177113, mean_q: 20.321720
 56201/100000: episode: 200, duration: 7.200s, episode steps: 1000, steps per second: 139, episode reward: -23.094, mean reward: -0.023 [-20.817, 25.764], mean action: 1.415 [0.000, 3.000], mean observation: 0.032 [-0.690, 1.405], loss: 7.511423, mean_absolute_error: 22.630817, mean_q: 20.401312
 56836/100000: episode: 201, duration: 4.533s, episode steps: 635, steps per second: 140, episode reward: -342.148, mean reward: -0.539 [-100.000, 13.208], mean action: 1.773 [0.000, 3.000], mean observation: 0.098 [-1.248, 2.293], loss: 7.391798, mean_absolute_error: 22.411114, mean_q: 20.887014
 57836/100000: episode: 202, duration: 8.670s, episode steps: 1000, steps per second: 115, episode reward: -74.308, mean reward: -0.074 [-5.731, 4.708], mean action: 1.693 [0.000, 3.000], mean observation: 0.115 [-0.457, 1.411], loss: 6.468428, mean_absolute_error: 22.101208, mean_q: 20.719183
 58836/100000: episode: 203, duration: 8.016s, episode steps: 1000, steps per second: 125, episode reward: -90.500, mean reward: -0.090 [-3.736, 4.591], mean action: 1.584 [0.000, 3.000], mean observation: 0.109 [-0.262, 1.414], loss: 6.310731, mean_absolute_error: 22.065575, mean_q: 21.922365
 59680/100000: episode: 204, duration: 6.659s, episode steps: 844, steps per second: 127, episode reward: -201.851, mean reward: -0.239 [-100.000, 17.665], mean action: 1.647 [0.000, 3.000], mean observation: 0.094 [-2.589, 1.392], loss: 8.027657, mean_absolute_error: 22.116884, mean_q: 22.248871
 60680/100000: episode: 205, duration: 8.881s, episode steps: 1000, steps per second: 113, episode reward: 0.516, mean reward: 0.001 [-4.187, 5.831], mean action: 1.629 [0.000, 3.000], mean observation: 0.068 [-0.799, 1.392], loss: 6.000416, mean_absolute_error: 22.429918, mean_q: 22.982620
 61680/100000: episode: 206, duration: 9.220s, episode steps: 1000, steps per second: 108, episode reward: -89.471, mean reward: -0.089 [-4.999, 4.597], mean action: 1.752 [0.000, 3.000], mean observation: 0.104 [-0.345, 1.401], loss: 6.731828, mean_absolute_error: 22.398823, mean_q: 23.922867
 62680/100000: episode: 207, duration: 8.069s, episode steps: 1000, steps per second: 124, episode reward: -52.820, mean reward: -0.053 [-4.932, 6.495], mean action: 1.766 [0.000, 3.000], mean observation: 0.108 [-0.483, 1.407], loss: 7.556743, mean_absolute_error: 22.662445, mean_q: 24.174368
 63680/100000: episode: 208, duration: 7.488s, episode steps: 1000, steps per second: 134, episode reward: -80.684, mean reward: -0.081 [-5.197, 4.627], mean action: 1.627 [0.000, 3.000], mean observation: 0.120 [-0.317, 1.450], loss: 5.413904, mean_absolute_error: 22.639690, mean_q: 25.133266
 64680/100000: episode: 209, duration: 8.374s, episode steps: 1000, steps per second: 119, episode reward: -65.928, mean reward: -0.066 [-5.189, 4.460], mean action: 1.761 [0.000, 3.000], mean observation: 0.112 [-0.464, 1.390], loss: 7.144161, mean_absolute_error: 23.113964, mean_q: 25.872402
 65680/100000: episode: 210, duration: 7.594s, episode steps: 1000, steps per second: 132, episode reward: -109.378, mean reward: -0.109 [-4.895, 4.638], mean action: 1.689 [0.000, 3.000], mean observation: 0.150 [-0.535, 1.387], loss: 6.301977, mean_absolute_error: 23.364847, mean_q: 26.281641
 66680/100000: episode: 211, duration: 7.632s, episode steps: 1000, steps per second: 131, episode reward: -88.911, mean reward: -0.089 [-4.436, 4.481], mean action: 1.545 [0.000, 3.000], mean observation: 0.117 [-0.468, 1.389], loss: 5.504780, mean_absolute_error: 23.436152, mean_q: 27.136974
 67123/100000: episode: 212, duration: 2.824s, episode steps: 443, steps per second: 157, episode reward: -132.626, mean reward: -0.299 [-100.000, 3.925], mean action: 1.673 [0.000, 3.000], mean observation: 0.190 [-0.384, 1.394], loss: 5.371708, mean_absolute_error: 23.734016, mean_q: 27.834064
 68123/100000: episode: 213, duration: 8.216s, episode steps: 1000, steps per second: 122, episode reward: -78.392, mean reward: -0.078 [-5.714, 4.605], mean action: 1.658 [0.000, 3.000], mean observation: 0.134 [-0.568, 1.445], loss: 7.669458, mean_absolute_error: 24.114315, mean_q: 28.376163
 69123/100000: episode: 214, duration: 7.862s, episode steps: 1000, steps per second: 127, episode reward: -118.680, mean reward: -0.119 [-4.973, 4.368], mean action: 1.565 [0.000, 3.000], mean observation: 0.176 [-0.494, 1.388], loss: 5.661923, mean_absolute_error: 24.018114, mean_q: 29.224546
 70013/100000: episode: 215, duration: 7.217s, episode steps: 890, steps per second: 123, episode reward: -370.735, mean reward: -0.417 [-100.000, 11.629], mean action: 1.838 [0.000, 3.000], mean observation: 0.052 [-2.059, 1.419], loss: 6.772366, mean_absolute_error: 24.202190, mean_q: 29.759256
 71013/100000: episode: 216, duration: 7.366s, episode steps: 1000, steps per second: 136, episode reward: -92.787, mean reward: -0.093 [-10.230, 17.095], mean action: 1.749 [0.000, 3.000], mean observation: 0.134 [-1.239, 1.392], loss: 6.148084, mean_absolute_error: 24.549625, mean_q: 30.151934
 71811/100000: episode: 217, duration: 5.872s, episode steps: 798, steps per second: 136, episode reward: -353.942, mean reward: -0.444 [-100.000, 4.419], mean action: 1.712 [0.000, 3.000], mean observation: 0.148 [-0.517, 1.407], loss: 5.576774, mean_absolute_error: 25.054932, mean_q: 31.023232
 72466/100000: episode: 218, duration: 4.428s, episode steps: 655, steps per second: 148, episode reward: -405.072, mean reward: -0.618 [-100.000, 6.984], mean action: 1.733 [0.000, 3.000], mean observation: 0.145 [-1.335, 2.194], loss: 6.128646, mean_absolute_error: 25.047155, mean_q: 31.110191
 73290/100000: episode: 219, duration: 5.630s, episode steps: 824, steps per second: 146, episode reward: -124.587, mean reward: -0.151 [-100.000, 8.720], mean action: 1.824 [0.000, 3.000], mean observation: 0.021 [-1.218, 1.413], loss: 7.066061, mean_absolute_error: 25.681751, mean_q: 31.744707
 73736/100000: episode: 220, duration: 2.824s, episode steps: 446, steps per second: 158, episode reward: -405.847, mean reward: -0.910 [-100.000, 43.300], mean action: 1.664 [0.000, 3.000], mean observation: 0.123 [-0.908, 2.026], loss: 6.504619, mean_absolute_error: 25.884258, mean_q: 31.798464
 74736/100000: episode: 221, duration: 7.627s, episode steps: 1000, steps per second: 131, episode reward: -41.301, mean reward: -0.041 [-21.159, 13.776], mean action: 1.728 [0.000, 3.000], mean observation: 0.034 [-1.040, 1.439], loss: 7.007687, mean_absolute_error: 26.020041, mean_q: 31.935085
 75031/100000: episode: 222, duration: 1.746s, episode steps: 295, steps per second: 169, episode reward: -64.005, mean reward: -0.217 [-100.000, 11.824], mean action: 1.519 [0.000, 3.000], mean observation: 0.150 [-0.950, 1.408], loss: 7.517776, mean_absolute_error: 26.009619, mean_q: 31.972895
 75529/100000: episode: 223, duration: 3.239s, episode steps: 498, steps per second: 154, episode reward: -71.487, mean reward: -0.144 [-100.000, 7.882], mean action: 1.799 [0.000, 3.000], mean observation: 0.054 [-1.159, 1.436], loss: 6.098446, mean_absolute_error: 25.830341, mean_q: 31.715191
 76529/100000: episode: 224, duration: 7.633s, episode steps: 1000, steps per second: 131, episode reward: -83.069, mean reward: -0.083 [-4.815, 6.038], mean action: 1.721 [0.000, 3.000], mean observation: 0.063 [-0.976, 1.405], loss: 9.612940, mean_absolute_error: 25.967840, mean_q: 32.130798
 77529/100000: episode: 225, duration: 8.371s, episode steps: 1000, steps per second: 119, episode reward: -33.584, mean reward: -0.034 [-4.662, 4.939], mean action: 1.675 [0.000, 3.000], mean observation: 0.082 [-0.772, 1.399], loss: 6.537270, mean_absolute_error: 25.825907, mean_q: 32.129246
 78529/100000: episode: 226, duration: 7.666s, episode steps: 1000, steps per second: 130, episode reward: 1.670, mean reward: 0.002 [-4.827, 5.090], mean action: 1.514 [0.000, 3.000], mean observation: 0.103 [-0.511, 1.496], loss: 6.468633, mean_absolute_error: 25.670715, mean_q: 31.840431
 79529/100000: episode: 227, duration: 8.292s, episode steps: 1000, steps per second: 121, episode reward: -61.676, mean reward: -0.062 [-4.303, 4.802], mean action: 1.518 [0.000, 3.000], mean observation: 0.076 [-0.333, 1.412], loss: 5.509070, mean_absolute_error: 25.395870, mean_q: 31.828310
 80529/100000: episode: 228, duration: 8.226s, episode steps: 1000, steps per second: 122, episode reward: -50.649, mean reward: -0.051 [-4.585, 4.467], mean action: 1.503 [0.000, 3.000], mean observation: 0.083 [-0.432, 1.391], loss: 6.696219, mean_absolute_error: 25.279230, mean_q: 31.963844
 81529/100000: episode: 229, duration: 7.563s, episode steps: 1000, steps per second: 132, episode reward: -36.442, mean reward: -0.036 [-4.591, 5.988], mean action: 1.507 [0.000, 3.000], mean observation: 0.068 [-0.660, 1.409], loss: 5.518384, mean_absolute_error: 24.983561, mean_q: 31.759193
 82529/100000: episode: 230, duration: 8.149s, episode steps: 1000, steps per second: 123, episode reward: -42.873, mean reward: -0.043 [-4.408, 4.880], mean action: 1.518 [0.000, 3.000], mean observation: 0.069 [-0.494, 1.402], loss: 5.984758, mean_absolute_error: 24.521332, mean_q: 31.379324
 83529/100000: episode: 231, duration: 7.559s, episode steps: 1000, steps per second: 132, episode reward: -71.273, mean reward: -0.071 [-4.202, 4.461], mean action: 1.463 [0.000, 3.000], mean observation: 0.079 [-0.353, 1.411], loss: 6.404085, mean_absolute_error: 23.887695, mean_q: 30.634909
 84529/100000: episode: 232, duration: 7.390s, episode steps: 1000, steps per second: 135, episode reward: -58.354, mean reward: -0.058 [-5.499, 4.778], mean action: 1.387 [0.000, 3.000], mean observation: 0.103 [-0.441, 1.524], loss: 5.137019, mean_absolute_error: 23.510027, mean_q: 30.247835
 85529/100000: episode: 233, duration: 8.614s, episode steps: 1000, steps per second: 116, episode reward: -55.491, mean reward: -0.055 [-5.522, 5.292], mean action: 1.523 [0.000, 3.000], mean observation: 0.070 [-0.625, 1.396], loss: 6.019143, mean_absolute_error: 23.466570, mean_q: 30.104153
 86529/100000: episode: 234, duration: 7.285s, episode steps: 1000, steps per second: 137, episode reward: -81.112, mean reward: -0.081 [-4.900, 5.438], mean action: 1.461 [0.000, 3.000], mean observation: 0.095 [-0.532, 1.408], loss: 4.148644, mean_absolute_error: 23.458117, mean_q: 30.270206
 86707/100000: episode: 235, duration: 1.011s, episode steps: 178, steps per second: 176, episode reward: -11.662, mean reward: -0.066 [-100.000, 15.681], mean action: 1.646 [0.000, 3.000], mean observation: 0.062 [-1.805, 1.533], loss: 5.935389, mean_absolute_error: 23.642254, mean_q: 30.376184
 87707/100000: episode: 236, duration: 7.860s, episode steps: 1000, steps per second: 127, episode reward: -25.421, mean reward: -0.025 [-23.839, 13.491], mean action: 1.561 [0.000, 3.000], mean observation: 0.068 [-1.046, 1.396], loss: 4.573007, mean_absolute_error: 24.078091, mean_q: 31.003269
 88707/100000: episode: 237, duration: 8.245s, episode steps: 1000, steps per second: 121, episode reward: -59.498, mean reward: -0.059 [-4.960, 4.590], mean action: 1.542 [0.000, 3.000], mean observation: 0.076 [-0.316, 1.420], loss: 5.064845, mean_absolute_error: 24.348606, mean_q: 31.504007
 89707/100000: episode: 238, duration: 7.921s, episode steps: 1000, steps per second: 126, episode reward: -50.223, mean reward: -0.050 [-4.318, 4.429], mean action: 1.481 [0.000, 3.000], mean observation: 0.068 [-0.304, 1.403], loss: 4.323891, mean_absolute_error: 24.342726, mean_q: 31.762503
 90707/100000: episode: 239, duration: 8.174s, episode steps: 1000, steps per second: 122, episode reward: -21.379, mean reward: -0.021 [-4.759, 4.899], mean action: 1.537 [0.000, 3.000], mean observation: 0.060 [-0.574, 1.515], loss: 4.834086, mean_absolute_error: 24.539871, mean_q: 32.212818
 91707/100000: episode: 240, duration: 9.004s, episode steps: 1000, steps per second: 111, episode reward: -37.540, mean reward: -0.038 [-4.943, 4.882], mean action: 1.547 [0.000, 3.000], mean observation: 0.068 [-0.520, 1.387], loss: 5.424090, mean_absolute_error: 24.137489, mean_q: 31.582611
 92707/100000: episode: 241, duration: 7.322s, episode steps: 1000, steps per second: 137, episode reward: -23.529, mean reward: -0.024 [-4.686, 5.432], mean action: 1.642 [0.000, 3.000], mean observation: 0.067 [-0.353, 1.407], loss: 6.031919, mean_absolute_error: 24.027636, mean_q: 31.638266
 93707/100000: episode: 242, duration: 8.280s, episode steps: 1000, steps per second: 121, episode reward: -42.736, mean reward: -0.043 [-4.729, 4.724], mean action: 1.489 [0.000, 3.000], mean observation: 0.086 [-0.228, 1.441], loss: 3.950735, mean_absolute_error: 23.489929, mean_q: 31.025198
 94707/100000: episode: 243, duration: 8.999s, episode steps: 1000, steps per second: 111, episode reward: -59.864, mean reward: -0.060 [-3.959, 5.039], mean action: 1.487 [0.000, 3.000], mean observation: 0.046 [-0.320, 1.412], loss: 3.336474, mean_absolute_error: 23.207123, mean_q: 30.620163
 95707/100000: episode: 244, duration: 7.781s, episode steps: 1000, steps per second: 129, episode reward: -16.694, mean reward: -0.017 [-3.927, 5.245], mean action: 1.459 [0.000, 3.000], mean observation: 0.043 [-0.444, 1.405], loss: 3.272762, mean_absolute_error: 22.866146, mean_q: 30.081133
 96528/100000: episode: 245, duration: 7.019s, episode steps: 821, steps per second: 117, episode reward: -146.367, mean reward: -0.178 [-100.000, 12.386], mean action: 1.410 [0.000, 3.000], mean observation: 0.060 [-0.636, 1.401], loss: 5.314182, mean_absolute_error: 22.729784, mean_q: 29.826817
 97424/100000: episode: 246, duration: 6.428s, episode steps: 896, steps per second: 139, episode reward: 55.294, mean reward: 0.062 [-18.691, 100.000], mean action: 1.441 [0.000, 3.000], mean observation: 0.067 [-0.893, 1.416], loss: 2.145800, mean_absolute_error: 22.544710, mean_q: 29.574327
 98424/100000: episode: 247, duration: 7.896s, episode steps: 1000, steps per second: 127, episode reward: 1.455, mean reward: 0.001 [-21.551, 12.228], mean action: 1.485 [0.000, 3.000], mean observation: 0.051 [-0.525, 1.390], loss: 3.729285, mean_absolute_error: 22.549999, mean_q: 29.559494
 99424/100000: episode: 248, duration: 6.742s, episode steps: 1000, steps per second: 148, episode reward: 23.846, mean reward: 0.024 [-5.422, 5.529], mean action: 1.533 [0.000, 3.000], mean observation: 0.109 [-0.441, 1.521], loss: 4.644932, mean_absolute_error: 22.551384, mean_q: 29.483507
done, took 715.835 seconds
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-Result">Evaluation Result<a class="anchor-link" href="#Evaluation-Result">&#182;</a></h2><p>We are testing the above model for 50 episodes and then looking at the mean reward value</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Finally, evaluate our algorithm for 50 episodes.</span>
<span class="c1">#dqn3.test(env, nb_episodes=50, visualize=False)</span>

<span class="c1"># Finally, evaluate the agent</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">dqn3</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;episode_reward&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Test rewards (#episodes=</span><span class="si">{}</span><span class="s2">): mean=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, std=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, &quot;</span>
           <span class="s2">&quot;min=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, max=</span><span class="si">{:&gt;5.2f}</span><span class="s2">&quot;</span><span class="p">)</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>

<span class="n">rl_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 3&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Testing for 50 episodes ...
Episode 1: reward: -13.904, steps: 1000
Episode 2: reward: -27.567, steps: 1000
Episode 3: reward: 7.155, steps: 1000
Episode 4: reward: 3.874, steps: 1000
Episode 5: reward: -31.419, steps: 1000
Episode 6: reward: 5.493, steps: 1000
Episode 7: reward: -53.837, steps: 1000
Episode 8: reward: -58.262, steps: 1000
Episode 9: reward: -26.818, steps: 1000
Episode 10: reward: -22.521, steps: 1000
Episode 11: reward: -28.619, steps: 1000
Episode 12: reward: -2.943, steps: 1000
Episode 13: reward: -13.825, steps: 1000
Episode 14: reward: -25.618, steps: 1000
Episode 15: reward: -33.615, steps: 1000
Episode 16: reward: -52.710, steps: 1000
Episode 17: reward: -27.549, steps: 1000
Episode 18: reward: -17.004, steps: 1000
Episode 19: reward: -22.071, steps: 1000
Episode 20: reward: -48.325, steps: 1000
Episode 21: reward: -22.303, steps: 1000
Episode 22: reward: -122.199, steps: 1000
Episode 23: reward: -14.136, steps: 1000
Episode 24: reward: -1.940, steps: 1000
Episode 25: reward: 5.532, steps: 1000
Episode 26: reward: 2.651, steps: 1000
Episode 27: reward: 9.630, steps: 1000
Episode 28: reward: -58.978, steps: 1000
Episode 29: reward: -24.227, steps: 1000
Episode 30: reward: -4.735, steps: 1000
Episode 31: reward: 8.475, steps: 1000
Episode 32: reward: 6.765, steps: 1000
Episode 33: reward: -28.928, steps: 1000
Episode 34: reward: -4.325, steps: 1000
Episode 35: reward: -49.668, steps: 1000
Episode 36: reward: -34.281, steps: 1000
Episode 37: reward: -50.253, steps: 1000
Episode 38: reward: -13.484, steps: 1000
Episode 39: reward: -11.029, steps: 1000
Episode 40: reward: 16.911, steps: 1000
Episode 41: reward: -13.203, steps: 1000
Episode 42: reward: -21.237, steps: 1000
Episode 43: reward: -34.567, steps: 1000
Episode 44: reward: -113.670, steps: 1000
Episode 45: reward: -7.325, steps: 1000
Episode 46: reward: 18.306, steps: 1000
Episode 47: reward: -34.526, steps: 1000
Episode 48: reward: -37.748, steps: 1000
Episode 49: reward: -14.722, steps: 1000
Episode 50: reward: -13.186, steps: 1000
Test rewards (#episodes=50): mean=-23.05, std=27.63, min=-122.20, max=18.31
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-4">Model 4<a class="anchor-link" href="#Model-4">&#182;</a></h2><p><b> Model Architecture</b></p>
<p>We are using the similar architecture and process as <a href="#task2_model1">Model 1</a> but with different hyper-parameters <br/> 
<b>In this Model, we are changing value of learning rate of Adam optimizer to 0.001 and epsilon to 0.2</b></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get the environment and extract the number of actions.</span>
<span class="c1">#env = gym.make(ENV_NAME)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">nb_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Next, we build a very simple model.</span>
<span class="n">model4</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">))</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model4</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="c1"># Finally, we configure and compile our agent. You can use every built-in Keras optimizer and</span>
<span class="c1"># even the metrics!</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">SequentialMemory</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">window_length</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">EpsGreedyQPolicy</span><span class="p">(</span><span class="n">eps</span><span class="o">=.</span><span class="mi">2</span><span class="p">)</span>
<span class="n">dqn4</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model4</span><span class="p">,</span> <span class="n">nb_actions</span><span class="o">=</span><span class="n">nb_actions</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="n">nb_steps_warmup</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
               <span class="n">target_model_update</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">)</span>
<span class="n">dqn4</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mae&#39;</span><span class="p">])</span>

<span class="c1"># Okay, now it&#39;s time to learn something! We visualize the training here for show, but this</span>
<span class="c1"># slows down training quite a lot. You can always safely abort the training prematurely using</span>
<span class="c1"># Ctrl + C.</span>
<span class="n">start</span><span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">dqn4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_steps</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">timetaken</span><span class="o">=</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
<span class="n">rl_model_time_comparisons</span><span class="p">[</span><span class="s1">&#39;Model 4&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">timetaken</span>
<span class="c1"># After training is done, we save the final weights.</span>
<span class="n">dqn4</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;dqn_</span><span class="si">{}</span><span class="s1">_weights_model4.h5f&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ENV_NAME</span><span class="p">),</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_4 (Flatten)          (None, 8)                 0         
_________________________________________________________________
dense_13 (Dense)             (None, 16)                144       
_________________________________________________________________
activation_13 (Activation)   (None, 16)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 16)                272       
_________________________________________________________________
activation_14 (Activation)   (None, 16)                0         
_________________________________________________________________
dense_15 (Dense)             (None, 16)                272       
_________________________________________________________________
activation_15 (Activation)   (None, 16)                0         
_________________________________________________________________
dense_16 (Dense)             (None, 4)                 68        
_________________________________________________________________
activation_16 (Activation)   (None, 4)                 0         
=================================================================
Total params: 756
Trainable params: 756
Non-trainable params: 0
_________________________________________________________________
None
Training for 100000 steps ...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/anaconda3/lib/python3.6/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!
  warnings.warn(&#39;Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!&#39;)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>    91/100000: episode: 1, duration: 2.253s, episode steps: 91, steps per second: 40, episode reward: -164.688, mean reward: -1.810 [-100.000, 11.862], mean action: 2.011 [0.000, 3.000], mean observation: 0.034 [-5.194, 1.399], loss: 3.954690, mean_absolute_error: 0.694446, mean_q: 0.109807
   164/100000: episode: 2, duration: 0.426s, episode steps: 73, steps per second: 171, episode reward: -385.565, mean reward: -5.282 [-100.000, 1.582], mean action: 2.192 [0.000, 3.000], mean observation: -0.270 [-2.727, 1.412], loss: 36.663620, mean_absolute_error: 1.179321, mean_q: 0.310515
   227/100000: episode: 3, duration: 0.353s, episode steps: 63, steps per second: 179, episode reward: -219.585, mean reward: -3.485 [-100.000, 80.575], mean action: 1.413 [0.000, 3.000], mean observation: -0.131 [-3.759, 1.398], loss: 50.023174, mean_absolute_error: 1.532596, mean_q: 0.154763
   291/100000: episode: 4, duration: 0.354s, episode steps: 64, steps per second: 181, episode reward: -258.153, mean reward: -4.034 [-100.000, 27.953], mean action: 0.516 [0.000, 3.000], mean observation: -0.008 [-3.250, 1.402], loss: 76.453712, mean_absolute_error: 2.150755, mean_q: -0.637932
   593/100000: episode: 5, duration: 1.860s, episode steps: 302, steps per second: 162, episode reward: -237.582, mean reward: -0.787 [-100.000, 4.016], mean action: 1.765 [0.000, 3.000], mean observation: 0.223 [-1.185, 2.074], loss: 39.160492, mean_absolute_error: 3.703890, mean_q: -2.844184
   664/100000: episode: 6, duration: 0.410s, episode steps: 71, steps per second: 173, episode reward: -150.435, mean reward: -2.119 [-100.000, 8.218], mean action: 1.859 [0.000, 3.000], mean observation: -0.125 [-1.768, 4.297], loss: 19.582897, mean_absolute_error: 4.052436, mean_q: -2.986958
   757/100000: episode: 7, duration: 0.535s, episode steps: 93, steps per second: 174, episode reward: -104.524, mean reward: -1.124 [-100.000, 13.848], mean action: 1.839 [0.000, 3.000], mean observation: -0.008 [-1.731, 1.507], loss: 23.476366, mean_absolute_error: 4.171351, mean_q: -3.319031
   814/100000: episode: 8, duration: 0.329s, episode steps: 57, steps per second: 173, episode reward: -106.342, mean reward: -1.866 [-100.000, 6.988], mean action: 2.018 [0.000, 3.000], mean observation: -0.063 [-1.756, 6.089], loss: 26.366758, mean_absolute_error: 4.612823, mean_q: -3.629078
   887/100000: episode: 9, duration: 0.421s, episode steps: 73, steps per second: 174, episode reward: -129.591, mean reward: -1.775 [-100.000, 7.229], mean action: 1.890 [0.000, 3.000], mean observation: -0.063 [-1.703, 6.117], loss: 10.682105, mean_absolute_error: 4.407564, mean_q: -3.703292
   969/100000: episode: 10, duration: 0.466s, episode steps: 82, steps per second: 176, episode reward: -131.689, mean reward: -1.606 [-100.000, 5.672], mean action: 1.671 [0.000, 3.000], mean observation: -0.104 [-1.677, 5.825], loss: 26.265703, mean_absolute_error: 4.883612, mean_q: -4.199272
  1155/100000: episode: 11, duration: 1.117s, episode steps: 186, steps per second: 167, episode reward: -50.930, mean reward: -0.274 [-100.000, 12.165], mean action: 1.855 [0.000, 3.000], mean observation: 0.130 [-0.728, 1.473], loss: 26.104937, mean_absolute_error: 5.213295, mean_q: -4.644275
  2155/100000: episode: 12, duration: 8.587s, episode steps: 1000, steps per second: 116, episode reward: -132.704, mean reward: -0.133 [-4.765, 4.549], mean action: 1.893 [0.000, 3.000], mean observation: 0.214 [-0.322, 1.730], loss: 11.414523, mean_absolute_error: 5.392057, mean_q: -4.674569
  2410/100000: episode: 13, duration: 1.611s, episode steps: 255, steps per second: 158, episode reward: -128.426, mean reward: -0.504 [-100.000, 4.429], mean action: 1.765 [0.000, 3.000], mean observation: 0.151 [-1.986, 1.398], loss: 6.553144, mean_absolute_error: 5.458738, mean_q: -3.050758
  3074/100000: episode: 14, duration: 5.050s, episode steps: 664, steps per second: 131, episode reward: -201.050, mean reward: -0.303 [-100.000, 18.574], mean action: 1.779 [0.000, 3.000], mean observation: 0.118 [-1.276, 2.306], loss: 7.029982, mean_absolute_error: 7.157750, mean_q: -1.648511
  3389/100000: episode: 15, duration: 1.961s, episode steps: 315, steps per second: 161, episode reward: -3.192, mean reward: -0.010 [-100.000, 17.148], mean action: 1.590 [0.000, 3.000], mean observation: 0.073 [-1.595, 1.403], loss: 5.076928, mean_absolute_error: 8.821388, mean_q: 0.021128
  3794/100000: episode: 16, duration: 2.508s, episode steps: 405, steps per second: 161, episode reward: -84.995, mean reward: -0.210 [-100.000, 9.264], mean action: 1.528 [0.000, 3.000], mean observation: 0.180 [-0.920, 3.498], loss: 5.539587, mean_absolute_error: 10.691497, mean_q: 0.830696
  4128/100000: episode: 17, duration: 2.006s, episode steps: 334, steps per second: 167, episode reward: -61.279, mean reward: -0.183 [-100.000, 18.283], mean action: 1.503 [0.000, 3.000], mean observation: 0.174 [-0.776, 1.439], loss: 4.262976, mean_absolute_error: 12.119099, mean_q: 2.554474
  4569/100000: episode: 18, duration: 3.158s, episode steps: 441, steps per second: 140, episode reward: -107.090, mean reward: -0.243 [-100.000, 9.755], mean action: 1.580 [0.000, 3.000], mean observation: 0.108 [-2.564, 1.394], loss: 5.451956, mean_absolute_error: 13.539908, mean_q: 4.040601
  5289/100000: episode: 19, duration: 5.593s, episode steps: 720, steps per second: 129, episode reward: -442.873, mean reward: -0.615 [-100.000, 14.129], mean action: 1.486 [0.000, 3.000], mean observation: 0.086 [-1.520, 2.219], loss: 3.674706, mean_absolute_error: 15.421574, mean_q: 5.956158
  5413/100000: episode: 20, duration: 0.753s, episode steps: 124, steps per second: 165, episode reward: -145.705, mean reward: -1.175 [-100.000, 3.601], mean action: 1.637 [0.000, 3.000], mean observation: -0.045 [-1.000, 1.386], loss: 4.804883, mean_absolute_error: 18.799332, mean_q: 3.791821
  5520/100000: episode: 21, duration: 0.629s, episode steps: 107, steps per second: 170, episode reward: -132.854, mean reward: -1.242 [-100.000, 2.950], mean action: 1.766 [0.000, 3.000], mean observation: -0.100 [-1.126, 1.389], loss: 7.418167, mean_absolute_error: 19.351202, mean_q: 4.294782
  6058/100000: episode: 22, duration: 3.870s, episode steps: 538, steps per second: 139, episode reward: -205.855, mean reward: -0.383 [-100.000, 8.283], mean action: 1.576 [0.000, 3.000], mean observation: 0.046 [-1.023, 1.399], loss: 6.436396, mean_absolute_error: 19.870731, mean_q: 5.576898
  6342/100000: episode: 23, duration: 1.731s, episode steps: 284, steps per second: 164, episode reward: -157.885, mean reward: -0.556 [-100.000, 21.576], mean action: 1.606 [0.000, 3.000], mean observation: 0.008 [-2.082, 1.408], loss: 6.257845, mean_absolute_error: 20.766279, mean_q: 6.129399
  6582/100000: episode: 24, duration: 1.444s, episode steps: 240, steps per second: 166, episode reward: -180.941, mean reward: -0.754 [-100.000, 3.201], mean action: 1.867 [0.000, 3.000], mean observation: 0.087 [-1.005, 1.591], loss: 5.436505, mean_absolute_error: 21.140045, mean_q: 6.570560
  6879/100000: episode: 25, duration: 1.875s, episode steps: 297, steps per second: 158, episode reward: -164.978, mean reward: -0.555 [-100.000, 12.892], mean action: 1.646 [0.000, 3.000], mean observation: 0.017 [-2.487, 1.457], loss: 7.978765, mean_absolute_error: 21.640667, mean_q: 8.195125
  7114/100000: episode: 26, duration: 1.396s, episode steps: 235, steps per second: 168, episode reward: -154.460, mean reward: -0.657 [-100.000, 4.135], mean action: 1.621 [0.000, 3.000], mean observation: 0.006 [-1.007, 1.442], loss: 4.082796, mean_absolute_error: 22.028534, mean_q: 8.969187
  7382/100000: episode: 27, duration: 1.637s, episode steps: 268, steps per second: 164, episode reward: -208.862, mean reward: -0.779 [-100.000, 2.907], mean action: 1.649 [0.000, 3.000], mean observation: 0.015 [-1.006, 1.428], loss: 6.871788, mean_absolute_error: 22.237406, mean_q: 9.589925
  7541/100000: episode: 28, duration: 0.926s, episode steps: 159, steps per second: 172, episode reward: -195.211, mean reward: -1.228 [-100.000, 3.230], mean action: 1.503 [0.000, 3.000], mean observation: -0.055 [-1.075, 1.386], loss: 4.936656, mean_absolute_error: 22.765383, mean_q: 9.789255
  8018/100000: episode: 29, duration: 3.144s, episode steps: 477, steps per second: 152, episode reward: -208.359, mean reward: -0.437 [-100.000, 5.043], mean action: 1.591 [0.000, 3.000], mean observation: 0.085 [-1.011, 1.463], loss: 5.740035, mean_absolute_error: 22.946516, mean_q: 10.437573
  8340/100000: episode: 30, duration: 2.049s, episode steps: 322, steps per second: 157, episode reward: -227.019, mean reward: -0.705 [-100.000, 4.470], mean action: 1.668 [0.000, 3.000], mean observation: 0.047 [-1.050, 1.387], loss: 5.685569, mean_absolute_error: 23.315964, mean_q: 10.194123
  8472/100000: episode: 31, duration: 0.759s, episode steps: 132, steps per second: 174, episode reward: -147.931, mean reward: -1.121 [-100.000, 7.297], mean action: 1.250 [0.000, 3.000], mean observation: -0.083 [-4.011, 1.388], loss: 6.207466, mean_absolute_error: 23.896080, mean_q: 9.940652
  8731/100000: episode: 32, duration: 1.637s, episode steps: 259, steps per second: 158, episode reward: -177.701, mean reward: -0.686 [-100.000, 8.173], mean action: 1.799 [0.000, 3.000], mean observation: 0.031 [-1.905, 1.390], loss: 5.622989, mean_absolute_error: 23.676758, mean_q: 10.833158
  9043/100000: episode: 33, duration: 1.914s, episode steps: 312, steps per second: 163, episode reward: -122.449, mean reward: -0.392 [-100.000, 6.770], mean action: 1.484 [0.000, 3.000], mean observation: 0.205 [-0.645, 1.396], loss: 3.826724, mean_absolute_error: 23.897980, mean_q: 9.046526
  9324/100000: episode: 34, duration: 1.718s, episode steps: 281, steps per second: 164, episode reward: -198.025, mean reward: -0.705 [-100.000, 4.844], mean action: 1.754 [0.000, 3.000], mean observation: 0.059 [-1.005, 1.479], loss: 3.255915, mean_absolute_error: 24.241943, mean_q: 9.079861
  9584/100000: episode: 35, duration: 1.586s, episode steps: 260, steps per second: 164, episode reward: -219.086, mean reward: -0.843 [-100.000, 4.167], mean action: 1.765 [0.000, 3.000], mean observation: 0.038 [-1.006, 1.392], loss: 4.229342, mean_absolute_error: 24.735317, mean_q: 9.335597
  9897/100000: episode: 36, duration: 1.981s, episode steps: 313, steps per second: 158, episode reward: -237.078, mean reward: -0.757 [-100.000, 3.620], mean action: 1.859 [0.000, 3.000], mean observation: 0.061 [-1.005, 1.404], loss: 2.678732, mean_absolute_error: 24.709126, mean_q: 8.866346
 10148/100000: episode: 37, duration: 1.527s, episode steps: 251, steps per second: 164, episode reward: -269.116, mean reward: -1.072 [-100.000, 2.703], mean action: 1.709 [0.000, 3.000], mean observation: 0.044 [-1.007, 1.412], loss: 7.755031, mean_absolute_error: 24.887255, mean_q: 9.400905
 10419/100000: episode: 38, duration: 1.655s, episode steps: 271, steps per second: 164, episode reward: -265.784, mean reward: -0.981 [-100.000, 3.439], mean action: 1.771 [0.000, 3.000], mean observation: 0.073 [-1.009, 1.420], loss: 3.577174, mean_absolute_error: 25.103216, mean_q: 9.344261
 10643/100000: episode: 39, duration: 1.341s, episode steps: 224, steps per second: 167, episode reward: -206.774, mean reward: -0.923 [-100.000, 2.366], mean action: 1.786 [0.000, 3.000], mean observation: 0.051 [-1.000, 1.471], loss: 4.528108, mean_absolute_error: 24.984619, mean_q: 9.507453
 10848/100000: episode: 40, duration: 1.234s, episode steps: 205, steps per second: 166, episode reward: -227.638, mean reward: -1.110 [-100.000, 2.230], mean action: 1.717 [0.000, 3.000], mean observation: 0.043 [-1.008, 1.418], loss: 3.609852, mean_absolute_error: 25.027056, mean_q: 9.613324
 11025/100000: episode: 41, duration: 1.051s, episode steps: 177, steps per second: 168, episode reward: -191.148, mean reward: -1.080 [-100.000, 3.259], mean action: 1.701 [0.000, 3.000], mean observation: 0.028 [-1.003, 1.472], loss: 5.767237, mean_absolute_error: 25.568464, mean_q: 8.609100
 11227/100000: episode: 42, duration: 1.187s, episode steps: 202, steps per second: 170, episode reward: -210.641, mean reward: -1.043 [-100.000, 4.297], mean action: 1.723 [0.000, 3.000], mean observation: 0.056 [-1.009, 1.456], loss: 4.056467, mean_absolute_error: 25.187309, mean_q: 8.362537
 11572/100000: episode: 43, duration: 2.133s, episode steps: 345, steps per second: 162, episode reward: -244.520, mean reward: -0.709 [-100.000, 4.858], mean action: 1.768 [0.000, 3.000], mean observation: 0.098 [-1.008, 1.410], loss: 4.439704, mean_absolute_error: 25.715218, mean_q: 7.620511
 11913/100000: episode: 44, duration: 2.112s, episode steps: 341, steps per second: 161, episode reward: -213.913, mean reward: -0.627 [-100.000, 5.513], mean action: 1.859 [0.000, 3.000], mean observation: 0.091 [-1.008, 1.415], loss: 3.758111, mean_absolute_error: 25.870478, mean_q: 7.572056
 12276/100000: episode: 45, duration: 2.195s, episode steps: 363, steps per second: 165, episode reward: -203.960, mean reward: -0.562 [-100.000, 4.063], mean action: 1.647 [0.000, 3.000], mean observation: 0.094 [-1.013, 1.442], loss: 3.392127, mean_absolute_error: 26.401741, mean_q: 7.427564
 12526/100000: episode: 46, duration: 1.478s, episode steps: 250, steps per second: 169, episode reward: -223.417, mean reward: -0.894 [-100.000, 1.705], mean action: 1.444 [0.000, 3.000], mean observation: 0.055 [-1.007, 1.434], loss: 3.823936, mean_absolute_error: 26.369530, mean_q: 6.021402
 12763/100000: episode: 47, duration: 1.467s, episode steps: 237, steps per second: 162, episode reward: -236.371, mean reward: -0.997 [-100.000, 3.579], mean action: 1.709 [0.000, 3.000], mean observation: 0.038 [-1.076, 1.388], loss: 4.121385, mean_absolute_error: 26.545681, mean_q: 5.940145
 13290/100000: episode: 48, duration: 3.946s, episode steps: 527, steps per second: 134, episode reward: -281.503, mean reward: -0.534 [-100.000, 4.375], mean action: 1.634 [0.000, 3.000], mean observation: 0.106 [-1.000, 1.402], loss: 3.725615, mean_absolute_error: 26.896881, mean_q: 5.056015
 13488/100000: episode: 49, duration: 1.167s, episode steps: 198, steps per second: 170, episode reward: -193.254, mean reward: -0.976 [-100.000, 1.704], mean action: 1.652 [0.000, 3.000], mean observation: 0.030 [-1.007, 1.405], loss: 3.642018, mean_absolute_error: 26.599413, mean_q: 4.885186
 14329/100000: episode: 50, duration: 6.362s, episode steps: 841, steps per second: 132, episode reward: -303.259, mean reward: -0.361 [-100.000, 5.522], mean action: 1.717 [0.000, 3.000], mean observation: 0.125 [-1.005, 1.428], loss: 3.315008, mean_absolute_error: 27.059128, mean_q: 4.097411
 14602/100000: episode: 51, duration: 1.655s, episode steps: 273, steps per second: 165, episode reward: -166.192, mean reward: -0.609 [-100.000, 3.198], mean action: 1.495 [0.000, 3.000], mean observation: 0.255 [-0.502, 1.398], loss: 3.603604, mean_absolute_error: 27.537350, mean_q: 3.096378
 15039/100000: episode: 52, duration: 2.874s, episode steps: 437, steps per second: 152, episode reward: -228.265, mean reward: -0.522 [-100.000, 3.613], mean action: 1.719 [0.000, 3.000], mean observation: 0.219 [-0.355, 1.436], loss: 3.476785, mean_absolute_error: 27.413088, mean_q: 3.354829
 15500/100000: episode: 53, duration: 2.956s, episode steps: 461, steps per second: 156, episode reward: -210.912, mean reward: -0.458 [-100.000, 4.658], mean action: 1.777 [0.000, 3.000], mean observation: 0.212 [-0.421, 1.503], loss: 3.245883, mean_absolute_error: 27.763269, mean_q: 2.898986
 16389/100000: episode: 54, duration: 7.419s, episode steps: 889, steps per second: 120, episode reward: -227.530, mean reward: -0.256 [-100.000, 4.625], mean action: 1.766 [0.000, 3.000], mean observation: 0.177 [-0.501, 1.560], loss: 3.578651, mean_absolute_error: 27.760555, mean_q: 3.306619
 16831/100000: episode: 55, duration: 3.008s, episode steps: 442, steps per second: 147, episode reward: -138.307, mean reward: -0.313 [-100.000, 4.821], mean action: 1.801 [0.000, 3.000], mean observation: 0.163 [-0.742, 1.391], loss: 3.046058, mean_absolute_error: 27.323460, mean_q: 3.660083
 17088/100000: episode: 56, duration: 1.557s, episode steps: 257, steps per second: 165, episode reward: -178.598, mean reward: -0.695 [-100.000, 3.856], mean action: 1.599 [0.000, 3.000], mean observation: 0.235 [-0.231, 1.402], loss: 4.409029, mean_absolute_error: 27.528128, mean_q: 3.638234
 17415/100000: episode: 57, duration: 2.057s, episode steps: 327, steps per second: 159, episode reward: -133.524, mean reward: -0.408 [-100.000, 3.019], mean action: 1.761 [0.000, 3.000], mean observation: 0.216 [-0.472, 1.397], loss: 3.271354, mean_absolute_error: 27.429646, mean_q: 3.149706
 17822/100000: episode: 58, duration: 2.634s, episode steps: 407, steps per second: 155, episode reward: -212.250, mean reward: -0.521 [-100.000, 3.500], mean action: 1.757 [0.000, 3.000], mean observation: 0.207 [-0.187, 1.417], loss: 3.450402, mean_absolute_error: 27.261034, mean_q: 2.613321
 18145/100000: episode: 59, duration: 1.973s, episode steps: 323, steps per second: 164, episode reward: -149.739, mean reward: -0.464 [-100.000, 5.114], mean action: 1.712 [0.000, 3.000], mean observation: 0.237 [-0.237, 1.513], loss: 2.659300, mean_absolute_error: 27.573450, mean_q: 2.221550
 18409/100000: episode: 60, duration: 1.605s, episode steps: 264, steps per second: 164, episode reward: -124.099, mean reward: -0.470 [-100.000, 4.702], mean action: 1.765 [0.000, 3.000], mean observation: 0.254 [-0.239, 1.525], loss: 2.379268, mean_absolute_error: 27.336851, mean_q: 2.954710
 18790/100000: episode: 61, duration: 2.577s, episode steps: 381, steps per second: 148, episode reward: -133.608, mean reward: -0.351 [-100.000, 4.514], mean action: 1.853 [0.000, 3.000], mean observation: 0.185 [-0.595, 1.386], loss: 2.525286, mean_absolute_error: 27.131756, mean_q: 3.113486
 19654/100000: episode: 62, duration: 7.636s, episode steps: 864, steps per second: 113, episode reward: -215.659, mean reward: -0.250 [-100.000, 4.831], mean action: 1.779 [0.000, 3.000], mean observation: 0.153 [-0.518, 1.387], loss: 2.760403, mean_absolute_error: 26.793406, mean_q: 3.551421
 19981/100000: episode: 63, duration: 2.043s, episode steps: 327, steps per second: 160, episode reward: -150.855, mean reward: -0.461 [-100.000, 3.598], mean action: 1.765 [0.000, 3.000], mean observation: 0.213 [-0.225, 1.492], loss: 2.083491, mean_absolute_error: 27.066786, mean_q: 4.932548
 20204/100000: episode: 64, duration: 1.335s, episode steps: 223, steps per second: 167, episode reward: -84.982, mean reward: -0.381 [-100.000, 3.882], mean action: 1.798 [0.000, 3.000], mean observation: 0.243 [-0.495, 1.397], loss: 3.009456, mean_absolute_error: 27.364683, mean_q: 4.057091
 20527/100000: episode: 65, duration: 2.018s, episode steps: 323, steps per second: 160, episode reward: -207.733, mean reward: -0.643 [-100.000, 3.273], mean action: 1.731 [0.000, 3.000], mean observation: 0.207 [-0.202, 1.406], loss: 2.708881, mean_absolute_error: 27.065016, mean_q: 3.926071
 21260/100000: episode: 66, duration: 6.313s, episode steps: 733, steps per second: 116, episode reward: -212.830, mean reward: -0.290 [-100.000, 4.239], mean action: 1.715 [0.000, 3.000], mean observation: 0.148 [-0.603, 1.421], loss: 2.494695, mean_absolute_error: 26.997820, mean_q: 3.689199
 21856/100000: episode: 67, duration: 4.017s, episode steps: 596, steps per second: 148, episode reward: -211.998, mean reward: -0.356 [-100.000, 4.365], mean action: 1.789 [0.000, 3.000], mean observation: 0.206 [-0.225, 1.411], loss: 2.663640, mean_absolute_error: 27.001890, mean_q: 3.952434
 22564/100000: episode: 68, duration: 5.516s, episode steps: 708, steps per second: 128, episode reward: -202.183, mean reward: -0.286 [-100.000, 4.547], mean action: 1.719 [0.000, 3.000], mean observation: 0.154 [-0.587, 1.386], loss: 2.785996, mean_absolute_error: 26.852825, mean_q: 3.639093
 23213/100000: episode: 69, duration: 4.901s, episode steps: 649, steps per second: 132, episode reward: -181.876, mean reward: -0.280 [-100.000, 4.040], mean action: 1.675 [0.000, 3.000], mean observation: 0.185 [-0.531, 1.563], loss: 2.213788, mean_absolute_error: 26.594704, mean_q: 3.341329
 24174/100000: episode: 70, duration: 7.007s, episode steps: 961, steps per second: 137, episode reward: -210.939, mean reward: -0.219 [-100.000, 3.780], mean action: 1.725 [0.000, 3.000], mean observation: 0.157 [-0.731, 1.459], loss: 1.978356, mean_absolute_error: 26.358400, mean_q: 3.228928
 25174/100000: episode: 71, duration: 8.598s, episode steps: 1000, steps per second: 116, episode reward: -169.371, mean reward: -0.169 [-5.146, 4.009], mean action: 1.655 [0.000, 3.000], mean observation: 0.173 [-0.186, 1.411], loss: 2.349763, mean_absolute_error: 25.569092, mean_q: 3.196912
 25944/100000: episode: 72, duration: 6.558s, episode steps: 770, steps per second: 117, episode reward: -230.157, mean reward: -0.299 [-100.000, 4.183], mean action: 1.771 [0.000, 3.000], mean observation: 0.170 [-0.385, 1.396], loss: 2.338580, mean_absolute_error: 25.276876, mean_q: 2.347241
 26944/100000: episode: 73, duration: 8.132s, episode steps: 1000, steps per second: 123, episode reward: -87.127, mean reward: -0.087 [-5.019, 5.199], mean action: 1.638 [0.000, 3.000], mean observation: 0.130 [-0.733, 1.453], loss: 2.276031, mean_absolute_error: 24.851059, mean_q: 1.767198
 27944/100000: episode: 74, duration: 7.619s, episode steps: 1000, steps per second: 131, episode reward: -77.221, mean reward: -0.077 [-4.522, 5.048], mean action: 1.781 [0.000, 3.000], mean observation: 0.156 [-0.485, 1.404], loss: 2.353066, mean_absolute_error: 23.979277, mean_q: 1.988024
 28944/100000: episode: 75, duration: 7.796s, episode steps: 1000, steps per second: 128, episode reward: -84.224, mean reward: -0.084 [-4.342, 4.510], mean action: 1.744 [0.000, 3.000], mean observation: 0.118 [-0.408, 1.393], loss: 2.341088, mean_absolute_error: 23.165319, mean_q: 2.383965
 29944/100000: episode: 76, duration: 7.712s, episode steps: 1000, steps per second: 130, episode reward: -76.036, mean reward: -0.076 [-4.808, 5.358], mean action: 1.701 [0.000, 3.000], mean observation: 0.160 [-0.283, 1.509], loss: 2.301399, mean_absolute_error: 22.625322, mean_q: 2.833976
 30944/100000: episode: 77, duration: 8.082s, episode steps: 1000, steps per second: 124, episode reward: -69.790, mean reward: -0.070 [-4.470, 4.632], mean action: 1.732 [0.000, 3.000], mean observation: 0.114 [-0.585, 1.483], loss: 2.559685, mean_absolute_error: 22.339523, mean_q: 2.913090
 31944/100000: episode: 78, duration: 8.567s, episode steps: 1000, steps per second: 117, episode reward: -70.471, mean reward: -0.070 [-4.460, 4.779], mean action: 1.672 [0.000, 3.000], mean observation: 0.120 [-0.315, 1.398], loss: 2.518329, mean_absolute_error: 21.738281, mean_q: 3.381934
 32944/100000: episode: 79, duration: 7.492s, episode steps: 1000, steps per second: 133, episode reward: -113.143, mean reward: -0.113 [-5.098, 4.809], mean action: 1.655 [0.000, 3.000], mean observation: 0.108 [-0.312, 1.405], loss: 2.255498, mean_absolute_error: 21.416925, mean_q: 4.070453
 33944/100000: episode: 80, duration: 7.427s, episode steps: 1000, steps per second: 135, episode reward: -43.993, mean reward: -0.044 [-4.621, 5.291], mean action: 1.665 [0.000, 3.000], mean observation: 0.123 [-0.664, 1.391], loss: 2.347197, mean_absolute_error: 20.823246, mean_q: 3.901532
 34944/100000: episode: 81, duration: 8.476s, episode steps: 1000, steps per second: 118, episode reward: -99.729, mean reward: -0.100 [-4.536, 4.407], mean action: 1.612 [0.000, 3.000], mean observation: 0.117 [-0.289, 1.400], loss: 1.912264, mean_absolute_error: 20.285748, mean_q: 4.136681
 35944/100000: episode: 82, duration: 7.652s, episode steps: 1000, steps per second: 131, episode reward: -87.121, mean reward: -0.087 [-4.772, 4.065], mean action: 1.626 [0.000, 3.000], mean observation: 0.118 [-0.251, 1.435], loss: 1.843177, mean_absolute_error: 19.749666, mean_q: 5.311347
 36944/100000: episode: 83, duration: 7.753s, episode steps: 1000, steps per second: 129, episode reward: -51.362, mean reward: -0.051 [-4.540, 6.099], mean action: 1.752 [0.000, 3.000], mean observation: 0.118 [-0.476, 1.520], loss: 2.215145, mean_absolute_error: 19.301441, mean_q: 5.798590
 37278/100000: episode: 84, duration: 2.127s, episode steps: 334, steps per second: 157, episode reward: -660.977, mean reward: -1.979 [-100.000, 5.375], mean action: 1.838 [0.000, 3.000], mean observation: 0.273 [-0.963, 4.499], loss: 2.344481, mean_absolute_error: 19.378910, mean_q: 6.554420
 38278/100000: episode: 85, duration: 8.961s, episode steps: 1000, steps per second: 112, episode reward: -116.381, mean reward: -0.116 [-4.572, 4.433], mean action: 1.738 [0.000, 3.000], mean observation: 0.112 [-0.311, 1.411], loss: 1.765229, mean_absolute_error: 19.085438, mean_q: 7.176369
 39278/100000: episode: 86, duration: 7.736s, episode steps: 1000, steps per second: 129, episode reward: -91.277, mean reward: -0.091 [-4.652, 4.744], mean action: 1.738 [0.000, 3.000], mean observation: 0.115 [-0.327, 1.410], loss: 2.868146, mean_absolute_error: 18.897224, mean_q: 7.043236
 40278/100000: episode: 87, duration: 8.376s, episode steps: 1000, steps per second: 119, episode reward: -56.961, mean reward: -0.057 [-4.560, 4.848], mean action: 1.722 [0.000, 3.000], mean observation: 0.084 [-0.361, 1.414], loss: 2.415416, mean_absolute_error: 18.347578, mean_q: 7.892896
 41278/100000: episode: 88, duration: 8.911s, episode steps: 1000, steps per second: 112, episode reward: -72.980, mean reward: -0.073 [-4.592, 4.610], mean action: 1.725 [0.000, 3.000], mean observation: 0.082 [-0.508, 1.414], loss: 1.791412, mean_absolute_error: 18.139887, mean_q: 7.568158
 42278/100000: episode: 89, duration: 9.314s, episode steps: 1000, steps per second: 107, episode reward: -48.858, mean reward: -0.049 [-4.832, 4.365], mean action: 1.773 [0.000, 3.000], mean observation: 0.091 [-0.500, 1.398], loss: 2.972843, mean_absolute_error: 17.891766, mean_q: 7.798575
 43278/100000: episode: 90, duration: 7.454s, episode steps: 1000, steps per second: 134, episode reward: -19.793, mean reward: -0.020 [-4.806, 4.259], mean action: 1.699 [0.000, 3.000], mean observation: 0.087 [-0.584, 1.476], loss: 2.039524, mean_absolute_error: 17.693001, mean_q: 8.147269
 44278/100000: episode: 91, duration: 8.599s, episode steps: 1000, steps per second: 116, episode reward: -35.716, mean reward: -0.036 [-4.710, 4.207], mean action: 1.709 [0.000, 3.000], mean observation: 0.092 [-0.343, 1.457], loss: 2.401630, mean_absolute_error: 17.603905, mean_q: 8.016111
 45278/100000: episode: 92, duration: 8.379s, episode steps: 1000, steps per second: 119, episode reward: -11.757, mean reward: -0.012 [-4.532, 5.231], mean action: 1.834 [0.000, 3.000], mean observation: 0.067 [-0.680, 1.387], loss: 2.629405, mean_absolute_error: 17.363396, mean_q: 8.334690
 46278/100000: episode: 93, duration: 8.407s, episode steps: 1000, steps per second: 119, episode reward: -33.956, mean reward: -0.034 [-4.390, 4.785], mean action: 1.687 [0.000, 3.000], mean observation: 0.100 [-0.338, 1.483], loss: 2.324131, mean_absolute_error: 17.018440, mean_q: 9.088146
 47278/100000: episode: 94, duration: 7.518s, episode steps: 1000, steps per second: 133, episode reward: -116.562, mean reward: -0.117 [-4.806, 4.707], mean action: 1.779 [0.000, 3.000], mean observation: 0.116 [-0.388, 1.402], loss: 2.816500, mean_absolute_error: 17.064980, mean_q: 9.076271
 47481/100000: episode: 95, duration: 1.202s, episode steps: 203, steps per second: 169, episode reward: 6.221, mean reward: 0.031 [-100.000, 33.036], mean action: 1.768 [0.000, 3.000], mean observation: 0.162 [-0.718, 1.474], loss: 1.807763, mean_absolute_error: 16.746778, mean_q: 9.440696
 48481/100000: episode: 96, duration: 7.351s, episode steps: 1000, steps per second: 136, episode reward: -41.374, mean reward: -0.041 [-5.218, 4.307], mean action: 1.540 [0.000, 3.000], mean observation: 0.096 [-0.874, 1.698], loss: 2.144586, mean_absolute_error: 16.994555, mean_q: 9.616934
 49481/100000: episode: 97, duration: 7.480s, episode steps: 1000, steps per second: 134, episode reward: 17.573, mean reward: 0.018 [-20.736, 19.753], mean action: 1.801 [0.000, 3.000], mean observation: 0.086 [-0.404, 1.397], loss: 2.609196, mean_absolute_error: 16.758413, mean_q: 10.222951
 50481/100000: episode: 98, duration: 8.289s, episode steps: 1000, steps per second: 121, episode reward: 51.960, mean reward: 0.052 [-20.176, 12.080], mean action: 1.623 [0.000, 3.000], mean observation: 0.085 [-0.400, 1.400], loss: 2.509195, mean_absolute_error: 16.783566, mean_q: 10.886588
 50805/100000: episode: 99, duration: 1.994s, episode steps: 324, steps per second: 163, episode reward: 194.772, mean reward: 0.601 [-12.741, 100.000], mean action: 1.679 [0.000, 3.000], mean observation: 0.180 [-0.844, 1.429], loss: 2.991701, mean_absolute_error: 16.840845, mean_q: 11.886755
 51805/100000: episode: 100, duration: 8.411s, episode steps: 1000, steps per second: 119, episode reward: 10.648, mean reward: 0.011 [-21.515, 13.738], mean action: 1.678 [0.000, 3.000], mean observation: 0.079 [-0.433, 1.392], loss: 3.108220, mean_absolute_error: 16.908911, mean_q: 11.479164
 52805/100000: episode: 101, duration: 7.248s, episode steps: 1000, steps per second: 138, episode reward: 44.910, mean reward: 0.045 [-20.651, 22.486], mean action: 1.570 [0.000, 3.000], mean observation: 0.078 [-1.077, 1.410], loss: 3.285167, mean_absolute_error: 16.905933, mean_q: 11.592532
 53805/100000: episode: 102, duration: 7.978s, episode steps: 1000, steps per second: 125, episode reward: 57.337, mean reward: 0.057 [-20.059, 21.890], mean action: 1.505 [0.000, 3.000], mean observation: 0.152 [-0.877, 1.442], loss: 2.714733, mean_absolute_error: 16.785261, mean_q: 12.163487
 54269/100000: episode: 103, duration: 3.160s, episode steps: 464, steps per second: 147, episode reward: -46.879, mean reward: -0.101 [-100.000, 11.802], mean action: 1.713 [0.000, 3.000], mean observation: 0.069 [-0.345, 1.398], loss: 2.984199, mean_absolute_error: 16.728613, mean_q: 12.157635
 55269/100000: episode: 104, duration: 8.490s, episode steps: 1000, steps per second: 118, episode reward: 15.318, mean reward: 0.015 [-22.240, 19.038], mean action: 1.641 [0.000, 3.000], mean observation: 0.077 [-0.338, 1.400], loss: 2.951714, mean_absolute_error: 16.709414, mean_q: 12.705859
 56269/100000: episode: 105, duration: 7.892s, episode steps: 1000, steps per second: 127, episode reward: 10.147, mean reward: 0.010 [-23.248, 19.499], mean action: 1.570 [0.000, 3.000], mean observation: 0.072 [-0.677, 1.457], loss: 2.555289, mean_absolute_error: 16.877674, mean_q: 13.728505
 57269/100000: episode: 106, duration: 7.622s, episode steps: 1000, steps per second: 131, episode reward: -42.745, mean reward: -0.043 [-24.216, 27.718], mean action: 1.604 [0.000, 3.000], mean observation: 0.043 [-0.581, 1.413], loss: 2.586225, mean_absolute_error: 17.022114, mean_q: 15.265731
 57377/100000: episode: 107, duration: 0.630s, episode steps: 108, steps per second: 171, episode reward: -155.429, mean reward: -1.439 [-100.000, 8.843], mean action: 1.741 [0.000, 3.000], mean observation: 0.183 [-2.457, 1.424], loss: 3.685858, mean_absolute_error: 16.744467, mean_q: 15.984938
 58377/100000: episode: 108, duration: 9.411s, episode steps: 1000, steps per second: 106, episode reward: 48.857, mean reward: 0.049 [-25.120, 26.301], mean action: 1.522 [0.000, 3.000], mean observation: 0.056 [-0.818, 1.484], loss: 2.961409, mean_absolute_error: 16.964031, mean_q: 16.516754
 58742/100000: episode: 109, duration: 2.425s, episode steps: 365, steps per second: 151, episode reward: -349.058, mean reward: -0.956 [-100.000, 10.023], mean action: 1.685 [0.000, 3.000], mean observation: 0.087 [-1.786, 1.414], loss: 2.667022, mean_absolute_error: 16.897911, mean_q: 16.896423
 59742/100000: episode: 110, duration: 8.940s, episode steps: 1000, steps per second: 112, episode reward: 12.426, mean reward: 0.012 [-24.615, 27.418], mean action: 1.405 [0.000, 3.000], mean observation: 0.059 [-1.040, 1.399], loss: 2.959614, mean_absolute_error: 16.795511, mean_q: 17.136360
 60742/100000: episode: 111, duration: 6.716s, episode steps: 1000, steps per second: 149, episode reward: 4.773, mean reward: 0.005 [-4.574, 4.787], mean action: 1.503 [0.000, 3.000], mean observation: 0.055 [-0.563, 1.504], loss: 3.122896, mean_absolute_error: 16.863642, mean_q: 17.950924
 61742/100000: episode: 112, duration: 8.588s, episode steps: 1000, steps per second: 116, episode reward: -28.440, mean reward: -0.028 [-13.269, 17.712], mean action: 1.599 [0.000, 3.000], mean observation: 0.021 [-1.085, 1.396], loss: 2.443213, mean_absolute_error: 16.684662, mean_q: 18.531525
 61938/100000: episode: 113, duration: 1.171s, episode steps: 196, steps per second: 167, episode reward: -254.988, mean reward: -1.301 [-100.000, 8.343], mean action: 1.847 [0.000, 3.000], mean observation: 0.154 [-1.160, 2.812], loss: 3.742325, mean_absolute_error: 16.734417, mean_q: 18.952995
 62156/100000: episode: 114, duration: 1.316s, episode steps: 218, steps per second: 166, episode reward: -350.957, mean reward: -1.610 [-100.000, 78.007], mean action: 1.908 [0.000, 3.000], mean observation: 0.107 [-0.995, 3.653], loss: 3.996792, mean_absolute_error: 16.618835, mean_q: 18.454985
 62569/100000: episode: 115, duration: 2.566s, episode steps: 413, steps per second: 161, episode reward: -68.059, mean reward: -0.165 [-100.000, 17.241], mean action: 1.748 [0.000, 3.000], mean observation: 0.185 [-0.792, 1.463], loss: 2.831129, mean_absolute_error: 16.753124, mean_q: 19.250179
 63569/100000: episode: 116, duration: 8.409s, episode steps: 1000, steps per second: 119, episode reward: 41.822, mean reward: 0.042 [-23.934, 16.023], mean action: 1.688 [0.000, 3.000], mean observation: 0.086 [-0.498, 1.388], loss: 2.748341, mean_absolute_error: 17.022884, mean_q: 19.984798
 63749/100000: episode: 117, duration: 1.066s, episode steps: 180, steps per second: 169, episode reward: -273.970, mean reward: -1.522 [-100.000, 38.964], mean action: 1.856 [0.000, 3.000], mean observation: 0.062 [-2.602, 1.403], loss: 3.093623, mean_absolute_error: 17.161049, mean_q: 20.641468
 63902/100000: episode: 118, duration: 0.912s, episode steps: 153, steps per second: 168, episode reward: -164.844, mean reward: -1.077 [-100.000, 15.107], mean action: 1.993 [0.000, 3.000], mean observation: 0.162 [-1.151, 1.403], loss: 3.931977, mean_absolute_error: 17.032633, mean_q: 20.488676
 64902/100000: episode: 119, duration: 8.188s, episode steps: 1000, steps per second: 122, episode reward: 23.545, mean reward: 0.024 [-24.387, 21.741], mean action: 1.712 [0.000, 3.000], mean observation: 0.073 [-0.382, 1.447], loss: 3.949859, mean_absolute_error: 17.616390, mean_q: 20.970491
 65148/100000: episode: 120, duration: 1.511s, episode steps: 246, steps per second: 163, episode reward: -299.444, mean reward: -1.217 [-100.000, 6.965], mean action: 1.707 [0.000, 3.000], mean observation: 0.143 [-1.289, 2.281], loss: 2.555271, mean_absolute_error: 17.422611, mean_q: 20.856552
 65251/100000: episode: 121, duration: 0.587s, episode steps: 103, steps per second: 176, episode reward: -160.856, mean reward: -1.562 [-100.000, 29.172], mean action: 0.981 [0.000, 3.000], mean observation: 0.045 [-5.938, 1.432], loss: 8.262562, mean_absolute_error: 17.922537, mean_q: 21.056776
 65521/100000: episode: 122, duration: 1.650s, episode steps: 270, steps per second: 164, episode reward: -313.171, mean reward: -1.160 [-100.000, 60.706], mean action: 1.533 [0.000, 3.000], mean observation: 0.035 [-2.865, 1.514], loss: 4.108464, mean_absolute_error: 18.184578, mean_q: 21.634729
 65612/100000: episode: 123, duration: 0.527s, episode steps: 91, steps per second: 173, episode reward: -187.390, mean reward: -2.059 [-100.000, 10.406], mean action: 1.385 [0.000, 3.000], mean observation: -0.093 [-4.998, 1.389], loss: 5.706449, mean_absolute_error: 18.214291, mean_q: 22.017647
 65822/100000: episode: 124, duration: 1.251s, episode steps: 210, steps per second: 168, episode reward: -132.622, mean reward: -0.632 [-100.000, 9.137], mean action: 1.538 [0.000, 3.000], mean observation: 0.061 [-0.985, 3.870], loss: 4.242646, mean_absolute_error: 18.549341, mean_q: 21.826162
 66822/100000: episode: 125, duration: 8.062s, episode steps: 1000, steps per second: 124, episode reward: 64.831, mean reward: 0.065 [-23.701, 25.728], mean action: 1.791 [0.000, 3.000], mean observation: 0.112 [-0.317, 1.493], loss: 3.388200, mean_absolute_error: 18.754454, mean_q: 22.115458
 67822/100000: episode: 126, duration: 7.881s, episode steps: 1000, steps per second: 127, episode reward: 62.957, mean reward: 0.063 [-23.841, 24.708], mean action: 1.769 [0.000, 3.000], mean observation: 0.130 [-0.546, 1.389], loss: 4.079776, mean_absolute_error: 19.005102, mean_q: 22.668036
 68306/100000: episode: 127, duration: 3.172s, episode steps: 484, steps per second: 153, episode reward: -520.713, mean reward: -1.076 [-100.000, 3.374], mean action: 1.376 [0.000, 3.000], mean observation: 0.261 [-2.443, 7.000], loss: 4.836730, mean_absolute_error: 18.858105, mean_q: 22.523268
 68992/100000: episode: 128, duration: 5.271s, episode steps: 686, steps per second: 130, episode reward: -21.581, mean reward: -0.031 [-100.000, 12.200], mean action: 1.802 [0.000, 3.000], mean observation: 0.100 [-0.656, 1.395], loss: 4.941828, mean_absolute_error: 19.265820, mean_q: 22.675785
 69890/100000: episode: 129, duration: 7.191s, episode steps: 898, steps per second: 125, episode reward: 203.256, mean reward: 0.226 [-19.009, 100.000], mean action: 2.171 [0.000, 3.000], mean observation: 0.145 [-0.633, 1.389], loss: 4.419186, mean_absolute_error: 19.452461, mean_q: 23.224340
 70890/100000: episode: 130, duration: 7.537s, episode steps: 1000, steps per second: 133, episode reward: 61.916, mean reward: 0.062 [-20.254, 21.751], mean action: 1.885 [0.000, 3.000], mean observation: 0.086 [-0.450, 1.419], loss: 3.781581, mean_absolute_error: 19.243502, mean_q: 23.585155
 71890/100000: episode: 131, duration: 7.520s, episode steps: 1000, steps per second: 133, episode reward: 26.392, mean reward: 0.026 [-22.788, 21.296], mean action: 1.775 [0.000, 3.000], mean observation: 0.080 [-0.615, 1.456], loss: 3.142587, mean_absolute_error: 19.437126, mean_q: 23.935434
 72890/100000: episode: 132, duration: 7.860s, episode steps: 1000, steps per second: 127, episode reward: -12.506, mean reward: -0.013 [-20.755, 22.933], mean action: 1.667 [0.000, 3.000], mean observation: 0.038 [-0.388, 1.407], loss: 3.495552, mean_absolute_error: 19.731525, mean_q: 24.335249
 73881/100000: episode: 133, duration: 8.774s, episode steps: 991, steps per second: 113, episode reward: 173.553, mean reward: 0.175 [-20.983, 100.000], mean action: 2.059 [0.000, 3.000], mean observation: 0.137 [-0.435, 1.492], loss: 2.847431, mean_absolute_error: 20.141830, mean_q: 24.633532
 74535/100000: episode: 134, duration: 4.933s, episode steps: 654, steps per second: 133, episode reward: 164.711, mean reward: 0.252 [-11.550, 100.000], mean action: 1.922 [0.000, 3.000], mean observation: 0.084 [-0.369, 1.402], loss: 3.894670, mean_absolute_error: 20.768999, mean_q: 25.007969
 75535/100000: episode: 135, duration: 8.800s, episode steps: 1000, steps per second: 114, episode reward: -19.607, mean reward: -0.020 [-4.586, 4.969], mean action: 1.677 [0.000, 3.000], mean observation: 0.074 [-0.343, 1.424], loss: 4.790513, mean_absolute_error: 20.655106, mean_q: 25.447441
 76535/100000: episode: 136, duration: 8.677s, episode steps: 1000, steps per second: 115, episode reward: 29.752, mean reward: 0.030 [-20.012, 14.576], mean action: 1.684 [0.000, 3.000], mean observation: 0.065 [-0.323, 1.448], loss: 3.309353, mean_absolute_error: 20.660749, mean_q: 25.753054
 77535/100000: episode: 137, duration: 7.089s, episode steps: 1000, steps per second: 141, episode reward: 123.207, mean reward: 0.123 [-21.685, 22.345], mean action: 1.887 [0.000, 3.000], mean observation: 0.182 [-0.661, 1.413], loss: 3.116291, mean_absolute_error: 20.461647, mean_q: 25.360527
 78535/100000: episode: 138, duration: 7.247s, episode steps: 1000, steps per second: 138, episode reward: -22.360, mean reward: -0.022 [-3.547, 4.273], mean action: 1.571 [0.000, 3.000], mean observation: 0.062 [-0.530, 1.508], loss: 3.469136, mean_absolute_error: 20.201168, mean_q: 24.920452
 79535/100000: episode: 139, duration: 7.414s, episode steps: 1000, steps per second: 135, episode reward: -21.739, mean reward: -0.022 [-4.426, 4.998], mean action: 1.818 [0.000, 3.000], mean observation: 0.061 [-0.686, 1.387], loss: 2.863166, mean_absolute_error: 20.253868, mean_q: 25.125872
 80535/100000: episode: 140, duration: 7.718s, episode steps: 1000, steps per second: 130, episode reward: -35.287, mean reward: -0.035 [-4.913, 4.294], mean action: 1.764 [0.000, 3.000], mean observation: 0.061 [-0.486, 1.390], loss: 3.432343, mean_absolute_error: 20.124777, mean_q: 24.967539
 81535/100000: episode: 141, duration: 8.509s, episode steps: 1000, steps per second: 118, episode reward: -25.920, mean reward: -0.026 [-4.967, 4.690], mean action: 1.673 [0.000, 3.000], mean observation: 0.082 [-0.370, 1.489], loss: 5.278962, mean_absolute_error: 20.103895, mean_q: 24.901442
 82535/100000: episode: 142, duration: 7.815s, episode steps: 1000, steps per second: 128, episode reward: 82.028, mean reward: 0.082 [-22.636, 22.736], mean action: 1.827 [0.000, 3.000], mean observation: 0.099 [-0.710, 1.402], loss: 3.115170, mean_absolute_error: 19.984743, mean_q: 24.659796
 83535/100000: episode: 143, duration: 7.292s, episode steps: 1000, steps per second: 137, episode reward: 90.050, mean reward: 0.090 [-19.118, 12.145], mean action: 1.554 [0.000, 3.000], mean observation: 0.095 [-0.771, 1.393], loss: 3.625318, mean_absolute_error: 20.117731, mean_q: 24.937138
 84535/100000: episode: 144, duration: 9.335s, episode steps: 1000, steps per second: 107, episode reward: -38.257, mean reward: -0.038 [-3.709, 4.799], mean action: 1.765 [0.000, 3.000], mean observation: 0.056 [-0.423, 1.403], loss: 4.189929, mean_absolute_error: 20.245735, mean_q: 24.854179
 85535/100000: episode: 145, duration: 7.296s, episode steps: 1000, steps per second: 137, episode reward: 81.357, mean reward: 0.081 [-21.307, 22.187], mean action: 1.639 [0.000, 3.000], mean observation: 0.101 [-0.569, 1.395], loss: 4.393840, mean_absolute_error: 20.212122, mean_q: 25.148796
 86535/100000: episode: 146, duration: 8.614s, episode steps: 1000, steps per second: 116, episode reward: -22.549, mean reward: -0.023 [-4.581, 4.870], mean action: 1.622 [0.000, 3.000], mean observation: 0.057 [-0.520, 1.387], loss: 3.122450, mean_absolute_error: 19.729849, mean_q: 24.915792
 87535/100000: episode: 147, duration: 8.954s, episode steps: 1000, steps per second: 112, episode reward: -24.834, mean reward: -0.025 [-3.749, 5.015], mean action: 1.679 [0.000, 3.000], mean observation: 0.060 [-0.546, 1.506], loss: 3.678513, mean_absolute_error: 19.696684, mean_q: 24.651047
 88535/100000: episode: 148, duration: 7.426s, episode steps: 1000, steps per second: 135, episode reward: 112.199, mean reward: 0.112 [-20.218, 19.211], mean action: 2.009 [0.000, 3.000], mean observation: 0.185 [-0.466, 1.397], loss: 3.762703, mean_absolute_error: 19.144430, mean_q: 23.973480
 89535/100000: episode: 149, duration: 8.331s, episode steps: 1000, steps per second: 120, episode reward: 48.594, mean reward: 0.049 [-20.300, 24.545], mean action: 1.681 [0.000, 3.000], mean observation: 0.166 [-0.698, 1.409], loss: 2.896630, mean_absolute_error: 19.054981, mean_q: 23.689890
 90336/100000: episode: 150, duration: 6.380s, episode steps: 801, steps per second: 126, episode reward: 175.764, mean reward: 0.219 [-19.361, 100.000], mean action: 1.554 [0.000, 3.000], mean observation: 0.123 [-0.532, 1.398], loss: 3.063755, mean_absolute_error: 18.998514, mean_q: 23.486097
 91336/100000: episode: 151, duration: 7.815s, episode steps: 1000, steps per second: 128, episode reward: 141.677, mean reward: 0.142 [-20.514, 23.807], mean action: 1.731 [0.000, 3.000], mean observation: 0.159 [-0.751, 1.391], loss: 3.074419, mean_absolute_error: 18.816124, mean_q: 23.281193
 92336/100000: episode: 152, duration: 8.198s, episode steps: 1000, steps per second: 122, episode reward: 76.176, mean reward: 0.076 [-21.119, 19.969], mean action: 1.736 [0.000, 3.000], mean observation: 0.136 [-0.484, 1.409], loss: 3.457540, mean_absolute_error: 18.820507, mean_q: 23.259243
 93336/100000: episode: 153, duration: 8.010s, episode steps: 1000, steps per second: 125, episode reward: 114.228, mean reward: 0.114 [-20.801, 22.817], mean action: 1.532 [0.000, 3.000], mean observation: 0.169 [-1.084, 1.460], loss: 4.208874, mean_absolute_error: 18.831366, mean_q: 23.187574
 94336/100000: episode: 154, duration: 7.101s, episode steps: 1000, steps per second: 141, episode reward: 102.257, mean reward: 0.102 [-19.369, 20.397], mean action: 1.659 [0.000, 3.000], mean observation: 0.138 [-0.677, 1.846], loss: 3.437401, mean_absolute_error: 18.944284, mean_q: 23.710110
 95336/100000: episode: 155, duration: 7.904s, episode steps: 1000, steps per second: 127, episode reward: 97.084, mean reward: 0.097 [-21.348, 23.176], mean action: 1.877 [0.000, 3.000], mean observation: 0.168 [-0.715, 1.403], loss: 2.701012, mean_absolute_error: 19.319801, mean_q: 24.353487
 95702/100000: episode: 156, duration: 2.248s, episode steps: 366, steps per second: 163, episode reward: 2.824, mean reward: 0.008 [-100.000, 14.988], mean action: 1.598 [0.000, 3.000], mean observation: 0.017 [-0.656, 1.478], loss: 3.407394, mean_absolute_error: 19.507242, mean_q: 24.555637
 96702/100000: episode: 157, duration: 7.140s, episode steps: 1000, steps per second: 140, episode reward: 158.579, mean reward: 0.159 [-19.917, 15.233], mean action: 1.516 [0.000, 3.000], mean observation: 0.105 [-1.376, 1.428], loss: 2.827288, mean_absolute_error: 19.808329, mean_q: 25.439560
 97702/100000: episode: 158, duration: 8.025s, episode steps: 1000, steps per second: 125, episode reward: 122.033, mean reward: 0.122 [-19.996, 22.785], mean action: 1.427 [0.000, 3.000], mean observation: 0.143 [-0.687, 1.396], loss: 3.113464, mean_absolute_error: 20.075678, mean_q: 25.844749
 98702/100000: episode: 159, duration: 8.839s, episode steps: 1000, steps per second: 113, episode reward: 72.191, mean reward: 0.072 [-19.475, 23.574], mean action: 1.400 [0.000, 3.000], mean observation: 0.118 [-0.514, 1.397], loss: 2.527920, mean_absolute_error: 19.680769, mean_q: 25.403099
 99702/100000: episode: 160, duration: 8.572s, episode steps: 1000, steps per second: 117, episode reward: 117.285, mean reward: 0.117 [-22.387, 23.877], mean action: 1.279 [0.000, 3.000], mean observation: 0.145 [-0.620, 1.401], loss: 2.334790, mean_absolute_error: 19.576534, mean_q: 25.539457
done, took 769.977 seconds
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-Result">Evaluation Result<a class="anchor-link" href="#Evaluation-Result">&#182;</a></h2><p>We are testing the above model for 50 episodes and then looking at the mean reward value</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Finally, evaluate our algorithm for 50 episodes.</span>
<span class="c1">#dqn3.test(env, nb_episodes=50, visualize=False)</span>

<span class="c1"># Finally, evaluate the agent</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">dqn4</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;episode_reward&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Test rewards (#episodes=</span><span class="si">{}</span><span class="s2">): mean=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, std=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, &quot;</span>
           <span class="s2">&quot;min=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, max=</span><span class="si">{:&gt;5.2f}</span><span class="s2">&quot;</span><span class="p">)</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>

<span class="n">rl_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 4&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Testing for 50 episodes ...
Episode 1: reward: -210.185, steps: 191
Episode 2: reward: 103.853, steps: 1000
Episode 3: reward: 118.624, steps: 1000
Episode 4: reward: 246.048, steps: 505
Episode 5: reward: 135.099, steps: 1000
Episode 6: reward: 117.364, steps: 1000
Episode 7: reward: 144.357, steps: 1000
Episode 8: reward: 114.239, steps: 1000
Episode 9: reward: 111.288, steps: 1000
Episode 10: reward: 119.039, steps: 1000
Episode 11: reward: 114.412, steps: 1000
Episode 12: reward: 124.712, steps: 1000
Episode 13: reward: 86.981, steps: 1000
Episode 14: reward: 110.171, steps: 1000
Episode 15: reward: 229.639, steps: 424
Episode 16: reward: 118.417, steps: 1000
Episode 17: reward: 123.959, steps: 1000
Episode 18: reward: 109.251, steps: 1000
Episode 19: reward: 97.037, steps: 1000
Episode 20: reward: -278.117, steps: 228
Episode 21: reward: 127.802, steps: 1000
Episode 22: reward: 211.703, steps: 679
Episode 23: reward: 108.731, steps: 1000
Episode 24: reward: 135.276, steps: 1000
Episode 25: reward: 118.171, steps: 1000
Episode 26: reward: 123.162, steps: 1000
Episode 27: reward: 81.010, steps: 1000
Episode 28: reward: 111.582, steps: 1000
Episode 29: reward: 245.714, steps: 454
Episode 30: reward: 108.428, steps: 1000
Episode 31: reward: 94.687, steps: 1000
Episode 32: reward: -76.606, steps: 501
Episode 33: reward: 78.877, steps: 1000
Episode 34: reward: 64.619, steps: 1000
Episode 35: reward: 152.652, steps: 1000
Episode 36: reward: 123.659, steps: 1000
Episode 37: reward: 256.754, steps: 533
Episode 38: reward: 100.845, steps: 1000
Episode 39: reward: -250.323, steps: 199
Episode 40: reward: 70.260, steps: 1000
Episode 41: reward: 116.353, steps: 1000
Episode 42: reward: 95.076, steps: 1000
Episode 43: reward: -186.346, steps: 214
Episode 44: reward: -237.563, steps: 203
Episode 45: reward: 124.581, steps: 1000
Episode 46: reward: 111.855, steps: 1000
Episode 47: reward: 120.883, steps: 1000
Episode 48: reward: 182.906, steps: 515
Episode 49: reward: 108.118, steps: 1000
Episode 50: reward: 124.404, steps: 1000
Test rewards (#episodes=50): mean=87.67, std=118.57, min=-278.12, max=256.75
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-5">Model 5<a class="anchor-link" href="#Model-5">&#182;</a></h2><p><b> Model Architecture</b></p>
<p>We are using the similar architecture and process as <a href="#task2_model1">Model 1</a> but with different hyper-parameters. <br/> <br/>
<b>In this Model, we are changing value of learning rate of Adam optimizer to 0.001. Also, we are using a different Policy that is LinearAnnealedPolicy. In this Policy, value of epsilon decay our as the agent steps forward in the world. In the below policy, were saying that we want to start with a value of 1 for epsilon and go no smaller than 0.1.</b></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get the environment and extract the number of actions.</span>
<span class="c1">#env = gym.make(ENV_NAME)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">nb_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Next, we build a very simple model.</span>
<span class="n">model5</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">))</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model5</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="c1"># Finally, we configure and compile our agent. You can use every built-in Keras optimizer and</span>
<span class="c1"># even the metrics!</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">SequentialMemory</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">window_length</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#policy = EpsGreedyQPolicy(eps=.1)</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">LinearAnnealedPolicy</span><span class="p">(</span><span class="n">EpsGreedyQPolicy</span><span class="p">(),</span> <span class="n">attr</span><span class="o">=</span><span class="s1">&#39;eps&#39;</span><span class="p">,</span> <span class="n">value_max</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">value_min</span><span class="o">=.</span><span class="mi">1</span><span class="p">,</span> <span class="n">value_test</span><span class="o">=.</span><span class="mi">05</span><span class="p">,</span> <span class="n">nb_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">dqn5</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model5</span><span class="p">,</span> <span class="n">nb_actions</span><span class="o">=</span><span class="n">nb_actions</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="n">nb_steps_warmup</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
               <span class="n">target_model_update</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">)</span>
<span class="n">dqn5</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mae&#39;</span><span class="p">])</span>

<span class="c1"># Okay, now it&#39;s time to learn something! We visualize the training here for show, but this</span>
<span class="c1"># slows down training quite a lot. You can always safely abort the training prematurely using</span>
<span class="c1"># Ctrl + C.</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">dqn5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_steps</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">timetaken</span><span class="o">=</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
<span class="n">rl_model_time_comparisons</span><span class="p">[</span><span class="s1">&#39;Model 5&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">timetaken</span>
<span class="c1"># After training is done, we save the final weights.</span>
<span class="n">dqn5</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;dqn_</span><span class="si">{}</span><span class="s1">_weights_model5.h5f&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ENV_NAME</span><span class="p">),</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_5 (Flatten)          (None, 8)                 0         
_________________________________________________________________
dense_17 (Dense)             (None, 16)                144       
_________________________________________________________________
activation_17 (Activation)   (None, 16)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 16)                272       
_________________________________________________________________
activation_18 (Activation)   (None, 16)                0         
_________________________________________________________________
dense_19 (Dense)             (None, 16)                272       
_________________________________________________________________
activation_19 (Activation)   (None, 16)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 4)                 68        
_________________________________________________________________
activation_20 (Activation)   (None, 4)                 0         
=================================================================
Total params: 756
Trainable params: 756
Non-trainable params: 0
_________________________________________________________________
None
Training for 100000 steps ...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/anaconda3/lib/python3.6/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!
  warnings.warn(&#39;Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!&#39;)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>    80/100000: episode: 1, duration: 2.389s, episode steps: 80, steps per second: 33, episode reward: -96.202, mean reward: -1.203 [-100.000, 11.577], mean action: 1.512 [0.000, 3.000], mean observation: 0.050 [-1.260, 4.242], loss: 1.533736, mean_absolute_error: 0.493214, mean_q: 0.309838, mean_eps: 0.995725
   140/100000: episode: 2, duration: 0.355s, episode steps: 60, steps per second: 169, episode reward: -90.287, mean reward: -1.505 [-100.000, 12.534], mean action: 1.583 [0.000, 3.000], mean observation: -0.101 [-5.039, 1.394], loss: 45.097277, mean_absolute_error: 1.147136, mean_q: 1.884800, mean_eps: 0.990145
   249/100000: episode: 3, duration: 0.638s, episode steps: 109, steps per second: 171, episode reward: -168.031, mean reward: -1.542 [-100.000, 5.909], mean action: 1.450 [0.000, 3.000], mean observation: -0.063 [-1.580, 5.109], loss: 43.599776, mean_absolute_error: 1.258506, mean_q: 2.334912, mean_eps: 0.982540
   388/100000: episode: 4, duration: 0.834s, episode steps: 139, steps per second: 167, episode reward: -100.471, mean reward: -0.723 [-100.000, 9.734], mean action: 1.554 [0.000, 3.000], mean observation: -0.110 [-1.094, 3.885], loss: 41.689760, mean_absolute_error: 1.334816, mean_q: 2.250549, mean_eps: 0.971380
   483/100000: episode: 5, duration: 0.555s, episode steps: 95, steps per second: 171, episode reward: -125.091, mean reward: -1.317 [-100.000, 12.347], mean action: 1.305 [0.000, 3.000], mean observation: 0.113 [-3.615, 1.419], loss: 36.921890, mean_absolute_error: 1.684781, mean_q: 3.059586, mean_eps: 0.960850
   594/100000: episode: 6, duration: 0.653s, episode steps: 111, steps per second: 170, episode reward: -282.932, mean reward: -2.549 [-100.000, 25.925], mean action: 1.423 [0.000, 3.000], mean observation: 0.073 [-4.879, 1.424], loss: 46.361386, mean_absolute_error: 2.088844, mean_q: 3.932713, mean_eps: 0.951580
   677/100000: episode: 7, duration: 0.491s, episode steps: 83, steps per second: 169, episode reward: -332.392, mean reward: -4.005 [-100.000, 27.304], mean action: 1.590 [0.000, 3.000], mean observation: 0.027 [-2.341, 1.557], loss: 47.881302, mean_absolute_error: 2.807784, mean_q: 4.984812, mean_eps: 0.942850
   739/100000: episode: 8, duration: 0.372s, episode steps: 62, steps per second: 167, episode reward: -132.781, mean reward: -2.142 [-100.000, 19.498], mean action: 1.774 [0.000, 3.000], mean observation: 0.052 [-1.470, 3.387], loss: 38.268932, mean_absolute_error: 3.362203, mean_q: 5.828222, mean_eps: 0.936325
   843/100000: episode: 9, duration: 0.619s, episode steps: 104, steps per second: 168, episode reward: -112.904, mean reward: -1.086 [-100.000, 11.214], mean action: 1.394 [0.000, 3.000], mean observation: -0.015 [-1.228, 4.117], loss: 49.733623, mean_absolute_error: 3.561506, mean_q: 5.128804, mean_eps: 0.928855
   929/100000: episode: 10, duration: 0.513s, episode steps: 86, steps per second: 168, episode reward: -254.745, mean reward: -2.962 [-100.000, 1.469], mean action: 1.721 [0.000, 3.000], mean observation: -0.085 [-1.673, 1.393], loss: 46.360678, mean_absolute_error: 3.241837, mean_q: 4.882152, mean_eps: 0.920305
  1061/100000: episode: 11, duration: 0.779s, episode steps: 132, steps per second: 170, episode reward: -349.835, mean reward: -2.650 [-100.000, 1.562], mean action: 1.538 [0.000, 3.000], mean observation: 0.165 [-1.504, 1.566], loss: 49.711261, mean_absolute_error: 3.329392, mean_q: 4.904083, mean_eps: 0.910495
  1135/100000: episode: 12, duration: 0.436s, episode steps: 74, steps per second: 170, episode reward: -160.629, mean reward: -2.171 [-100.000, 10.657], mean action: 1.432 [0.000, 3.000], mean observation: 0.064 [-1.533, 5.098], loss: 60.363050, mean_absolute_error: 3.154330, mean_q: 4.470817, mean_eps: 0.901225
  1231/100000: episode: 13, duration: 0.570s, episode steps: 96, steps per second: 168, episode reward: -68.911, mean reward: -0.718 [-100.000, 13.739], mean action: 1.490 [0.000, 3.000], mean observation: 0.129 [-3.575, 1.405], loss: 56.195923, mean_absolute_error: 3.278032, mean_q: 4.854964, mean_eps: 0.893575
  1357/100000: episode: 14, duration: 0.748s, episode steps: 126, steps per second: 169, episode reward: -314.281, mean reward: -2.494 [-100.000, 22.417], mean action: 1.579 [0.000, 3.000], mean observation: 0.071 [-1.273, 2.631], loss: 48.598822, mean_absolute_error: 3.803640, mean_q: 5.781555, mean_eps: 0.883585
  1465/100000: episode: 15, duration: 0.637s, episode steps: 108, steps per second: 169, episode reward: -491.520, mean reward: -4.551 [-100.000, 1.069], mean action: 1.528 [0.000, 3.000], mean observation: -0.009 [-2.510, 2.006], loss: 42.936983, mean_absolute_error: 4.033401, mean_q: 5.756616, mean_eps: 0.873055
  1571/100000: episode: 16, duration: 0.630s, episode steps: 106, steps per second: 168, episode reward: -112.285, mean reward: -1.059 [-100.000, 10.833], mean action: 1.462 [0.000, 3.000], mean observation: 0.128 [-4.297, 1.429], loss: 37.598804, mean_absolute_error: 4.126323, mean_q: 5.758281, mean_eps: 0.863425
  1747/100000: episode: 17, duration: 1.049s, episode steps: 176, steps per second: 168, episode reward: -177.383, mean reward: -1.008 [-100.000, 7.099], mean action: 1.551 [0.000, 3.000], mean observation: 0.031 [-6.203, 1.657], loss: 42.533453, mean_absolute_error: 4.736523, mean_q: 6.388214, mean_eps: 0.850735
  1862/100000: episode: 18, duration: 0.680s, episode steps: 115, steps per second: 169, episode reward: -117.778, mean reward: -1.024 [-100.000, 20.342], mean action: 1.583 [0.000, 3.000], mean observation: 0.002 [-1.207, 1.426], loss: 31.188117, mean_absolute_error: 5.409640, mean_q: 7.140458, mean_eps: 0.837640
  1936/100000: episode: 19, duration: 0.442s, episode steps: 74, steps per second: 168, episode reward: -100.604, mean reward: -1.360 [-100.000, 16.885], mean action: 1.595 [0.000, 3.000], mean observation: -0.005 [-3.859, 1.385], loss: 37.751912, mean_absolute_error: 6.167174, mean_q: 7.847794, mean_eps: 0.829135
  2040/100000: episode: 20, duration: 0.619s, episode steps: 104, steps per second: 168, episode reward: -117.295, mean reward: -1.128 [-100.000, 38.677], mean action: 1.596 [0.000, 3.000], mean observation: -0.081 [-2.258, 1.417], loss: 41.339985, mean_absolute_error: 6.490610, mean_q: 8.011789, mean_eps: 0.821125
  2132/100000: episode: 21, duration: 0.545s, episode steps: 92, steps per second: 169, episode reward: -334.505, mean reward: -3.636 [-100.000, 0.245], mean action: 1.359 [0.000, 3.000], mean observation: 0.236 [-1.284, 1.596], loss: 33.647822, mean_absolute_error: 7.233439, mean_q: 8.700572, mean_eps: 0.812305
  2274/100000: episode: 22, duration: 0.850s, episode steps: 142, steps per second: 167, episode reward: 3.880, mean reward: 0.027 [-100.000, 85.506], mean action: 1.641 [0.000, 3.000], mean observation: 0.114 [-1.220, 1.690], loss: 25.272768, mean_absolute_error: 7.892211, mean_q: 9.035427, mean_eps: 0.801775
  2354/100000: episode: 23, duration: 0.471s, episode steps: 80, steps per second: 170, episode reward: -102.492, mean reward: -1.281 [-100.000, 12.019], mean action: 1.225 [0.000, 3.000], mean observation: 0.131 [-1.144, 4.041], loss: 26.914583, mean_absolute_error: 8.361283, mean_q: 9.236618, mean_eps: 0.791785
  2453/100000: episode: 24, duration: 0.586s, episode steps: 99, steps per second: 169, episode reward: -119.459, mean reward: -1.207 [-100.000, 7.992], mean action: 1.717 [0.000, 3.000], mean observation: 0.111 [-1.344, 1.389], loss: 24.004779, mean_absolute_error: 8.964026, mean_q: 9.541610, mean_eps: 0.783730
  2585/100000: episode: 25, duration: 0.782s, episode steps: 132, steps per second: 169, episode reward: -105.826, mean reward: -0.802 [-100.000, 11.236], mean action: 1.371 [0.000, 3.000], mean observation: 0.082 [-2.753, 1.418], loss: 28.348898, mean_absolute_error: 9.808884, mean_q: 9.771216, mean_eps: 0.773335
  2659/100000: episode: 26, duration: 0.439s, episode steps: 74, steps per second: 169, episode reward: -74.467, mean reward: -1.006 [-100.000, 17.828], mean action: 1.432 [0.000, 3.000], mean observation: 0.007 [-4.332, 1.392], loss: 29.541489, mean_absolute_error: 10.428428, mean_q: 10.522654, mean_eps: 0.764065
  2753/100000: episode: 27, duration: 0.555s, episode steps: 94, steps per second: 169, episode reward: -125.455, mean reward: -1.335 [-100.000, 16.283], mean action: 1.479 [0.000, 3.000], mean observation: 0.182 [-1.417, 1.574], loss: 26.026572, mean_absolute_error: 10.996482, mean_q: 10.662089, mean_eps: 0.756505
  2848/100000: episode: 28, duration: 0.588s, episode steps: 95, steps per second: 161, episode reward: -85.771, mean reward: -0.903 [-100.000, 7.333], mean action: 1.716 [0.000, 3.000], mean observation: -0.046 [-1.083, 3.987], loss: 23.530632, mean_absolute_error: 11.543287, mean_q: 10.871222, mean_eps: 0.748000
  2939/100000: episode: 29, duration: 0.541s, episode steps: 91, steps per second: 168, episode reward: -115.969, mean reward: -1.274 [-100.000, 9.488], mean action: 1.593 [0.000, 3.000], mean observation: -0.125 [-0.974, 2.919], loss: 23.587906, mean_absolute_error: 11.774356, mean_q: 11.483670, mean_eps: 0.739630
  3052/100000: episode: 30, duration: 0.673s, episode steps: 113, steps per second: 168, episode reward: -65.710, mean reward: -0.582 [-100.000, 10.583], mean action: 1.637 [0.000, 3.000], mean observation: -0.033 [-3.390, 1.395], loss: 21.151316, mean_absolute_error: 12.886764, mean_q: 10.703189, mean_eps: 0.730450
  3120/100000: episode: 31, duration: 0.401s, episode steps: 68, steps per second: 169, episode reward: -94.991, mean reward: -1.397 [-100.000, 11.189], mean action: 1.426 [0.000, 3.000], mean observation: 0.100 [-4.001, 1.388], loss: 18.257516, mean_absolute_error: 13.414496, mean_q: 11.510216, mean_eps: 0.722305
  3217/100000: episode: 32, duration: 0.573s, episode steps: 97, steps per second: 169, episode reward: -107.669, mean reward: -1.110 [-100.000, 10.131], mean action: 1.732 [0.000, 3.000], mean observation: -0.069 [-1.094, 3.559], loss: 19.539244, mean_absolute_error: 13.730248, mean_q: 10.990787, mean_eps: 0.714880
  3318/100000: episode: 33, duration: 0.595s, episode steps: 101, steps per second: 170, episode reward: -140.662, mean reward: -1.393 [-100.000, 8.869], mean action: 1.653 [0.000, 3.000], mean observation: 0.056 [-1.161, 1.413], loss: 18.972533, mean_absolute_error: 14.046784, mean_q: 11.344690, mean_eps: 0.705970
  3443/100000: episode: 34, duration: 0.735s, episode steps: 125, steps per second: 170, episode reward: -69.763, mean reward: -0.558 [-100.000, 12.521], mean action: 1.472 [0.000, 3.000], mean observation: 0.073 [-1.029, 3.110], loss: 19.946251, mean_absolute_error: 14.583230, mean_q: 11.226193, mean_eps: 0.695800
  3545/100000: episode: 35, duration: 0.603s, episode steps: 102, steps per second: 169, episode reward: 1.106, mean reward: 0.011 [-100.000, 104.105], mean action: 1.471 [0.000, 3.000], mean observation: -0.019 [-1.465, 1.394], loss: 20.225882, mean_absolute_error: 15.356494, mean_q: 11.003069, mean_eps: 0.685585
  3629/100000: episode: 36, duration: 0.493s, episode steps: 84, steps per second: 170, episode reward: -195.029, mean reward: -2.322 [-100.000, 15.300], mean action: 1.381 [0.000, 3.000], mean observation: -0.092 [-1.803, 1.402], loss: 25.010698, mean_absolute_error: 15.280775, mean_q: 11.025147, mean_eps: 0.677215
  4629/100000: episode: 37, duration: 8.069s, episode steps: 1000, steps per second: 124, episode reward: 49.253, mean reward: 0.049 [-24.068, 101.023], mean action: 1.539 [0.000, 3.000], mean observation: 0.091 [-1.250, 1.394], loss: 17.686593, mean_absolute_error: 17.758966, mean_q: 6.474430, mean_eps: 0.628435
  4741/100000: episode: 38, duration: 0.667s, episode steps: 112, steps per second: 168, episode reward: -178.318, mean reward: -1.592 [-100.000, 11.293], mean action: 1.616 [0.000, 3.000], mean observation: 0.268 [-1.423, 6.116], loss: 13.867318, mean_absolute_error: 19.523247, mean_q: 2.525755, mean_eps: 0.578395
  4822/100000: episode: 39, duration: 0.479s, episode steps: 81, steps per second: 169, episode reward: -68.286, mean reward: -0.843 [-100.000, 17.560], mean action: 1.519 [0.000, 3.000], mean observation: 0.148 [-1.139, 1.400], loss: 16.823892, mean_absolute_error: 19.353339, mean_q: 4.302609, mean_eps: 0.569710
  4986/100000: episode: 40, duration: 0.977s, episode steps: 164, steps per second: 168, episode reward: -69.596, mean reward: -0.424 [-100.000, 26.499], mean action: 1.421 [0.000, 3.000], mean observation: -0.020 [-0.938, 1.707], loss: 14.206526, mean_absolute_error: 19.501539, mean_q: 3.785802, mean_eps: 0.558685
  5118/100000: episode: 41, duration: 0.794s, episode steps: 132, steps per second: 166, episode reward: 6.769, mean reward: 0.051 [-100.000, 84.722], mean action: 1.614 [0.000, 3.000], mean observation: 0.178 [-1.579, 1.802], loss: 13.925060, mean_absolute_error: 19.680747, mean_q: 4.071217, mean_eps: 0.545365
  5240/100000: episode: 42, duration: 0.730s, episode steps: 122, steps per second: 167, episode reward: -77.293, mean reward: -0.634 [-100.000, 9.882], mean action: 1.680 [0.000, 3.000], mean observation: 0.101 [-3.093, 1.398], loss: 13.218772, mean_absolute_error: 20.046254, mean_q: 4.810799, mean_eps: 0.533935
  5380/100000: episode: 43, duration: 0.837s, episode steps: 140, steps per second: 167, episode reward: -82.254, mean reward: -0.588 [-100.000, 10.778], mean action: 1.600 [0.000, 3.000], mean observation: 0.116 [-2.404, 1.404], loss: 12.981170, mean_absolute_error: 20.189000, mean_q: 4.691153, mean_eps: 0.522145
  5518/100000: episode: 44, duration: 0.834s, episode steps: 138, steps per second: 165, episode reward: -111.377, mean reward: -0.807 [-100.000, 9.277], mean action: 1.601 [0.000, 3.000], mean observation: 0.040 [-0.939, 1.406], loss: 13.038883, mean_absolute_error: 19.931275, mean_q: 5.666919, mean_eps: 0.509635
  5643/100000: episode: 45, duration: 0.752s, episode steps: 125, steps per second: 166, episode reward: -195.634, mean reward: -1.565 [-100.000, 22.632], mean action: 1.712 [0.000, 3.000], mean observation: 0.196 [-0.982, 1.860], loss: 16.956594, mean_absolute_error: 20.187600, mean_q: 5.948382, mean_eps: 0.497800
  5792/100000: episode: 46, duration: 0.899s, episode steps: 149, steps per second: 166, episode reward: -69.076, mean reward: -0.464 [-100.000, 18.596], mean action: 1.779 [0.000, 3.000], mean observation: 0.102 [-2.726, 1.388], loss: 16.096018, mean_absolute_error: 20.787768, mean_q: 5.671816, mean_eps: 0.485470
  5963/100000: episode: 47, duration: 1.041s, episode steps: 171, steps per second: 164, episode reward: -9.763, mean reward: -0.057 [-100.000, 14.676], mean action: 1.661 [0.000, 3.000], mean observation: -0.002 [-0.633, 1.401], loss: 13.070544, mean_absolute_error: 20.790334, mean_q: 5.926326, mean_eps: 0.471070
  6167/100000: episode: 48, duration: 1.244s, episode steps: 204, steps per second: 164, episode reward: -75.122, mean reward: -0.368 [-100.000, 12.819], mean action: 1.544 [0.000, 3.000], mean observation: -0.031 [-0.875, 3.163], loss: 12.340363, mean_absolute_error: 21.175780, mean_q: 6.431267, mean_eps: 0.454195
  6324/100000: episode: 49, duration: 0.941s, episode steps: 157, steps per second: 167, episode reward: -151.366, mean reward: -0.964 [-100.000, 15.308], mean action: 1.490 [0.000, 3.000], mean observation: -0.055 [-1.052, 3.943], loss: 13.394324, mean_absolute_error: 21.512711, mean_q: 8.033019, mean_eps: 0.437950
  6420/100000: episode: 50, duration: 0.575s, episode steps: 96, steps per second: 167, episode reward: -168.575, mean reward: -1.756 [-100.000, 18.114], mean action: 1.677 [0.000, 3.000], mean observation: 0.197 [-1.256, 4.539], loss: 12.783690, mean_absolute_error: 21.834333, mean_q: 7.852402, mean_eps: 0.426565
  6550/100000: episode: 51, duration: 0.784s, episode steps: 130, steps per second: 166, episode reward: -218.631, mean reward: -1.682 [-100.000, 16.621], mean action: 1.715 [0.000, 3.000], mean observation: 0.183 [-0.806, 2.004], loss: 15.995239, mean_absolute_error: 21.577741, mean_q: 8.229911, mean_eps: 0.416395
  6657/100000: episode: 52, duration: 0.643s, episode steps: 107, steps per second: 166, episode reward: -109.166, mean reward: -1.020 [-100.000, 10.527], mean action: 1.813 [0.000, 3.000], mean observation: 0.157 [-1.080, 4.086], loss: 16.086982, mean_absolute_error: 21.712983, mean_q: 7.492903, mean_eps: 0.405730
  6756/100000: episode: 53, duration: 0.590s, episode steps: 99, steps per second: 168, episode reward: -84.277, mean reward: -0.851 [-100.000, 8.041], mean action: 1.616 [0.000, 3.000], mean observation: -0.131 [-0.935, 3.794], loss: 12.105940, mean_absolute_error: 21.892710, mean_q: 7.864835, mean_eps: 0.396460
  6974/100000: episode: 54, duration: 1.329s, episode steps: 218, steps per second: 164, episode reward: -41.443, mean reward: -0.190 [-100.000, 14.752], mean action: 1.661 [0.000, 3.000], mean observation: 0.048 [-0.918, 1.424], loss: 11.550512, mean_absolute_error: 22.619874, mean_q: 8.839685, mean_eps: 0.382195
  7118/100000: episode: 55, duration: 0.861s, episode steps: 144, steps per second: 167, episode reward: 15.647, mean reward: 0.109 [-100.000, 17.964], mean action: 1.604 [0.000, 3.000], mean observation: -0.020 [-0.817, 1.448], loss: 12.503320, mean_absolute_error: 22.691998, mean_q: 9.333096, mean_eps: 0.365905
  7472/100000: episode: 56, duration: 2.206s, episode steps: 354, steps per second: 160, episode reward: -30.024, mean reward: -0.085 [-100.000, 7.107], mean action: 1.653 [0.000, 3.000], mean observation: 0.052 [-0.481, 1.496], loss: 11.381594, mean_absolute_error: 23.303030, mean_q: 10.219546, mean_eps: 0.343495
  7625/100000: episode: 57, duration: 0.914s, episode steps: 153, steps per second: 167, episode reward: -17.897, mean reward: -0.117 [-100.000, 12.580], mean action: 1.641 [0.000, 3.000], mean observation: -0.035 [-0.828, 1.423], loss: 10.337591, mean_absolute_error: 23.591134, mean_q: 11.833068, mean_eps: 0.320680
  7994/100000: episode: 58, duration: 2.411s, episode steps: 369, steps per second: 153, episode reward: -61.763, mean reward: -0.167 [-100.000, 16.001], mean action: 1.585 [0.000, 3.000], mean observation: 0.000 [-0.694, 1.395], loss: 14.367350, mean_absolute_error: 24.156955, mean_q: 11.661870, mean_eps: 0.297190
  8103/100000: episode: 59, duration: 0.656s, episode steps: 109, steps per second: 166, episode reward: -11.809, mean reward: -0.108 [-100.000, 17.730], mean action: 1.780 [0.000, 3.000], mean observation: -0.094 [-0.917, 1.547], loss: 13.572151, mean_absolute_error: 24.674133, mean_q: 10.947713, mean_eps: 0.275680
  8737/100000: episode: 60, duration: 4.819s, episode steps: 634, steps per second: 132, episode reward: -197.599, mean reward: -0.312 [-100.000, 4.800], mean action: 1.543 [0.000, 3.000], mean observation: -0.008 [-1.004, 1.474], loss: 12.804968, mean_absolute_error: 25.198386, mean_q: 12.849385, mean_eps: 0.242245
  9737/100000: episode: 61, duration: 8.323s, episode steps: 1000, steps per second: 120, episode reward: -114.811, mean reward: -0.115 [-25.035, 17.501], mean action: 1.498 [0.000, 3.000], mean observation: 0.042 [-0.721, 1.392], loss: 11.949576, mean_absolute_error: 25.362998, mean_q: 14.002449, mean_eps: 0.168715
 10045/100000: episode: 62, duration: 1.948s, episode steps: 308, steps per second: 158, episode reward: -7.856, mean reward: -0.026 [-100.000, 5.416], mean action: 1.779 [0.000, 3.000], mean observation: 0.109 [-0.404, 1.410], loss: 10.458424, mean_absolute_error: 25.195285, mean_q: 14.798219, mean_eps: 0.110144
 10749/100000: episode: 63, duration: 5.432s, episode steps: 704, steps per second: 130, episode reward: -233.493, mean reward: -0.332 [-100.000, 16.668], mean action: 1.445 [0.000, 3.000], mean observation: 0.014 [-1.001, 1.435], loss: 10.403736, mean_absolute_error: 25.094930, mean_q: 14.847439, mean_eps: 0.100000
 11178/100000: episode: 64, duration: 2.943s, episode steps: 429, steps per second: 146, episode reward: -105.165, mean reward: -0.245 [-100.000, 18.579], mean action: 1.464 [0.000, 3.000], mean observation: -0.003 [-0.945, 1.386], loss: 10.120096, mean_absolute_error: 25.324273, mean_q: 15.275795, mean_eps: 0.100000
 12006/100000: episode: 65, duration: 6.558s, episode steps: 828, steps per second: 126, episode reward: 146.215, mean reward: 0.177 [-23.073, 100.000], mean action: 1.501 [0.000, 3.000], mean observation: 0.116 [-0.833, 1.391], loss: 11.165217, mean_absolute_error: 25.453005, mean_q: 14.814547, mean_eps: 0.100000
 12393/100000: episode: 66, duration: 2.601s, episode steps: 387, steps per second: 149, episode reward: -158.045, mean reward: -0.408 [-100.000, 8.958], mean action: 1.775 [0.000, 3.000], mean observation: 0.142 [-1.004, 1.411], loss: 10.401033, mean_absolute_error: 25.279008, mean_q: 14.003295, mean_eps: 0.100000
 12720/100000: episode: 67, duration: 2.091s, episode steps: 327, steps per second: 156, episode reward: -108.258, mean reward: -0.331 [-100.000, 10.355], mean action: 1.560 [0.000, 3.000], mean observation: 0.126 [-1.475, 1.412], loss: 10.330626, mean_absolute_error: 25.711074, mean_q: 14.634005, mean_eps: 0.100000
 12899/100000: episode: 68, duration: 1.061s, episode steps: 179, steps per second: 169, episode reward: -119.668, mean reward: -0.669 [-100.000, 3.430], mean action: 1.330 [0.000, 3.000], mean observation: -0.028 [-1.004, 1.518], loss: 10.772726, mean_absolute_error: 25.463702, mean_q: 13.392603, mean_eps: 0.100000
 13109/100000: episode: 69, duration: 1.289s, episode steps: 210, steps per second: 163, episode reward: -66.671, mean reward: -0.317 [-100.000, 8.246], mean action: 1.857 [0.000, 3.000], mean observation: 0.112 [-0.682, 2.220], loss: 13.402249, mean_absolute_error: 26.006586, mean_q: 15.181156, mean_eps: 0.100000
 13280/100000: episode: 70, duration: 1.025s, episode steps: 171, steps per second: 167, episode reward: -105.856, mean reward: -0.619 [-100.000, 3.215], mean action: 1.608 [0.000, 3.000], mean observation: -0.054 [-1.006, 1.401], loss: 9.673508, mean_absolute_error: 25.528869, mean_q: 14.746136, mean_eps: 0.100000
 13520/100000: episode: 71, duration: 1.485s, episode steps: 240, steps per second: 162, episode reward: -98.762, mean reward: -0.412 [-100.000, 7.642], mean action: 1.629 [0.000, 3.000], mean observation: 0.092 [-2.238, 1.401], loss: 9.038838, mean_absolute_error: 25.557431, mean_q: 14.377752, mean_eps: 0.100000
 13823/100000: episode: 72, duration: 1.935s, episode steps: 303, steps per second: 157, episode reward: -63.052, mean reward: -0.208 [-100.000, 19.338], mean action: 1.366 [0.000, 3.000], mean observation: 0.058 [-0.751, 1.417], loss: 8.902410, mean_absolute_error: 26.410809, mean_q: 14.564591, mean_eps: 0.100000
 14119/100000: episode: 73, duration: 1.854s, episode steps: 296, steps per second: 160, episode reward: -49.555, mean reward: -0.167 [-100.000, 13.433], mean action: 1.601 [0.000, 3.000], mean observation: 0.172 [-0.851, 1.395], loss: 11.899277, mean_absolute_error: 26.467308, mean_q: 14.040884, mean_eps: 0.100000
 14472/100000: episode: 74, duration: 2.191s, episode steps: 353, steps per second: 161, episode reward: -111.253, mean reward: -0.315 [-100.000, 10.814], mean action: 1.499 [0.000, 3.000], mean observation: 0.155 [-0.845, 1.792], loss: 10.224699, mean_absolute_error: 26.394753, mean_q: 14.788628, mean_eps: 0.100000
 14814/100000: episode: 75, duration: 2.217s, episode steps: 342, steps per second: 154, episode reward: -89.284, mean reward: -0.261 [-100.000, 10.995], mean action: 1.561 [0.000, 3.000], mean observation: 0.118 [-2.330, 1.393], loss: 9.258858, mean_absolute_error: 26.413697, mean_q: 14.475654, mean_eps: 0.100000
 15275/100000: episode: 76, duration: 3.134s, episode steps: 461, steps per second: 147, episode reward: -100.939, mean reward: -0.219 [-100.000, 15.447], mean action: 1.779 [0.000, 3.000], mean observation: 0.162 [-1.080, 1.397], loss: 10.921224, mean_absolute_error: 25.776701, mean_q: 13.784434, mean_eps: 0.100000
 15697/100000: episode: 77, duration: 2.695s, episode steps: 422, steps per second: 157, episode reward: -144.956, mean reward: -0.343 [-100.000, 4.024], mean action: 1.675 [0.000, 3.000], mean observation: -0.017 [-1.004, 1.415], loss: 9.912119, mean_absolute_error: 26.158847, mean_q: 14.510088, mean_eps: 0.100000
 16392/100000: episode: 78, duration: 5.089s, episode steps: 695, steps per second: 137, episode reward: -311.467, mean reward: -0.448 [-100.000, 18.540], mean action: 1.853 [0.000, 3.000], mean observation: 0.117 [-1.990, 1.452], loss: 10.563753, mean_absolute_error: 25.696173, mean_q: 14.184513, mean_eps: 0.100000
 16683/100000: episode: 79, duration: 1.796s, episode steps: 291, steps per second: 162, episode reward: -54.222, mean reward: -0.186 [-100.000, 13.754], mean action: 1.756 [0.000, 3.000], mean observation: 0.119 [-0.787, 1.411], loss: 13.850016, mean_absolute_error: 25.600406, mean_q: 13.923388, mean_eps: 0.100000
 17049/100000: episode: 80, duration: 2.354s, episode steps: 366, steps per second: 155, episode reward: -145.359, mean reward: -0.397 [-100.000, 5.307], mean action: 1.852 [0.000, 3.000], mean observation: 0.106 [-0.803, 1.994], loss: 8.151118, mean_absolute_error: 25.999302, mean_q: 13.691301, mean_eps: 0.100000
 17484/100000: episode: 81, duration: 3.040s, episode steps: 435, steps per second: 143, episode reward: -116.594, mean reward: -0.268 [-100.000, 9.138], mean action: 1.726 [0.000, 3.000], mean observation: 0.118 [-0.726, 1.681], loss: 10.215110, mean_absolute_error: 25.770879, mean_q: 13.136301, mean_eps: 0.100000
 18484/100000: episode: 82, duration: 9.827s, episode steps: 1000, steps per second: 102, episode reward: -73.269, mean reward: -0.073 [-4.647, 4.679], mean action: 1.905 [0.000, 3.000], mean observation: 0.096 [-0.533, 1.416], loss: 9.688678, mean_absolute_error: 25.242522, mean_q: 13.499999, mean_eps: 0.100000
 19063/100000: episode: 83, duration: 3.880s, episode steps: 579, steps per second: 149, episode reward: -114.113, mean reward: -0.197 [-100.000, 13.728], mean action: 1.718 [0.000, 3.000], mean observation: 0.088 [-0.989, 1.394], loss: 7.308984, mean_absolute_error: 24.547716, mean_q: 12.898169, mean_eps: 0.100000
 19364/100000: episode: 84, duration: 1.890s, episode steps: 301, steps per second: 159, episode reward: -113.950, mean reward: -0.379 [-100.000, 4.506], mean action: 1.791 [0.000, 3.000], mean observation: 0.270 [-0.293, 1.414], loss: 7.552328, mean_absolute_error: 24.166605, mean_q: 12.790541, mean_eps: 0.100000
 19606/100000: episode: 85, duration: 1.494s, episode steps: 242, steps per second: 162, episode reward: -152.459, mean reward: -0.630 [-100.000, 4.552], mean action: 1.694 [0.000, 3.000], mean observation: 0.247 [-0.407, 1.394], loss: 11.349572, mean_absolute_error: 24.274878, mean_q: 13.112937, mean_eps: 0.100000
 20606/100000: episode: 86, duration: 7.090s, episode steps: 1000, steps per second: 141, episode reward: -84.895, mean reward: -0.085 [-4.344, 5.238], mean action: 1.605 [0.000, 3.000], mean observation: 0.178 [-0.325, 1.501], loss: 8.902169, mean_absolute_error: 23.404374, mean_q: 13.115309, mean_eps: 0.100000
 20906/100000: episode: 87, duration: 1.916s, episode steps: 300, steps per second: 157, episode reward: -27.475, mean reward: -0.092 [-100.000, 14.891], mean action: 1.650 [0.000, 3.000], mean observation: 0.101 [-0.939, 1.388], loss: 8.224927, mean_absolute_error: 23.173254, mean_q: 12.956657, mean_eps: 0.100000
 21256/100000: episode: 88, duration: 2.184s, episode steps: 350, steps per second: 160, episode reward: -121.947, mean reward: -0.348 [-100.000, 4.429], mean action: 1.563 [0.000, 3.000], mean observation: -0.000 [-1.001, 1.409], loss: 8.314870, mean_absolute_error: 23.059421, mean_q: 14.126119, mean_eps: 0.100000
 21387/100000: episode: 89, duration: 0.782s, episode steps: 131, steps per second: 168, episode reward: -146.167, mean reward: -1.116 [-100.000, 1.427], mean action: 1.389 [0.000, 3.000], mean observation: -0.008 [-1.005, 1.412], loss: 11.029573, mean_absolute_error: 23.272544, mean_q: 14.481889, mean_eps: 0.100000
 22387/100000: episode: 90, duration: 8.035s, episode steps: 1000, steps per second: 124, episode reward: -40.606, mean reward: -0.041 [-4.635, 4.934], mean action: 1.682 [0.000, 3.000], mean observation: 0.135 [-0.393, 1.414], loss: 11.011907, mean_absolute_error: 22.452890, mean_q: 14.148314, mean_eps: 0.100000
 23387/100000: episode: 91, duration: 7.725s, episode steps: 1000, steps per second: 129, episode reward: -89.408, mean reward: -0.089 [-4.711, 4.059], mean action: 1.795 [0.000, 3.000], mean observation: 0.180 [-0.334, 1.463], loss: 10.129414, mean_absolute_error: 21.017039, mean_q: 13.876202, mean_eps: 0.100000
 24387/100000: episode: 92, duration: 7.280s, episode steps: 1000, steps per second: 137, episode reward: -34.296, mean reward: -0.034 [-4.772, 5.077], mean action: 1.509 [0.000, 3.000], mean observation: 0.094 [-0.422, 1.455], loss: 9.144829, mean_absolute_error: 20.763861, mean_q: 13.672353, mean_eps: 0.100000
 25387/100000: episode: 93, duration: 9.428s, episode steps: 1000, steps per second: 106, episode reward: -113.431, mean reward: -0.113 [-4.942, 4.649], mean action: 1.815 [0.000, 3.000], mean observation: 0.145 [-0.388, 1.430], loss: 8.853962, mean_absolute_error: 20.106036, mean_q: 13.221832, mean_eps: 0.100000
 25512/100000: episode: 94, duration: 0.749s, episode steps: 125, steps per second: 167, episode reward: -202.391, mean reward: -1.619 [-100.000, 0.812], mean action: 1.616 [0.000, 3.000], mean observation: 0.024 [-1.007, 1.451], loss: 5.156673, mean_absolute_error: 19.486779, mean_q: 12.819189, mean_eps: 0.100000
 26512/100000: episode: 95, duration: 7.921s, episode steps: 1000, steps per second: 126, episode reward: -111.915, mean reward: -0.112 [-4.354, 6.379], mean action: 1.558 [0.000, 3.000], mean observation: 0.095 [-0.731, 1.420], loss: 9.439044, mean_absolute_error: 19.134122, mean_q: 12.262028, mean_eps: 0.100000
 27512/100000: episode: 96, duration: 7.215s, episode steps: 1000, steps per second: 139, episode reward: -70.779, mean reward: -0.071 [-5.188, 5.406], mean action: 1.532 [0.000, 3.000], mean observation: 0.126 [-0.575, 1.402], loss: 7.828513, mean_absolute_error: 18.496739, mean_q: 11.701162, mean_eps: 0.100000
 28512/100000: episode: 97, duration: 7.470s, episode steps: 1000, steps per second: 134, episode reward: -71.022, mean reward: -0.071 [-4.864, 4.876], mean action: 1.492 [0.000, 3.000], mean observation: 0.106 [-0.454, 1.393], loss: 7.713052, mean_absolute_error: 17.987488, mean_q: 12.090087, mean_eps: 0.100000
 29512/100000: episode: 98, duration: 7.237s, episode steps: 1000, steps per second: 138, episode reward: -85.388, mean reward: -0.085 [-5.376, 4.376], mean action: 1.608 [0.000, 3.000], mean observation: 0.122 [-0.448, 1.406], loss: 7.638818, mean_absolute_error: 17.671480, mean_q: 12.072427, mean_eps: 0.100000
 29730/100000: episode: 99, duration: 1.340s, episode steps: 218, steps per second: 163, episode reward: -118.301, mean reward: -0.543 [-100.000, 4.413], mean action: 1.537 [0.000, 3.000], mean observation: -0.021 [-1.001, 1.385], loss: 8.103446, mean_absolute_error: 17.143165, mean_q: 12.368791, mean_eps: 0.100000
 30730/100000: episode: 100, duration: 6.956s, episode steps: 1000, steps per second: 144, episode reward: -82.744, mean reward: -0.083 [-4.823, 5.179], mean action: 1.496 [0.000, 3.000], mean observation: 0.107 [-0.475, 1.389], loss: 7.228173, mean_absolute_error: 17.422095, mean_q: 12.682812, mean_eps: 0.100000
 31730/100000: episode: 101, duration: 6.967s, episode steps: 1000, steps per second: 144, episode reward: -28.433, mean reward: -0.028 [-4.991, 4.755], mean action: 1.441 [0.000, 3.000], mean observation: 0.061 [-0.672, 1.469], loss: 7.787611, mean_absolute_error: 17.476811, mean_q: 12.469179, mean_eps: 0.100000
 32730/100000: episode: 102, duration: 7.970s, episode steps: 1000, steps per second: 125, episode reward: -24.642, mean reward: -0.025 [-4.773, 4.676], mean action: 1.500 [0.000, 3.000], mean observation: 0.103 [-0.582, 1.395], loss: 6.708246, mean_absolute_error: 17.410762, mean_q: 13.839176, mean_eps: 0.100000
 33730/100000: episode: 103, duration: 8.792s, episode steps: 1000, steps per second: 114, episode reward: -25.576, mean reward: -0.026 [-4.475, 6.105], mean action: 1.528 [0.000, 3.000], mean observation: 0.107 [-0.505, 1.416], loss: 7.453086, mean_absolute_error: 17.339039, mean_q: 14.382756, mean_eps: 0.100000
 34730/100000: episode: 104, duration: 7.972s, episode steps: 1000, steps per second: 125, episode reward: -74.057, mean reward: -0.074 [-4.541, 4.849], mean action: 1.441 [0.000, 3.000], mean observation: 0.094 [-0.387, 1.471], loss: 6.342310, mean_absolute_error: 17.229893, mean_q: 14.989060, mean_eps: 0.100000
 35730/100000: episode: 105, duration: 8.092s, episode steps: 1000, steps per second: 124, episode reward: -81.020, mean reward: -0.081 [-4.306, 4.840], mean action: 1.508 [0.000, 3.000], mean observation: 0.093 [-0.565, 1.416], loss: 6.018765, mean_absolute_error: 17.447572, mean_q: 15.495804, mean_eps: 0.100000
 36730/100000: episode: 106, duration: 9.093s, episode steps: 1000, steps per second: 110, episode reward: -35.246, mean reward: -0.035 [-4.557, 5.323], mean action: 1.521 [0.000, 3.000], mean observation: 0.102 [-0.459, 1.398], loss: 5.345604, mean_absolute_error: 17.225414, mean_q: 15.899656, mean_eps: 0.100000
 37730/100000: episode: 107, duration: 8.044s, episode steps: 1000, steps per second: 124, episode reward: -27.729, mean reward: -0.028 [-4.103, 5.155], mean action: 1.553 [0.000, 3.000], mean observation: 0.071 [-0.666, 1.397], loss: 5.962276, mean_absolute_error: 16.848623, mean_q: 16.442985, mean_eps: 0.100000
 38730/100000: episode: 108, duration: 7.930s, episode steps: 1000, steps per second: 126, episode reward: -76.106, mean reward: -0.076 [-4.690, 4.451], mean action: 1.605 [0.000, 3.000], mean observation: 0.100 [-0.527, 1.409], loss: 6.505173, mean_absolute_error: 16.805387, mean_q: 16.503151, mean_eps: 0.100000
 39600/100000: episode: 109, duration: 6.175s, episode steps: 870, steps per second: 141, episode reward: -358.665, mean reward: -0.412 [-100.000, 15.376], mean action: 1.711 [0.000, 3.000], mean observation: 0.105 [-0.947, 2.080], loss: 5.031094, mean_absolute_error: 16.814508, mean_q: 16.826981, mean_eps: 0.100000
 40600/100000: episode: 110, duration: 7.609s, episode steps: 1000, steps per second: 131, episode reward: -32.062, mean reward: -0.032 [-5.191, 3.688], mean action: 1.512 [0.000, 3.000], mean observation: 0.078 [-0.702, 1.428], loss: 6.280149, mean_absolute_error: 16.567028, mean_q: 17.535002, mean_eps: 0.100000
 41600/100000: episode: 111, duration: 6.813s, episode steps: 1000, steps per second: 147, episode reward: -23.317, mean reward: -0.023 [-4.997, 5.083], mean action: 1.436 [0.000, 3.000], mean observation: 0.119 [-0.467, 1.415], loss: 6.476797, mean_absolute_error: 16.626156, mean_q: 17.190159, mean_eps: 0.100000
 42600/100000: episode: 112, duration: 6.800s, episode steps: 1000, steps per second: 147, episode reward: -33.948, mean reward: -0.034 [-5.416, 4.644], mean action: 1.531 [0.000, 3.000], mean observation: 0.115 [-0.639, 1.392], loss: 5.387055, mean_absolute_error: 16.447378, mean_q: 17.135587, mean_eps: 0.100000
 43600/100000: episode: 113, duration: 6.988s, episode steps: 1000, steps per second: 143, episode reward: -66.175, mean reward: -0.066 [-4.667, 4.438], mean action: 1.506 [0.000, 3.000], mean observation: 0.126 [-0.306, 1.397], loss: 5.812590, mean_absolute_error: 16.150650, mean_q: 16.615729, mean_eps: 0.100000
 44397/100000: episode: 114, duration: 6.235s, episode steps: 797, steps per second: 128, episode reward: -143.291, mean reward: -0.180 [-100.000, 9.911], mean action: 1.487 [0.000, 3.000], mean observation: 0.036 [-0.686, 1.408], loss: 6.847012, mean_absolute_error: 16.314923, mean_q: 16.983464, mean_eps: 0.100000
 45397/100000: episode: 115, duration: 8.035s, episode steps: 1000, steps per second: 124, episode reward: 11.305, mean reward: 0.011 [-23.108, 26.714], mean action: 1.589 [0.000, 3.000], mean observation: 0.033 [-0.775, 1.505], loss: 7.330888, mean_absolute_error: 16.232845, mean_q: 16.779672, mean_eps: 0.100000
 46397/100000: episode: 116, duration: 7.928s, episode steps: 1000, steps per second: 126, episode reward: -43.901, mean reward: -0.044 [-4.664, 5.287], mean action: 1.572 [0.000, 3.000], mean observation: 0.085 [-0.435, 1.420], loss: 6.564784, mean_absolute_error: 16.306937, mean_q: 17.077404, mean_eps: 0.100000
 47278/100000: episode: 117, duration: 7.794s, episode steps: 881, steps per second: 113, episode reward: 137.776, mean reward: 0.156 [-13.234, 100.000], mean action: 1.453 [0.000, 3.000], mean observation: 0.019 [-0.763, 1.403], loss: 5.633371, mean_absolute_error: 16.479008, mean_q: 17.365311, mean_eps: 0.100000
 48278/100000: episode: 118, duration: 8.387s, episode steps: 1000, steps per second: 119, episode reward: -94.056, mean reward: -0.094 [-4.592, 4.180], mean action: 1.595 [0.000, 3.000], mean observation: 0.111 [-0.325, 1.425], loss: 7.374295, mean_absolute_error: 16.481869, mean_q: 18.257862, mean_eps: 0.100000
 49278/100000: episode: 119, duration: 7.552s, episode steps: 1000, steps per second: 132, episode reward: -59.382, mean reward: -0.059 [-4.204, 4.752], mean action: 1.678 [0.000, 3.000], mean observation: 0.048 [-0.477, 1.415], loss: 5.349246, mean_absolute_error: 16.716216, mean_q: 18.752526, mean_eps: 0.100000
 50278/100000: episode: 120, duration: 7.402s, episode steps: 1000, steps per second: 135, episode reward: -47.333, mean reward: -0.047 [-4.906, 5.294], mean action: 1.643 [0.000, 3.000], mean observation: 0.117 [-0.383, 1.407], loss: 6.971817, mean_absolute_error: 17.067293, mean_q: 19.382980, mean_eps: 0.100000
 51278/100000: episode: 121, duration: 7.742s, episode steps: 1000, steps per second: 129, episode reward: -17.500, mean reward: -0.018 [-4.124, 5.387], mean action: 1.553 [0.000, 3.000], mean observation: 0.034 [-0.645, 1.500], loss: 5.430050, mean_absolute_error: 17.112737, mean_q: 20.080412, mean_eps: 0.100000
 52278/100000: episode: 122, duration: 8.798s, episode steps: 1000, steps per second: 114, episode reward: -80.886, mean reward: -0.081 [-3.726, 4.717], mean action: 1.461 [0.000, 3.000], mean observation: 0.039 [-0.421, 1.409], loss: 6.157781, mean_absolute_error: 16.994992, mean_q: 20.663279, mean_eps: 0.100000
 53278/100000: episode: 123, duration: 9.931s, episode steps: 1000, steps per second: 101, episode reward: -63.836, mean reward: -0.064 [-4.008, 4.296], mean action: 1.510 [0.000, 3.000], mean observation: 0.088 [-0.288, 1.408], loss: 5.762473, mean_absolute_error: 17.022033, mean_q: 21.006652, mean_eps: 0.100000
 54278/100000: episode: 124, duration: 8.556s, episode steps: 1000, steps per second: 117, episode reward: -85.425, mean reward: -0.085 [-4.881, 4.152], mean action: 1.528 [0.000, 3.000], mean observation: 0.043 [-0.480, 1.402], loss: 4.483113, mean_absolute_error: 17.196790, mean_q: 21.727304, mean_eps: 0.100000
 55278/100000: episode: 125, duration: 7.581s, episode steps: 1000, steps per second: 132, episode reward: -61.447, mean reward: -0.061 [-4.088, 4.643], mean action: 1.546 [0.000, 3.000], mean observation: 0.037 [-0.520, 1.464], loss: 3.923451, mean_absolute_error: 17.768475, mean_q: 22.683055, mean_eps: 0.100000
 56278/100000: episode: 126, duration: 6.990s, episode steps: 1000, steps per second: 143, episode reward: -92.139, mean reward: -0.092 [-4.342, 3.714], mean action: 1.472 [0.000, 3.000], mean observation: 0.006 [-0.595, 1.405], loss: 4.068508, mean_absolute_error: 18.074411, mean_q: 22.969371, mean_eps: 0.100000
 57278/100000: episode: 127, duration: 7.223s, episode steps: 1000, steps per second: 138, episode reward: -45.640, mean reward: -0.046 [-4.166, 4.762], mean action: 1.508 [0.000, 3.000], mean observation: 0.006 [-0.503, 1.391], loss: 4.608211, mean_absolute_error: 18.158643, mean_q: 23.127343, mean_eps: 0.100000
 58278/100000: episode: 128, duration: 7.878s, episode steps: 1000, steps per second: 127, episode reward: -57.228, mean reward: -0.057 [-4.018, 4.854], mean action: 1.487 [0.000, 3.000], mean observation: 0.017 [-0.535, 1.388], loss: 4.083965, mean_absolute_error: 18.653509, mean_q: 24.054955, mean_eps: 0.100000
 59278/100000: episode: 129, duration: 8.983s, episode steps: 1000, steps per second: 111, episode reward: -35.518, mean reward: -0.036 [-4.655, 4.197], mean action: 1.683 [0.000, 3.000], mean observation: 0.044 [-0.587, 1.386], loss: 3.769887, mean_absolute_error: 18.952174, mean_q: 24.672718, mean_eps: 0.100000
 60278/100000: episode: 130, duration: 7.340s, episode steps: 1000, steps per second: 136, episode reward: -79.232, mean reward: -0.079 [-4.605, 4.784], mean action: 1.728 [0.000, 3.000], mean observation: 0.007 [-0.492, 1.398], loss: 2.896750, mean_absolute_error: 19.833674, mean_q: 25.884878, mean_eps: 0.100000
 61278/100000: episode: 131, duration: 8.055s, episode steps: 1000, steps per second: 124, episode reward: -104.302, mean reward: -0.104 [-3.735, 4.383], mean action: 1.552 [0.000, 3.000], mean observation: 0.009 [-0.652, 1.405], loss: 4.397146, mean_absolute_error: 20.576887, mean_q: 26.926379, mean_eps: 0.100000
 62278/100000: episode: 132, duration: 7.568s, episode steps: 1000, steps per second: 132, episode reward: -28.362, mean reward: -0.028 [-2.977, 4.614], mean action: 1.536 [0.000, 3.000], mean observation: 0.034 [-0.490, 1.418], loss: 2.690518, mean_absolute_error: 20.919919, mean_q: 27.346715, mean_eps: 0.100000
 63278/100000: episode: 133, duration: 8.121s, episode steps: 1000, steps per second: 123, episode reward: 10.810, mean reward: 0.011 [-21.394, 22.414], mean action: 1.557 [0.000, 3.000], mean observation: 0.049 [-0.614, 1.408], loss: 3.514521, mean_absolute_error: 21.364044, mean_q: 27.891466, mean_eps: 0.100000
 64278/100000: episode: 134, duration: 7.735s, episode steps: 1000, steps per second: 129, episode reward: 2.612, mean reward: 0.003 [-11.951, 16.025], mean action: 1.556 [0.000, 3.000], mean observation: 0.034 [-0.659, 1.448], loss: 3.880178, mean_absolute_error: 21.141313, mean_q: 27.718455, mean_eps: 0.100000
 65278/100000: episode: 135, duration: 8.380s, episode steps: 1000, steps per second: 119, episode reward: -31.085, mean reward: -0.031 [-4.127, 4.333], mean action: 1.801 [0.000, 3.000], mean observation: 0.095 [-0.471, 1.395], loss: 3.679258, mean_absolute_error: 20.846854, mean_q: 27.388676, mean_eps: 0.100000
 65413/100000: episode: 136, duration: 0.806s, episode steps: 135, steps per second: 167, episode reward: -133.363, mean reward: -0.988 [-100.000, 7.534], mean action: 1.178 [0.000, 3.000], mean observation: 0.001 [-1.551, 1.436], loss: 2.104473, mean_absolute_error: 20.594210, mean_q: 26.965220, mean_eps: 0.100000
 65517/100000: episode: 137, duration: 0.616s, episode steps: 104, steps per second: 169, episode reward: -146.612, mean reward: -1.410 [-100.000, 16.682], mean action: 1.087 [0.000, 3.000], mean observation: -0.070 [-1.237, 1.394], loss: 2.069405, mean_absolute_error: 20.345992, mean_q: 26.753494, mean_eps: 0.100000
 66517/100000: episode: 138, duration: 7.613s, episode steps: 1000, steps per second: 131, episode reward: -69.826, mean reward: -0.070 [-3.133, 4.864], mean action: 1.683 [0.000, 3.000], mean observation: 0.021 [-0.563, 1.450], loss: 2.209402, mean_absolute_error: 20.377349, mean_q: 26.750607, mean_eps: 0.100000
 67448/100000: episode: 139, duration: 7.072s, episode steps: 931, steps per second: 132, episode reward: -153.977, mean reward: -0.165 [-100.000, 14.572], mean action: 1.735 [0.000, 3.000], mean observation: -0.043 [-0.649, 1.391], loss: 3.491838, mean_absolute_error: 20.011028, mean_q: 26.353231, mean_eps: 0.100000
 67778/100000: episode: 140, duration: 2.197s, episode steps: 330, steps per second: 150, episode reward: -51.718, mean reward: -0.157 [-100.000, 10.585], mean action: 1.697 [0.000, 3.000], mean observation: 0.093 [-2.157, 1.398], loss: 3.140337, mean_absolute_error: 19.832565, mean_q: 26.181216, mean_eps: 0.100000
 68152/100000: episode: 141, duration: 2.374s, episode steps: 374, steps per second: 158, episode reward: -454.621, mean reward: -1.216 [-100.000, 5.997], mean action: 1.650 [0.000, 3.000], mean observation: -0.000 [-2.249, 1.680], loss: 3.132545, mean_absolute_error: 19.823338, mean_q: 25.918775, mean_eps: 0.100000
 69152/100000: episode: 142, duration: 8.065s, episode steps: 1000, steps per second: 124, episode reward: -29.989, mean reward: -0.030 [-4.124, 4.309], mean action: 1.776 [0.000, 3.000], mean observation: 0.025 [-0.658, 1.387], loss: 2.563626, mean_absolute_error: 19.762804, mean_q: 25.430470, mean_eps: 0.100000
 69560/100000: episode: 143, duration: 2.612s, episode steps: 408, steps per second: 156, episode reward: -111.127, mean reward: -0.272 [-100.000, 3.725], mean action: 1.745 [0.000, 3.000], mean observation: 0.231 [-0.234, 1.490], loss: 2.786990, mean_absolute_error: 19.702992, mean_q: 25.391947, mean_eps: 0.100000
 70560/100000: episode: 144, duration: 7.634s, episode steps: 1000, steps per second: 131, episode reward: -49.158, mean reward: -0.049 [-4.502, 4.791], mean action: 1.531 [0.000, 3.000], mean observation: 0.006 [-0.440, 1.394], loss: 2.574147, mean_absolute_error: 19.168632, mean_q: 24.971216, mean_eps: 0.100000
 71560/100000: episode: 145, duration: 7.439s, episode steps: 1000, steps per second: 134, episode reward: -3.844, mean reward: -0.004 [-4.909, 4.564], mean action: 1.504 [0.000, 3.000], mean observation: -0.003 [-0.693, 1.396], loss: 3.028750, mean_absolute_error: 18.482332, mean_q: 23.914039, mean_eps: 0.100000
 72560/100000: episode: 146, duration: 8.695s, episode steps: 1000, steps per second: 115, episode reward: 0.947, mean reward: 0.001 [-18.062, 15.227], mean action: 1.959 [0.000, 3.000], mean observation: 0.063 [-0.946, 1.412], loss: 2.350117, mean_absolute_error: 17.893348, mean_q: 23.166000, mean_eps: 0.100000
 73560/100000: episode: 147, duration: 9.646s, episode steps: 1000, steps per second: 104, episode reward: -46.064, mean reward: -0.046 [-4.820, 4.409], mean action: 1.590 [0.000, 3.000], mean observation: 0.057 [-0.377, 1.393], loss: 3.326102, mean_absolute_error: 17.403458, mean_q: 22.498472, mean_eps: 0.100000
 74560/100000: episode: 148, duration: 8.435s, episode steps: 1000, steps per second: 119, episode reward: -25.931, mean reward: -0.026 [-4.868, 4.830], mean action: 1.514 [0.000, 3.000], mean observation: 0.075 [-0.384, 1.518], loss: 1.613565, mean_absolute_error: 17.352378, mean_q: 22.413152, mean_eps: 0.100000
 75560/100000: episode: 149, duration: 7.989s, episode steps: 1000, steps per second: 125, episode reward: -46.426, mean reward: -0.046 [-4.796, 4.561], mean action: 1.405 [0.000, 3.000], mean observation: 0.031 [-0.366, 1.426], loss: 1.612853, mean_absolute_error: 17.106010, mean_q: 22.105684, mean_eps: 0.100000
 75867/100000: episode: 150, duration: 1.975s, episode steps: 307, steps per second: 155, episode reward: -147.118, mean reward: -0.479 [-100.000, 4.520], mean action: 1.821 [0.000, 3.000], mean observation: 0.166 [-0.743, 1.394], loss: 2.373888, mean_absolute_error: 16.823668, mean_q: 21.559188, mean_eps: 0.100000
 76867/100000: episode: 151, duration: 7.336s, episode steps: 1000, steps per second: 136, episode reward: -54.901, mean reward: -0.055 [-4.064, 4.731], mean action: 1.432 [0.000, 3.000], mean observation: 0.006 [-0.515, 1.403], loss: 3.482467, mean_absolute_error: 16.846853, mean_q: 21.366272, mean_eps: 0.100000
 77864/100000: episode: 152, duration: 8.511s, episode steps: 997, steps per second: 117, episode reward: -585.769, mean reward: -0.588 [-100.000, 20.198], mean action: 1.478 [0.000, 3.000], mean observation: 0.053 [-1.849, 3.208], loss: 2.606936, mean_absolute_error: 16.600596, mean_q: 21.230943, mean_eps: 0.100000
 78864/100000: episode: 153, duration: 8.569s, episode steps: 1000, steps per second: 117, episode reward: 1.712, mean reward: 0.002 [-4.717, 6.168], mean action: 1.564 [0.000, 3.000], mean observation: -0.010 [-0.719, 1.599], loss: 6.173123, mean_absolute_error: 16.873566, mean_q: 20.811665, mean_eps: 0.100000
 79864/100000: episode: 154, duration: 9.248s, episode steps: 1000, steps per second: 108, episode reward: -52.030, mean reward: -0.052 [-4.238, 4.749], mean action: 1.546 [0.000, 3.000], mean observation: 0.025 [-0.354, 1.400], loss: 2.948861, mean_absolute_error: 17.061518, mean_q: 21.331979, mean_eps: 0.100000
 80864/100000: episode: 155, duration: 7.419s, episode steps: 1000, steps per second: 135, episode reward: -2.585, mean reward: -0.003 [-4.196, 6.085], mean action: 1.463 [0.000, 3.000], mean observation: -0.002 [-0.686, 1.523], loss: 7.511529, mean_absolute_error: 17.134855, mean_q: 21.493961, mean_eps: 0.100000
 81864/100000: episode: 156, duration: 8.837s, episode steps: 1000, steps per second: 113, episode reward: -26.139, mean reward: -0.026 [-4.458, 4.688], mean action: 1.493 [0.000, 3.000], mean observation: 0.013 [-0.572, 1.389], loss: 2.223078, mean_absolute_error: 16.773961, mean_q: 21.033800, mean_eps: 0.100000
 82864/100000: episode: 157, duration: 7.061s, episode steps: 1000, steps per second: 142, episode reward: -0.262, mean reward: -0.000 [-4.734, 5.751], mean action: 1.510 [0.000, 3.000], mean observation: 0.002 [-0.655, 1.528], loss: 5.524301, mean_absolute_error: 16.241160, mean_q: 20.691956, mean_eps: 0.100000
 83864/100000: episode: 158, duration: 7.553s, episode steps: 1000, steps per second: 132, episode reward: -46.319, mean reward: -0.046 [-4.968, 5.906], mean action: 1.471 [0.000, 3.000], mean observation: 0.043 [-0.315, 1.455], loss: 2.721545, mean_absolute_error: 15.779670, mean_q: 19.989531, mean_eps: 0.100000
 84864/100000: episode: 159, duration: 8.989s, episode steps: 1000, steps per second: 111, episode reward: -59.620, mean reward: -0.060 [-3.652, 4.543], mean action: 1.436 [0.000, 3.000], mean observation: 0.037 [-0.426, 1.406], loss: 1.699680, mean_absolute_error: 15.236044, mean_q: 19.373895, mean_eps: 0.100000
 85864/100000: episode: 160, duration: 9.020s, episode steps: 1000, steps per second: 111, episode reward: -31.764, mean reward: -0.032 [-3.839, 4.895], mean action: 1.496 [0.000, 3.000], mean observation: 0.031 [-0.723, 1.387], loss: 2.791505, mean_absolute_error: 15.008729, mean_q: 18.594353, mean_eps: 0.100000
 86864/100000: episode: 161, duration: 8.988s, episode steps: 1000, steps per second: 111, episode reward: -61.620, mean reward: -0.062 [-4.154, 4.254], mean action: 1.500 [0.000, 3.000], mean observation: 0.027 [-0.454, 1.401], loss: 1.682597, mean_absolute_error: 14.340488, mean_q: 18.208092, mean_eps: 0.100000
 87864/100000: episode: 162, duration: 8.956s, episode steps: 1000, steps per second: 112, episode reward: -62.873, mean reward: -0.063 [-5.865, 4.070], mean action: 1.499 [0.000, 3.000], mean observation: 0.022 [-0.578, 1.392], loss: 5.528272, mean_absolute_error: 13.750054, mean_q: 17.222732, mean_eps: 0.100000
 88864/100000: episode: 163, duration: 9.070s, episode steps: 1000, steps per second: 110, episode reward: -65.724, mean reward: -0.066 [-3.896, 4.899], mean action: 1.533 [0.000, 3.000], mean observation: 0.040 [-0.431, 1.429], loss: 4.621438, mean_absolute_error: 13.485135, mean_q: 16.835161, mean_eps: 0.100000
 89152/100000: episode: 164, duration: 1.805s, episode steps: 288, steps per second: 160, episode reward: -136.716, mean reward: -0.475 [-100.000, 5.494], mean action: 1.500 [0.000, 3.000], mean observation: -0.021 [-1.004, 1.421], loss: 5.312380, mean_absolute_error: 13.378042, mean_q: 16.681835, mean_eps: 0.100000
 90028/100000: episode: 165, duration: 7.449s, episode steps: 876, steps per second: 118, episode reward: 216.886, mean reward: 0.248 [-22.040, 100.000], mean action: 1.531 [0.000, 3.000], mean observation: 0.118 [-0.900, 1.394], loss: 3.580701, mean_absolute_error: 13.000338, mean_q: 16.360969, mean_eps: 0.100000
 90144/100000: episode: 166, duration: 0.705s, episode steps: 116, steps per second: 165, episode reward: -148.409, mean reward: -1.279 [-100.000, 2.765], mean action: 1.017 [0.000, 3.000], mean observation: 0.196 [-1.172, 1.409], loss: 2.792534, mean_absolute_error: 12.729513, mean_q: 15.725904, mean_eps: 0.100000
 90914/100000: episode: 167, duration: 5.768s, episode steps: 770, steps per second: 133, episode reward: 130.840, mean reward: 0.170 [-10.786, 100.000], mean action: 1.978 [0.000, 3.000], mean observation: 0.116 [-1.631, 1.392], loss: 1.919678, mean_absolute_error: 12.766104, mean_q: 16.012981, mean_eps: 0.100000
 91151/100000: episode: 168, duration: 1.462s, episode steps: 237, steps per second: 162, episode reward: -66.712, mean reward: -0.281 [-100.000, 10.627], mean action: 1.696 [0.000, 3.000], mean observation: 0.131 [-1.157, 1.691], loss: 3.077559, mean_absolute_error: 12.951684, mean_q: 16.169847, mean_eps: 0.100000
 91307/100000: episode: 169, duration: 0.946s, episode steps: 156, steps per second: 165, episode reward: -18.243, mean reward: -0.117 [-100.000, 39.752], mean action: 1.923 [0.000, 3.000], mean observation: 0.102 [-1.459, 1.421], loss: 19.683647, mean_absolute_error: 12.937049, mean_q: 16.017252, mean_eps: 0.100000
 91571/100000: episode: 170, duration: 1.665s, episode steps: 264, steps per second: 159, episode reward: -124.176, mean reward: -0.470 [-100.000, 5.574], mean action: 1.610 [0.000, 3.000], mean observation: -0.030 [-1.005, 1.391], loss: 2.676205, mean_absolute_error: 12.957631, mean_q: 16.230805, mean_eps: 0.100000
 91700/100000: episode: 171, duration: 0.772s, episode steps: 129, steps per second: 167, episode reward: -215.215, mean reward: -1.668 [-100.000, 3.073], mean action: 1.659 [0.000, 3.000], mean observation: -0.046 [-1.337, 1.396], loss: 4.224608, mean_absolute_error: 12.856998, mean_q: 15.999806, mean_eps: 0.100000
 91936/100000: episode: 172, duration: 1.484s, episode steps: 236, steps per second: 159, episode reward: -171.228, mean reward: -0.726 [-100.000, 22.392], mean action: 1.771 [0.000, 3.000], mean observation: 0.109 [-2.354, 1.398], loss: 5.454517, mean_absolute_error: 12.397579, mean_q: 15.365891, mean_eps: 0.100000
 92113/100000: episode: 173, duration: 1.075s, episode steps: 177, steps per second: 165, episode reward: -109.846, mean reward: -0.621 [-100.000, 18.465], mean action: 1.695 [0.000, 3.000], mean observation: 0.110 [-2.763, 1.483], loss: 3.188152, mean_absolute_error: 12.826604, mean_q: 15.973085, mean_eps: 0.100000
 92231/100000: episode: 174, duration: 0.708s, episode steps: 118, steps per second: 167, episode reward: -243.373, mean reward: -2.062 [-100.000, 3.791], mean action: 1.322 [0.000, 3.000], mean observation: 0.254 [-1.054, 1.434], loss: 3.021369, mean_absolute_error: 13.051519, mean_q: 15.935531, mean_eps: 0.100000
 93231/100000: episode: 175, duration: 7.743s, episode steps: 1000, steps per second: 129, episode reward: 13.315, mean reward: 0.013 [-10.604, 15.938], mean action: 1.761 [0.000, 3.000], mean observation: 0.065 [-0.656, 1.386], loss: 5.249228, mean_absolute_error: 12.608625, mean_q: 15.346267, mean_eps: 0.100000
 94117/100000: episode: 176, duration: 7.222s, episode steps: 886, steps per second: 123, episode reward: 122.777, mean reward: 0.139 [-24.061, 100.000], mean action: 1.657 [0.000, 3.000], mean observation: 0.070 [-0.798, 1.410], loss: 7.396911, mean_absolute_error: 12.504048, mean_q: 15.241213, mean_eps: 0.100000
 94209/100000: episode: 177, duration: 0.544s, episode steps: 92, steps per second: 169, episode reward: -438.608, mean reward: -4.767 [-100.000, -0.678], mean action: 0.815 [0.000, 3.000], mean observation: 0.003 [-2.425, 1.429], loss: 2.755854, mean_absolute_error: 12.635508, mean_q: 15.362965, mean_eps: 0.100000
 95209/100000: episode: 178, duration: 8.865s, episode steps: 1000, steps per second: 113, episode reward: -31.187, mean reward: -0.031 [-4.369, 10.937], mean action: 1.814 [0.000, 3.000], mean observation: 0.029 [-0.399, 1.402], loss: 3.748067, mean_absolute_error: 12.775338, mean_q: 15.219025, mean_eps: 0.100000
 95324/100000: episode: 179, duration: 0.680s, episode steps: 115, steps per second: 169, episode reward: -275.910, mean reward: -2.399 [-100.000, 9.432], mean action: 1.200 [0.000, 3.000], mean observation: -0.067 [-5.258, 1.497], loss: 2.543020, mean_absolute_error: 13.505886, mean_q: 15.402110, mean_eps: 0.100000
 96324/100000: episode: 180, duration: 7.548s, episode steps: 1000, steps per second: 132, episode reward: -11.215, mean reward: -0.011 [-3.832, 5.410], mean action: 1.671 [0.000, 3.000], mean observation: 0.059 [-0.476, 1.529], loss: 9.800013, mean_absolute_error: 13.598337, mean_q: 15.763338, mean_eps: 0.100000
 97196/100000: episode: 181, duration: 6.993s, episode steps: 872, steps per second: 125, episode reward: 127.636, mean reward: 0.146 [-11.453, 100.000], mean action: 1.497 [0.000, 3.000], mean observation: 0.043 [-0.528, 1.431], loss: 6.713946, mean_absolute_error: 13.712061, mean_q: 16.104096, mean_eps: 0.100000
 97973/100000: episode: 182, duration: 5.786s, episode steps: 777, steps per second: 134, episode reward: 138.263, mean reward: 0.178 [-10.415, 100.000], mean action: 1.674 [0.000, 3.000], mean observation: 0.050 [-0.507, 1.404], loss: 5.602372, mean_absolute_error: 13.994427, mean_q: 16.550862, mean_eps: 0.100000
 98973/100000: episode: 183, duration: 9.143s, episode steps: 1000, steps per second: 109, episode reward: -38.153, mean reward: -0.038 [-3.301, 5.212], mean action: 1.663 [0.000, 3.000], mean observation: 0.007 [-0.402, 1.395], loss: 4.945801, mean_absolute_error: 14.415509, mean_q: 17.313304, mean_eps: 0.100000
 99973/100000: episode: 184, duration: 7.994s, episode steps: 1000, steps per second: 125, episode reward: -33.155, mean reward: -0.033 [-3.728, 7.563], mean action: 1.685 [0.000, 3.000], mean observation: -0.011 [-1.055, 1.434], loss: 3.596136, mean_absolute_error: 15.100486, mean_q: 18.315063, mean_eps: 0.100000
done, took 772.261 seconds
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-Result">Evaluation Result<a class="anchor-link" href="#Evaluation-Result">&#182;</a></h2><p>We are testing the above model for 50 episodes and then looking at the mean reward value</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Finally, evaluate the agent</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">dqn5</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;episode_reward&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Test rewards (#episodes=</span><span class="si">{}</span><span class="s2">): mean=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, std=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, &quot;</span>
           <span class="s2">&quot;min=</span><span class="si">{:&gt;5.2f}</span><span class="s2">, max=</span><span class="si">{:&gt;5.2f}</span><span class="s2">&quot;</span><span class="p">)</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                  <span class="n">rewards</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>

<span class="n">rl_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 5&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Testing for 50 episodes ...
Episode 1: reward: -152.385, steps: 208
Episode 2: reward: -61.721, steps: 1000
Episode 3: reward: -21.787, steps: 1000
Episode 4: reward: -119.642, steps: 210
Episode 5: reward: -56.291, steps: 1000
Episode 6: reward: -104.080, steps: 271
Episode 7: reward: -38.385, steps: 1000
Episode 8: reward: -37.637, steps: 1000
Episode 9: reward: -52.232, steps: 1000
Episode 10: reward: -157.687, steps: 166
Episode 11: reward: 184.895, steps: 565
Episode 12: reward: -74.763, steps: 1000
Episode 13: reward: -119.801, steps: 227
Episode 14: reward: -108.668, steps: 212
Episode 15: reward: -37.236, steps: 1000
Episode 16: reward: -62.961, steps: 1000
Episode 17: reward: -161.091, steps: 176
Episode 18: reward: -131.141, steps: 208
Episode 19: reward: -54.391, steps: 1000
Episode 20: reward: -88.476, steps: 1000
Episode 21: reward: -25.260, steps: 1000
Episode 22: reward: -27.738, steps: 1000
Episode 23: reward: -157.261, steps: 186
Episode 24: reward: -69.314, steps: 1000
Episode 25: reward: -136.128, steps: 170
Episode 26: reward: -52.069, steps: 1000
Episode 27: reward: -150.914, steps: 196
Episode 28: reward: -94.599, steps: 260
Episode 29: reward: -30.444, steps: 1000
Episode 30: reward: -93.771, steps: 248
Episode 31: reward: -60.429, steps: 1000
Episode 32: reward: -34.927, steps: 1000
Episode 33: reward: -113.484, steps: 235
Episode 34: reward: -57.411, steps: 1000
Episode 35: reward: -61.515, steps: 1000
Episode 36: reward: -168.470, steps: 841
Episode 37: reward: -122.791, steps: 208
Episode 38: reward: -142.578, steps: 207
Episode 39: reward: -97.379, steps: 471
Episode 40: reward: -56.024, steps: 1000
Episode 41: reward: -161.894, steps: 168
Episode 42: reward: -44.458, steps: 1000
Episode 43: reward: -23.175, steps: 1000
Episode 44: reward: -68.104, steps: 1000
Episode 45: reward: -130.278, steps: 194
Episode 46: reward: -31.072, steps: 1000
Episode 47: reward: -13.920, steps: 1000
Episode 48: reward: -104.613, steps: 231
Episode 49: reward: 10.877, steps: 1000
Episode 50: reward: -19.201, steps: 1000
Test rewards (#episodes=50): mean=-75.88, std=60.24, min=-168.47, max=184.89
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Task-3">Task 3<a class="anchor-link" href="#Task-3">&#182;</a></h2><p>Deploy each of the two models trained to the Lunar Lander Game play 200 episodes and analyse the reward achieved by the models trained using each approach <br/></p>
<p>1) The lunar_lander_ml_images_player.py and lunar_lander_rl_player.py python scripts contain the code to load a saved model and run iterations of the game using that model.<br/>
2) Write a short document (no more that 350 words) in a Jupyter notebook to describe the results of the experiments.
3) Reflect on the performance of each model. <br/>
4) Reflect on the amount of computation required to train each model</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[46]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">task2_model_reward_comparisons</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python lunar_lander_rl_player_model1.py
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Using TensorFlow backend.
2019-04-28 21:04:37.446366: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
results
Testing for 200 episodes ...
Episode 1: reward: -104.231, steps: 1000
Episode 2: reward: -35.669, steps: 1000
Episode 3: reward: -50.068, steps: 1000
Episode 4: reward: -36.481, steps: 1000
Episode 5: reward: -102.598, steps: 1000
Episode 6: reward: -69.979, steps: 1000
Episode 7: reward: -89.020, steps: 1000
Episode 8: reward: -68.549, steps: 1000
Episode 9: reward: -98.523, steps: 1000
Episode 10: reward: -79.001, steps: 1000
Episode 11: reward: -51.673, steps: 1000
Episode 12: reward: -80.564, steps: 1000
Episode 13: reward: -56.508, steps: 1000
Episode 14: reward: -130.665, steps: 1000
Episode 15: reward: -79.176, steps: 1000
Episode 16: reward: -51.271, steps: 1000
Episode 17: reward: -79.792, steps: 1000
Episode 18: reward: -92.625, steps: 1000
Episode 19: reward: -100.128, steps: 1000
Episode 20: reward: -57.238, steps: 1000
Episode 21: reward: -48.744, steps: 1000
Episode 22: reward: -73.732, steps: 1000
Episode 23: reward: -54.549, steps: 1000
Episode 24: reward: -113.387, steps: 1000
Episode 25: reward: -82.968, steps: 1000
Episode 26: reward: -66.952, steps: 1000
Episode 27: reward: -75.407, steps: 1000
Episode 28: reward: -95.735, steps: 1000
Episode 29: reward: -69.017, steps: 1000
Episode 30: reward: -74.328, steps: 1000
Episode 31: reward: -85.235, steps: 1000
Episode 32: reward: -48.171, steps: 1000
Episode 33: reward: -52.659, steps: 1000
Episode 34: reward: -57.253, steps: 1000
Episode 35: reward: -50.103, steps: 1000
Episode 36: reward: -67.353, steps: 1000
Episode 37: reward: -97.246, steps: 1000
Episode 38: reward: -56.345, steps: 1000
Episode 39: reward: -132.674, steps: 1000
Episode 40: reward: -90.873, steps: 1000
Episode 41: reward: -95.650, steps: 1000
Episode 42: reward: -108.154, steps: 1000
Episode 43: reward: -127.996, steps: 1000
Episode 44: reward: -63.299, steps: 1000
Episode 45: reward: -55.616, steps: 1000
Episode 46: reward: -77.480, steps: 1000
Episode 47: reward: -44.420, steps: 1000
Episode 48: reward: -111.830, steps: 1000
Episode 49: reward: -127.231, steps: 1000
Episode 50: reward: -37.575, steps: 1000
Episode 51: reward: -103.264, steps: 1000
Episode 52: reward: -88.426, steps: 1000
Episode 53: reward: -61.278, steps: 1000
Episode 54: reward: -88.669, steps: 1000
Episode 55: reward: -130.941, steps: 1000
Episode 56: reward: -44.324, steps: 1000
Episode 57: reward: -46.571, steps: 1000
Episode 58: reward: -82.244, steps: 1000
Episode 59: reward: -98.695, steps: 1000
Episode 60: reward: -42.240, steps: 1000
Episode 61: reward: -65.163, steps: 1000
Episode 62: reward: -74.879, steps: 1000
Episode 63: reward: -88.039, steps: 1000
Episode 64: reward: -72.838, steps: 1000
Episode 65: reward: -119.218, steps: 1000
Episode 66: reward: -51.884, steps: 1000
Episode 67: reward: -59.085, steps: 1000
Episode 68: reward: -101.174, steps: 1000
Episode 69: reward: -86.714, steps: 1000
Episode 70: reward: -50.576, steps: 1000
Episode 71: reward: -61.279, steps: 1000
Episode 72: reward: -117.780, steps: 1000
Episode 73: reward: -51.864, steps: 1000
Episode 74: reward: -71.914, steps: 1000
Episode 75: reward: -89.116, steps: 1000
Episode 76: reward: -109.142, steps: 1000
Episode 77: reward: -107.643, steps: 1000
Episode 78: reward: -57.902, steps: 1000
Episode 79: reward: -105.550, steps: 1000
Episode 80: reward: -81.634, steps: 1000
Episode 81: reward: -41.204, steps: 1000
Episode 82: reward: -80.806, steps: 1000
Episode 83: reward: -81.558, steps: 1000
Episode 84: reward: -78.950, steps: 1000
Episode 85: reward: -78.013, steps: 1000
Episode 86: reward: -84.398, steps: 1000
Episode 87: reward: -46.172, steps: 1000
Episode 88: reward: -64.088, steps: 1000
Episode 89: reward: -54.068, steps: 1000
Episode 90: reward: -66.686, steps: 1000
Episode 91: reward: -114.483, steps: 1000
Episode 92: reward: -57.361, steps: 1000
Episode 93: reward: -51.642, steps: 1000
Episode 94: reward: -93.674, steps: 1000
Episode 95: reward: -103.227, steps: 1000
Episode 96: reward: -105.637, steps: 1000
Episode 97: reward: -95.696, steps: 1000
Episode 98: reward: -67.779, steps: 1000
Episode 99: reward: -108.378, steps: 1000
Episode 100: reward: -54.322, steps: 1000
Episode 101: reward: -63.736, steps: 1000
Episode 102: reward: -84.896, steps: 1000
Episode 103: reward: -52.350, steps: 1000
Episode 104: reward: -40.115, steps: 1000
Episode 105: reward: -60.244, steps: 1000
Episode 106: reward: -101.233, steps: 1000
Episode 107: reward: -44.964, steps: 1000
Episode 108: reward: -89.928, steps: 1000
Episode 109: reward: -79.475, steps: 1000
Episode 110: reward: -82.502, steps: 1000
Episode 111: reward: -107.735, steps: 1000
Episode 112: reward: -75.846, steps: 1000
Episode 113: reward: -93.150, steps: 1000
Episode 114: reward: -79.942, steps: 1000
Episode 115: reward: -88.779, steps: 1000
Episode 116: reward: -114.835, steps: 1000
Episode 117: reward: -125.315, steps: 1000
Episode 118: reward: -83.005, steps: 1000
Episode 119: reward: -70.702, steps: 1000
Episode 120: reward: -54.775, steps: 1000
Episode 121: reward: -53.916, steps: 1000
Episode 122: reward: -95.581, steps: 1000
Episode 123: reward: -86.162, steps: 1000
Episode 124: reward: -114.477, steps: 1000
Episode 125: reward: -106.414, steps: 1000
Episode 126: reward: -75.330, steps: 1000
Episode 127: reward: -45.754, steps: 1000
Episode 128: reward: -80.252, steps: 1000
Episode 129: reward: -47.159, steps: 1000
Episode 130: reward: -105.727, steps: 1000
Episode 131: reward: -89.090, steps: 1000
Episode 132: reward: -80.357, steps: 1000
Episode 133: reward: -53.698, steps: 1000
Episode 134: reward: -87.785, steps: 1000
Episode 135: reward: -41.614, steps: 1000
Episode 136: reward: -120.818, steps: 1000
Episode 137: reward: -69.313, steps: 1000
Episode 138: reward: -119.912, steps: 1000
Episode 139: reward: -82.170, steps: 1000
Episode 140: reward: -38.803, steps: 1000
Episode 141: reward: -43.985, steps: 1000
Episode 142: reward: -118.774, steps: 1000
Episode 143: reward: -100.336, steps: 1000
Episode 144: reward: -90.562, steps: 1000
Episode 145: reward: -45.522, steps: 1000
Episode 146: reward: -80.529, steps: 1000
Episode 147: reward: -77.044, steps: 1000
Episode 148: reward: -47.670, steps: 1000
Episode 149: reward: -40.194, steps: 1000
Episode 150: reward: -92.966, steps: 1000
Episode 151: reward: -77.278, steps: 1000
Episode 152: reward: -46.873, steps: 1000
Episode 153: reward: -65.753, steps: 1000
Episode 154: reward: -54.805, steps: 1000
Episode 155: reward: -102.940, steps: 1000
Episode 156: reward: -95.125, steps: 1000
Episode 157: reward: -47.138, steps: 1000
Episode 158: reward: -58.533, steps: 1000
Episode 159: reward: -70.405, steps: 1000
Episode 160: reward: -79.519, steps: 1000
Episode 161: reward: -62.080, steps: 1000
Episode 162: reward: -107.982, steps: 1000
Episode 163: reward: -38.209, steps: 1000
Episode 164: reward: -92.623, steps: 1000
Episode 165: reward: -92.730, steps: 1000
Episode 166: reward: -100.050, steps: 1000
Episode 167: reward: -117.400, steps: 1000
Episode 168: reward: -107.917, steps: 1000
Episode 169: reward: -70.795, steps: 1000
Episode 170: reward: -108.308, steps: 1000
Episode 171: reward: -81.247, steps: 1000
Episode 172: reward: -63.354, steps: 1000
Episode 173: reward: -94.787, steps: 1000
Episode 174: reward: -98.877, steps: 1000
Episode 175: reward: -119.559, steps: 1000
Episode 176: reward: -81.654, steps: 1000
Episode 177: reward: -38.419, steps: 1000
Episode 178: reward: -110.696, steps: 1000
Episode 179: reward: -92.048, steps: 1000
Episode 180: reward: -67.208, steps: 1000
Episode 181: reward: -60.827, steps: 1000
Episode 182: reward: -96.501, steps: 1000
Episode 183: reward: -114.802, steps: 1000
Episode 184: reward: -54.714, steps: 1000
Episode 185: reward: -64.664, steps: 1000
Episode 186: reward: -51.053, steps: 1000
Episode 187: reward: -104.769, steps: 1000
Episode 188: reward: -107.218, steps: 1000
Episode 189: reward: -83.257, steps: 1000
Episode 190: reward: -86.531, steps: 1000
Episode 191: reward: -128.043, steps: 1000
Episode 192: reward: -87.930, steps: 1000
Episode 193: reward: -104.696, steps: 1000
Episode 194: reward: -38.801, steps: 1000
Episode 195: reward: -78.290, steps: 1000
Episode 196: reward: -99.684, steps: 1000
Episode 197: reward: -72.336, steps: 1000
Episode 198: reward: -65.703, steps: 1000
Episode 199: reward: -50.415, steps: 1000
Episode 200: reward: -100.466, steps: 1000

total rewards [-104.231, -35.669, -50.068, -36.481, -102.598, -69.979, -89.02, -68.549, -98.523, -79.001, -51.673, -80.564, -56.508, -130.665, -79.176, -51.271, -79.792, -92.625, -100.128, -57.238, -48.744, -73.732, -54.549, -113.387, -82.968, -66.952, -75.407, -95.735, -69.017, -74.328, -85.235, -48.171, -52.659, -57.253, -50.103, -67.353, -97.246, -56.345, -132.674, -90.873, -95.65, -108.154, -127.996, -63.299, -55.616, -77.48, -44.42, -111.83, -127.231, -37.575, -103.264, -88.426, -61.278, -88.669, -130.941, -44.324, -46.571, -82.244, -98.695, -42.24, -65.163, -74.879, -88.039, -72.838, -119.218, -51.884, -59.085, -101.174, -86.714, -50.576, -61.279, -117.78, -51.864, -71.914, -89.116, -109.142, -107.643, -57.902, -105.55, -81.634, -41.204, -80.806, -81.558, -78.95, -78.013, -84.398, -46.172, -64.088, -54.068, -66.686, -114.483, -57.361, -51.642, -93.674, -103.227, -105.637, -95.696, -67.779, -108.378, -54.322, -63.736, -84.896, -52.35, -40.115, -60.244, -101.233, -44.964, -89.928, -79.475, -82.502, -107.735, -75.846, -93.15, -79.942, -88.779, -114.835, -125.315, -83.005, -70.702, -54.775, -53.916, -95.581, -86.162, -114.477, -106.414, -75.33, -45.754, -80.252, -47.159, -105.727, -89.09, -80.357, -53.698, -87.785, -41.614, -120.818, -69.313, -119.912, -82.17, -38.803, -43.985, -118.774, -100.336, -90.562, -45.522, -80.529, -77.044, -47.67, -40.194, -92.966, -77.278, -46.873, -65.753, -54.805, -102.94, -95.125, -47.138, -58.533, -70.405, -79.519, -62.08, -107.982, -38.209, -92.623, -92.73, -100.05, -117.4, -107.917, -70.795, -108.308, -81.247, -63.354, -94.787, -98.877, -119.559, -81.654, -38.419, -110.696, -92.048, -67.208, -60.827, -96.501, -114.802, -54.714, -64.664, -51.053, -104.769, -107.218, -83.257, -86.531, -128.043, -87.93, -104.696, -38.801, -78.29, -99.684, -72.336, -65.703, -50.415, -100.466]
average total reward -79.07191
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">task2_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;-79.07191&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python lunar_lander_rl_player_model2.py
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Using TensorFlow backend.
2019-04-28 21:13:13.874704: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
results
Testing for 200 episodes ...
Episode 1: reward: -146.097, steps: 1000
Episode 2: reward: -107.581, steps: 1000
Episode 3: reward: -150.205, steps: 677
Episode 4: reward: -167.455, steps: 1000
Episode 5: reward: -143.771, steps: 1000
Episode 6: reward: -137.223, steps: 1000
Episode 7: reward: -119.939, steps: 1000
Episode 8: reward: -132.464, steps: 1000
Episode 9: reward: -145.361, steps: 1000
Episode 10: reward: -112.932, steps: 1000
Episode 11: reward: -82.749, steps: 1000
Episode 12: reward: -127.225, steps: 1000
Episode 13: reward: -144.793, steps: 1000
Episode 14: reward: -102.089, steps: 1000
Episode 15: reward: -116.437, steps: 1000
Episode 16: reward: -143.992, steps: 655
Episode 17: reward: -173.656, steps: 834
Episode 18: reward: -95.258, steps: 1000
Episode 19: reward: -128.563, steps: 1000
Episode 20: reward: -154.983, steps: 1000
Episode 21: reward: -99.125, steps: 1000
Episode 22: reward: -114.454, steps: 1000
Episode 23: reward: -90.872, steps: 1000
Episode 24: reward: -110.453, steps: 1000
Episode 25: reward: -146.470, steps: 1000
Episode 26: reward: -208.835, steps: 873
Episode 27: reward: -132.944, steps: 1000
Episode 28: reward: -135.462, steps: 1000
Episode 29: reward: -123.703, steps: 1000
Episode 30: reward: -139.303, steps: 1000
Episode 31: reward: -261.875, steps: 984
Episode 32: reward: -135.942, steps: 1000
Episode 33: reward: -152.756, steps: 1000
Episode 34: reward: -85.986, steps: 1000
Episode 35: reward: -111.755, steps: 1000
Episode 36: reward: -96.912, steps: 1000
Episode 37: reward: -176.649, steps: 1000
Episode 38: reward: -112.645, steps: 1000
Episode 39: reward: -80.904, steps: 1000
Episode 40: reward: -121.389, steps: 1000
Episode 41: reward: -129.302, steps: 1000
Episode 42: reward: -94.350, steps: 1000
Episode 43: reward: -100.512, steps: 1000
Episode 44: reward: -111.097, steps: 1000
Episode 45: reward: -56.100, steps: 1000
Episode 46: reward: -184.044, steps: 813
Episode 47: reward: -104.222, steps: 1000
Episode 48: reward: -136.076, steps: 1000
Episode 49: reward: -110.074, steps: 1000
Episode 50: reward: -240.068, steps: 866
Episode 51: reward: -76.866, steps: 1000
Episode 52: reward: -120.510, steps: 1000
Episode 53: reward: -152.027, steps: 1000
Episode 54: reward: -105.576, steps: 1000
Episode 55: reward: -93.830, steps: 1000
Episode 56: reward: -134.033, steps: 1000
Episode 57: reward: -144.879, steps: 1000
Episode 58: reward: -150.032, steps: 1000
Episode 59: reward: -125.468, steps: 1000
Episode 60: reward: -145.577, steps: 1000
Episode 61: reward: -142.937, steps: 1000
Episode 62: reward: -195.301, steps: 822
Episode 63: reward: -198.558, steps: 886
Episode 64: reward: -131.277, steps: 1000
Episode 65: reward: -70.024, steps: 1000
Episode 66: reward: -98.144, steps: 1000
Episode 67: reward: -147.219, steps: 1000
Episode 68: reward: -174.188, steps: 647
Episode 69: reward: -73.168, steps: 1000
Episode 70: reward: -125.327, steps: 1000
Episode 71: reward: -133.748, steps: 1000
Episode 72: reward: -50.912, steps: 1000
Episode 73: reward: -129.541, steps: 1000
Episode 74: reward: -120.435, steps: 1000
Episode 75: reward: -132.310, steps: 1000
Episode 76: reward: -142.968, steps: 1000
Episode 77: reward: -156.354, steps: 1000
Episode 78: reward: -162.594, steps: 1000
Episode 79: reward: -92.633, steps: 1000
Episode 80: reward: -144.378, steps: 1000
Episode 81: reward: -136.323, steps: 1000
Episode 82: reward: -194.641, steps: 852
Episode 83: reward: -93.785, steps: 1000
Episode 84: reward: -118.503, steps: 1000
Episode 85: reward: -155.326, steps: 1000
Episode 86: reward: -65.887, steps: 1000
Episode 87: reward: -173.899, steps: 725
Episode 88: reward: -99.438, steps: 1000
Episode 89: reward: -98.886, steps: 1000
Episode 90: reward: -228.453, steps: 995
Episode 91: reward: -129.019, steps: 1000
Episode 92: reward: -190.350, steps: 797
Episode 93: reward: -132.032, steps: 1000
Episode 94: reward: -88.697, steps: 1000
Episode 95: reward: -119.921, steps: 1000
Episode 96: reward: -149.701, steps: 1000
Episode 97: reward: -60.844, steps: 1000
Episode 98: reward: -115.072, steps: 1000
Episode 99: reward: -119.351, steps: 1000
Episode 100: reward: -211.232, steps: 999
Episode 101: reward: -99.990, steps: 1000
Episode 102: reward: -154.651, steps: 1000
Episode 103: reward: -123.222, steps: 1000
Episode 104: reward: -122.347, steps: 1000
Episode 105: reward: -133.088, steps: 1000
Episode 106: reward: -158.804, steps: 1000
Episode 107: reward: -138.780, steps: 1000
Episode 108: reward: -122.994, steps: 1000
Episode 109: reward: -130.507, steps: 1000
Episode 110: reward: -165.666, steps: 1000
Episode 111: reward: -104.943, steps: 1000
Episode 112: reward: -99.983, steps: 1000
Episode 113: reward: -123.962, steps: 1000
Episode 114: reward: -130.251, steps: 1000
Episode 115: reward: -72.107, steps: 1000
Episode 116: reward: -86.238, steps: 1000
Episode 117: reward: -99.668, steps: 1000
Episode 118: reward: -59.335, steps: 1000
Episode 119: reward: -167.828, steps: 1000
Episode 120: reward: -108.213, steps: 1000
Episode 121: reward: -171.893, steps: 1000
Episode 122: reward: -113.326, steps: 1000
Episode 123: reward: -156.041, steps: 1000
Episode 124: reward: -179.397, steps: 820
Episode 125: reward: -117.976, steps: 1000
Episode 126: reward: -230.125, steps: 992
Episode 127: reward: -119.164, steps: 1000
Episode 128: reward: -149.882, steps: 1000
Episode 129: reward: -106.347, steps: 1000
Episode 130: reward: -123.718, steps: 1000
Episode 131: reward: -161.602, steps: 1000
Episode 132: reward: -107.871, steps: 1000
Episode 133: reward: -129.028, steps: 1000
Episode 134: reward: -167.338, steps: 825
Episode 135: reward: -156.366, steps: 1000
Episode 136: reward: -71.142, steps: 1000
Episode 137: reward: -66.336, steps: 1000
Episode 138: reward: -125.787, steps: 1000
Episode 139: reward: -74.985, steps: 1000
Episode 140: reward: -141.396, steps: 1000
Episode 141: reward: -121.469, steps: 1000
Episode 142: reward: -135.357, steps: 1000
Episode 143: reward: -119.504, steps: 1000
Episode 144: reward: -59.326, steps: 1000
Episode 145: reward: -111.912, steps: 1000
Episode 146: reward: -83.873, steps: 1000
Episode 147: reward: -98.669, steps: 1000
Episode 148: reward: -120.955, steps: 1000
Episode 149: reward: -146.698, steps: 1000
Episode 150: reward: -128.654, steps: 1000
Episode 151: reward: -111.349, steps: 1000
Episode 152: reward: -117.924, steps: 1000
Episode 153: reward: -146.386, steps: 1000
Episode 154: reward: -132.973, steps: 1000
Episode 155: reward: -127.865, steps: 1000
Episode 156: reward: -110.675, steps: 1000
Episode 157: reward: -118.612, steps: 1000
Episode 158: reward: -116.217, steps: 1000
Episode 159: reward: -94.044, steps: 1000
Episode 160: reward: -130.667, steps: 1000
Episode 161: reward: -138.381, steps: 1000
Episode 162: reward: -101.495, steps: 1000
Episode 163: reward: -94.471, steps: 1000
Episode 164: reward: -123.514, steps: 1000
Episode 165: reward: -132.177, steps: 1000
Episode 166: reward: -128.662, steps: 1000
Episode 167: reward: -107.946, steps: 1000
Episode 168: reward: -150.406, steps: 1000
Episode 169: reward: -108.036, steps: 1000
Episode 170: reward: -145.911, steps: 1000
Episode 171: reward: -166.664, steps: 1000
Episode 172: reward: -132.428, steps: 1000
Episode 173: reward: -211.998, steps: 921
Episode 174: reward: -87.143, steps: 1000
Episode 175: reward: -172.242, steps: 814
Episode 176: reward: -154.216, steps: 1000
Episode 177: reward: -119.244, steps: 1000
Episode 178: reward: -107.376, steps: 1000
Episode 179: reward: -67.057, steps: 1000
Episode 180: reward: -106.463, steps: 1000
Episode 181: reward: -120.968, steps: 1000
Episode 182: reward: -67.106, steps: 1000
Episode 183: reward: -113.121, steps: 1000
Episode 184: reward: -68.158, steps: 1000
Episode 185: reward: -133.708, steps: 1000
Episode 186: reward: -138.309, steps: 1000
Episode 187: reward: -193.822, steps: 828
Episode 188: reward: -147.268, steps: 1000
Episode 189: reward: -77.364, steps: 1000
Episode 190: reward: -141.052, steps: 1000
Episode 191: reward: -147.910, steps: 1000
Episode 192: reward: -135.171, steps: 1000
Episode 193: reward: -149.185, steps: 1000
Episode 194: reward: -133.094, steps: 1000
Episode 195: reward: -118.852, steps: 1000
Episode 196: reward: -95.558, steps: 1000
Episode 197: reward: -150.186, steps: 1000
Episode 198: reward: -130.839, steps: 1000
Episode 199: reward: -120.243, steps: 1000
Episode 200: reward: -116.948, steps: 1000

total rewards [-146.097, -107.581, -150.205, -167.455, -143.771, -137.223, -119.939, -132.464, -145.361, -112.932, -82.749, -127.225, -144.793, -102.089, -116.437, -143.992, -173.656, -95.258, -128.563, -154.983, -99.125, -114.454, -90.872, -110.453, -146.47, -208.835, -132.944, -135.462, -123.703, -139.303, -261.875, -135.942, -152.756, -85.986, -111.755, -96.912, -176.649, -112.645, -80.904, -121.389, -129.302, -94.35, -100.512, -111.097, -56.1, -184.044, -104.222, -136.076, -110.074, -240.068, -76.866, -120.51, -152.027, -105.576, -93.83, -134.033, -144.879, -150.032, -125.468, -145.577, -142.937, -195.301, -198.558, -131.277, -70.024, -98.144, -147.219, -174.188, -73.168, -125.327, -133.748, -50.912, -129.541, -120.435, -132.31, -142.968, -156.354, -162.594, -92.633, -144.378, -136.323, -194.641, -93.785, -118.503, -155.326, -65.887, -173.899, -99.438, -98.886, -228.453, -129.019, -190.35, -132.032, -88.697, -119.921, -149.701, -60.844, -115.072, -119.351, -211.232, -99.99, -154.651, -123.222, -122.347, -133.088, -158.804, -138.78, -122.994, -130.507, -165.666, -104.943, -99.983, -123.962, -130.251, -72.107, -86.238, -99.668, -59.335, -167.828, -108.213, -171.893, -113.326, -156.041, -179.397, -117.976, -230.125, -119.164, -149.882, -106.347, -123.718, -161.602, -107.871, -129.028, -167.338, -156.366, -71.142, -66.336, -125.787, -74.985, -141.396, -121.469, -135.357, -119.504, -59.326, -111.912, -83.873, -98.669, -120.955, -146.698, -128.654, -111.349, -117.924, -146.386, -132.973, -127.865, -110.675, -118.612, -116.217, -94.044, -130.667, -138.381, -101.495, -94.471, -123.514, -132.177, -128.662, -107.946, -150.406, -108.036, -145.911, -166.664, -132.428, -211.998, -87.143, -172.242, -154.216, -119.244, -107.376, -67.057, -106.463, -120.968, -67.106, -113.121, -68.158, -133.708, -138.309, -193.822, -147.268, -77.364, -141.052, -147.91, -135.171, -149.185, -133.094, -118.852, -95.558, -150.186, -130.839, -120.243, -116.948]
average total reward -127.74672000000001
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">task2_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;-127.74672&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python lunar_lander_rl_player_model3.py
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Using TensorFlow backend.
2019-04-28 21:22:11.902123: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
results
Testing for 200 episodes ...
Episode 1: reward: -31.248, steps: 1000
Episode 2: reward: 5.535, steps: 1000
Episode 3: reward: 0.744, steps: 1000
Episode 4: reward: 13.047, steps: 1000
Episode 5: reward: -21.307, steps: 1000
Episode 6: reward: -5.697, steps: 1000
Episode 7: reward: -18.054, steps: 1000
Episode 8: reward: -8.069, steps: 1000
Episode 9: reward: -24.705, steps: 1000
Episode 10: reward: -15.123, steps: 1000
Episode 11: reward: -1.592, steps: 1000
Episode 12: reward: -12.140, steps: 1000
Episode 13: reward: 8.659, steps: 1000
Episode 14: reward: -66.282, steps: 1000
Episode 15: reward: 4.503, steps: 1000
Episode 16: reward: 19.355, steps: 1000
Episode 17: reward: -12.493, steps: 1000
Episode 18: reward: -21.302, steps: 1000
Episode 19: reward: -31.803, steps: 1000
Episode 20: reward: -4.507, steps: 1000
Episode 21: reward: -0.385, steps: 1000
Episode 22: reward: -6.351, steps: 1000
Episode 23: reward: 14.894, steps: 1000
Episode 24: reward: -41.731, steps: 1000
Episode 25: reward: -28.459, steps: 1000
Episode 26: reward: -15.766, steps: 1000
Episode 27: reward: -3.663, steps: 1000
Episode 28: reward: -25.274, steps: 1000
Episode 29: reward: -36.399, steps: 1000
Episode 30: reward: -17.288, steps: 1000
Episode 31: reward: -24.895, steps: 1000
Episode 32: reward: 8.440, steps: 1000
Episode 33: reward: 9.681, steps: 1000
Episode 34: reward: 7.394, steps: 1000
Episode 35: reward: 3.686, steps: 1000
Episode 36: reward: -1.564, steps: 1000
Episode 37: reward: -29.173, steps: 1000
Episode 38: reward: -5.857, steps: 1000
Episode 39: reward: -58.751, steps: 1000
Episode 40: reward: -19.161, steps: 1000
Episode 41: reward: -355.807, steps: 983
Episode 42: reward: -34.283, steps: 1000
Episode 43: reward: -177.358, steps: 1000
Episode 44: reward: -149.039, steps: 1000
Episode 45: reward: -36.055, steps: 1000
Episode 46: reward: -33.048, steps: 1000
Episode 47: reward: -19.579, steps: 1000
Episode 48: reward: 13.769, steps: 1000
Episode 49: reward: -17.908, steps: 1000
Episode 50: reward: -6.673, steps: 1000
Episode 51: reward: -11.562, steps: 1000
Episode 52: reward: 5.770, steps: 1000
Episode 53: reward: -35.441, steps: 1000
Episode 54: reward: -2.911, steps: 1000
Episode 55: reward: -19.122, steps: 1000
Episode 56: reward: -27.472, steps: 1000
Episode 57: reward: 9.680, steps: 1000
Episode 58: reward: -11.231, steps: 1000
Episode 59: reward: -38.536, steps: 1000
Episode 60: reward: -190.629, steps: 1000
Episode 61: reward: -11.867, steps: 1000
Episode 62: reward: -99.728, steps: 1000
Episode 63: reward: -4.599, steps: 1000
Episode 64: reward: -27.258, steps: 1000
Episode 65: reward: -22.220, steps: 1000
Episode 66: reward: -42.254, steps: 1000
Episode 67: reward: -9.270, steps: 1000
Episode 68: reward: -196.577, steps: 1000
Episode 69: reward: -22.185, steps: 1000
Episode 70: reward: 8.726, steps: 1000
Episode 71: reward: -139.711, steps: 955
Episode 72: reward: -21.355, steps: 1000
Episode 73: reward: -1.874, steps: 1000
Episode 74: reward: -8.473, steps: 1000
Episode 75: reward: 14.428, steps: 1000
Episode 76: reward: -101.325, steps: 1000
Episode 77: reward: -127.945, steps: 1000
Episode 78: reward: -3.761, steps: 1000
Episode 79: reward: -3.561, steps: 1000
Episode 80: reward: -49.900, steps: 1000
Episode 81: reward: 0.401, steps: 1000
Episode 82: reward: -51.233, steps: 1000
Episode 83: reward: -11.207, steps: 1000
Episode 84: reward: -40.695, steps: 1000
Episode 85: reward: 11.257, steps: 1000
Episode 86: reward: 18.711, steps: 1000
Episode 87: reward: -128.002, steps: 857
Episode 88: reward: 10.748, steps: 1000
Episode 89: reward: -7.572, steps: 1000
Episode 90: reward: -9.560, steps: 1000
Episode 91: reward: 8.903, steps: 1000
Episode 92: reward: -21.511, steps: 1000
Episode 93: reward: -0.549, steps: 1000
Episode 94: reward: -11.645, steps: 1000
Episode 95: reward: -12.945, steps: 1000
Episode 96: reward: 8.770, steps: 1000
Episode 97: reward: 1.113, steps: 1000
Episode 98: reward: -47.495, steps: 1000
Episode 99: reward: 0.736, steps: 1000
Episode 100: reward: -42.605, steps: 1000
Episode 101: reward: -1.979, steps: 1000
Episode 102: reward: -42.096, steps: 1000
Episode 103: reward: -13.332, steps: 1000
Episode 104: reward: -33.320, steps: 1000
Episode 105: reward: -20.835, steps: 1000
Episode 106: reward: -0.458, steps: 1000
Episode 107: reward: -34.046, steps: 1000
Episode 108: reward: -28.488, steps: 1000
Episode 109: reward: -19.019, steps: 1000
Episode 110: reward: -19.589, steps: 1000
Episode 111: reward: 14.030, steps: 1000
Episode 112: reward: -39.973, steps: 1000
Episode 113: reward: -51.699, steps: 1000
Episode 114: reward: -38.446, steps: 1000
Episode 115: reward: 15.367, steps: 1000
Episode 116: reward: -30.827, steps: 1000
Episode 117: reward: -2.450, steps: 1000
Episode 118: reward: -7.193, steps: 1000
Episode 119: reward: -31.369, steps: 1000
Episode 120: reward: -37.781, steps: 1000
Episode 121: reward: -20.197, steps: 1000
Episode 122: reward: -10.728, steps: 1000
Episode 123: reward: -1.134, steps: 1000
Episode 124: reward: -36.256, steps: 1000
Episode 125: reward: -59.420, steps: 1000
Episode 126: reward: -4.815, steps: 1000
Episode 127: reward: -28.949, steps: 1000
Episode 128: reward: -54.891, steps: 1000
Episode 129: reward: -25.266, steps: 1000
Episode 130: reward: -242.012, steps: 1000
Episode 131: reward: -35.637, steps: 1000
Episode 132: reward: 10.948, steps: 1000
Episode 133: reward: -23.992, steps: 1000
Episode 134: reward: 12.934, steps: 1000
Episode 135: reward: -33.262, steps: 1000
Episode 136: reward: -9.690, steps: 1000
Episode 137: reward: -0.681, steps: 1000
Episode 138: reward: -53.827, steps: 1000
Episode 139: reward: -59.261, steps: 1000
Episode 140: reward: -58.832, steps: 1000
Episode 141: reward: 8.157, steps: 1000
Episode 142: reward: -58.425, steps: 1000
Episode 143: reward: -24.958, steps: 1000
Episode 144: reward: -28.709, steps: 1000
Episode 145: reward: -3.359, steps: 1000
Episode 146: reward: 0.117, steps: 1000
Episode 147: reward: 13.206, steps: 1000
Episode 148: reward: -65.540, steps: 1000
Episode 149: reward: -35.742, steps: 1000
Episode 150: reward: -4.790, steps: 1000
Episode 151: reward: 0.310, steps: 1000
Episode 152: reward: -35.650, steps: 1000
Episode 153: reward: -0.334, steps: 1000
Episode 154: reward: -54.012, steps: 1000
Episode 155: reward: 5.568, steps: 1000
Episode 156: reward: -22.718, steps: 1000
Episode 157: reward: -149.786, steps: 1000
Episode 158: reward: -24.760, steps: 1000
Episode 159: reward: 9.908, steps: 1000
Episode 160: reward: -67.150, steps: 1000
Episode 161: reward: -27.433, steps: 1000
Episode 162: reward: -3.280, steps: 1000
Episode 163: reward: -19.100, steps: 1000
Episode 164: reward: -41.362, steps: 1000
Episode 165: reward: -22.237, steps: 1000
Episode 166: reward: 6.808, steps: 1000
Episode 167: reward: -1.860, steps: 1000
Episode 168: reward: -5.315, steps: 1000
Episode 169: reward: -4.655, steps: 1000
Episode 170: reward: 13.041, steps: 1000
Episode 171: reward: -20.525, steps: 1000
Episode 172: reward: -23.869, steps: 1000
Episode 173: reward: 26.753, steps: 1000
Episode 174: reward: -26.770, steps: 1000
Episode 175: reward: -29.139, steps: 1000
Episode 176: reward: 0.897, steps: 1000
Episode 177: reward: -30.063, steps: 1000
Episode 178: reward: -1.064, steps: 1000
Episode 179: reward: -23.673, steps: 1000
Episode 180: reward: -10.013, steps: 1000
Episode 181: reward: -8.478, steps: 1000
Episode 182: reward: -181.969, steps: 1000
Episode 183: reward: -8.380, steps: 1000
Episode 184: reward: -9.048, steps: 1000
Episode 185: reward: 29.008, steps: 1000
Episode 186: reward: 0.042, steps: 1000
Episode 187: reward: -83.481, steps: 1000
Episode 188: reward: -202.192, steps: 1000
Episode 189: reward: -0.794, steps: 1000
Episode 190: reward: -32.901, steps: 1000
Episode 191: reward: -20.138, steps: 1000
Episode 192: reward: 19.315, steps: 1000
Episode 193: reward: -27.400, steps: 1000
Episode 194: reward: -0.441, steps: 1000
Episode 195: reward: -46.753, steps: 1000
Episode 196: reward: -17.378, steps: 1000
Episode 197: reward: -4.832, steps: 1000
Episode 198: reward: -1.822, steps: 1000
Episode 199: reward: -13.077, steps: 1000
Episode 200: reward: -10.738, steps: 1000

total rewards [-31.248, 5.535, 0.744, 13.047, -21.307, -5.697, -18.054, -8.069, -24.705, -15.123, -1.592, -12.14, 8.659, -66.282, 4.503, 19.355, -12.493, -21.302, -31.803, -4.507, -0.385, -6.351, 14.894, -41.731, -28.459, -15.766, -3.663, -25.274, -36.399, -17.288, -24.895, 8.44, 9.681, 7.394, 3.686, -1.564, -29.173, -5.857, -58.751, -19.161, -355.807, -34.283, -177.358, -149.039, -36.055, -33.048, -19.579, 13.769, -17.908, -6.673, -11.562, 5.77, -35.441, -2.911, -19.122, -27.472, 9.68, -11.231, -38.536, -190.629, -11.867, -99.728, -4.599, -27.258, -22.22, -42.254, -9.27, -196.577, -22.185, 8.726, -139.711, -21.355, -1.874, -8.473, 14.428, -101.325, -127.945, -3.761, -3.561, -49.9, 0.401, -51.233, -11.207, -40.695, 11.257, 18.711, -128.002, 10.748, -7.572, -9.56, 8.903, -21.511, -0.549, -11.645, -12.945, 8.77, 1.113, -47.495, 0.736, -42.605, -1.979, -42.096, -13.332, -33.32, -20.835, -0.458, -34.046, -28.488, -19.019, -19.589, 14.03, -39.973, -51.699, -38.446, 15.367, -30.827, -2.45, -7.193, -31.369, -37.781, -20.197, -10.728, -1.134, -36.256, -59.42, -4.815, -28.949, -54.891, -25.266, -242.012, -35.637, 10.948, -23.992, 12.934, -33.262, -9.69, -0.681, -53.827, -59.261, -58.832, 8.157, -58.425, -24.958, -28.709, -3.359, 0.117, 13.206, -65.54, -35.742, -4.79, 0.31, -35.65, -0.334, -54.012, 5.568, -22.718, -149.786, -24.76, 9.908, -67.15, -27.433, -3.28, -19.1, -41.362, -22.237, 6.808, -1.86, -5.315, -4.655, 13.041, -20.525, -23.869, 26.753, -26.77, -29.139, 0.897, -30.063, -1.064, -23.673, -10.013, -8.478, -181.969, -8.38, -9.048, 29.008, 0.042, -83.481, -202.192, -0.794, -32.901, -20.138, 19.315, -27.4, -0.441, -46.753, -17.378, -4.832, -1.822, -13.077, -10.738]
average total reward -26.935395
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">task2_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 3&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;-26.935395&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python lunar_lander_rl_player_model4.py
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Using TensorFlow backend.
2019-04-28 21:33:08.561394: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
results
Testing for 200 episodes ...
Episode 1: reward: 93.794, steps: 1000
Episode 2: reward: 125.313, steps: 1000
Episode 3: reward: -215.775, steps: 180
Episode 4: reward: 127.415, steps: 1000
Episode 5: reward: 115.491, steps: 1000
Episode 6: reward: 156.143, steps: 1000
Episode 7: reward: 86.420, steps: 1000
Episode 8: reward: 119.398, steps: 1000
Episode 9: reward: 209.597, steps: 618
Episode 10: reward: 227.445, steps: 450
Episode 11: reward: 123.056, steps: 1000
Episode 12: reward: -251.392, steps: 202
Episode 13: reward: 106.589, steps: 1000
Episode 14: reward: 104.477, steps: 1000
Episode 15: reward: 105.321, steps: 1000
Episode 16: reward: 75.263, steps: 1000
Episode 17: reward: 97.711, steps: 1000
Episode 18: reward: 71.227, steps: 1000
Episode 19: reward: 70.100, steps: 1000
Episode 20: reward: 119.727, steps: 1000
Episode 21: reward: 116.849, steps: 1000
Episode 22: reward: -254.552, steps: 209
Episode 23: reward: -220.091, steps: 206
Episode 24: reward: 80.708, steps: 1000
Episode 25: reward: 109.717, steps: 1000
Episode 26: reward: 128.187, steps: 1000
Episode 27: reward: 102.185, steps: 1000
Episode 28: reward: 96.306, steps: 1000
Episode 29: reward: 230.772, steps: 580
Episode 30: reward: 116.785, steps: 1000
Episode 31: reward: 127.158, steps: 1000
Episode 32: reward: 92.943, steps: 1000
Episode 33: reward: 129.310, steps: 1000
Episode 34: reward: 86.091, steps: 1000
Episode 35: reward: 89.587, steps: 1000
Episode 36: reward: 126.871, steps: 1000
Episode 37: reward: 91.344, steps: 1000
Episode 38: reward: 89.949, steps: 1000
Episode 39: reward: 119.616, steps: 1000
Episode 40: reward: 101.461, steps: 1000
Episode 41: reward: 112.469, steps: 1000
Episode 42: reward: 130.510, steps: 1000
Episode 43: reward: 100.772, steps: 1000
Episode 44: reward: -235.671, steps: 194
Episode 45: reward: 100.647, steps: 1000
Episode 46: reward: 133.661, steps: 1000
Episode 47: reward: 201.735, steps: 461
Episode 48: reward: 226.765, steps: 607
Episode 49: reward: 126.702, steps: 1000
Episode 50: reward: 91.999, steps: 1000
Episode 51: reward: -75.686, steps: 354
Episode 52: reward: 109.203, steps: 1000
Episode 53: reward: 142.278, steps: 1000
Episode 54: reward: 116.525, steps: 1000
Episode 55: reward: 114.192, steps: 1000
Episode 56: reward: 105.452, steps: 1000
Episode 57: reward: 190.514, steps: 497
Episode 58: reward: 89.782, steps: 1000
Episode 59: reward: 75.240, steps: 1000
Episode 60: reward: 118.629, steps: 1000
Episode 61: reward: 144.411, steps: 1000
Episode 62: reward: 98.882, steps: 1000
Episode 63: reward: 99.009, steps: 1000
Episode 64: reward: 125.636, steps: 1000
Episode 65: reward: 124.957, steps: 1000
Episode 66: reward: 187.829, steps: 564
Episode 67: reward: 109.886, steps: 1000
Episode 68: reward: 103.262, steps: 1000
Episode 69: reward: 118.556, steps: 1000
Episode 70: reward: 226.005, steps: 516
Episode 71: reward: 123.445, steps: 1000
Episode 72: reward: 85.024, steps: 1000
Episode 73: reward: -302.401, steps: 228
Episode 74: reward: 137.778, steps: 1000
Episode 75: reward: 133.225, steps: 1000
Episode 76: reward: -206.570, steps: 185
Episode 77: reward: 81.686, steps: 1000
Episode 78: reward: 109.514, steps: 1000
Episode 79: reward: 124.476, steps: 1000
Episode 80: reward: 117.420, steps: 1000
Episode 81: reward: 65.103, steps: 1000
Episode 82: reward: 124.611, steps: 1000
Episode 83: reward: 102.941, steps: 1000
Episode 84: reward: 133.892, steps: 1000
Episode 85: reward: 115.395, steps: 1000
Episode 86: reward: 135.365, steps: 1000
Episode 87: reward: 125.919, steps: 1000
Episode 88: reward: 101.064, steps: 1000
Episode 89: reward: 117.343, steps: 1000
Episode 90: reward: 134.238, steps: 1000
Episode 91: reward: 150.757, steps: 1000
Episode 92: reward: 84.297, steps: 1000
Episode 93: reward: 217.491, steps: 376
Episode 94: reward: 253.014, steps: 497
Episode 95: reward: 118.088, steps: 1000
Episode 96: reward: -260.639, steps: 195
Episode 97: reward: -287.826, steps: 192
Episode 98: reward: 137.101, steps: 1000
Episode 99: reward: 171.227, steps: 594
Episode 100: reward: 139.556, steps: 1000
Episode 101: reward: 118.780, steps: 1000
Episode 102: reward: 253.406, steps: 432
Episode 103: reward: 101.907, steps: 1000
Episode 104: reward: 109.594, steps: 1000
Episode 105: reward: 105.027, steps: 1000
Episode 106: reward: 116.430, steps: 1000
Episode 107: reward: 98.255, steps: 1000
Episode 108: reward: 109.583, steps: 1000
Episode 109: reward: 93.167, steps: 1000
Episode 110: reward: 212.631, steps: 442
Episode 111: reward: 94.787, steps: 1000
Episode 112: reward: 114.532, steps: 1000
Episode 113: reward: 102.494, steps: 1000
Episode 114: reward: 245.355, steps: 484
Episode 115: reward: 94.439, steps: 1000
Episode 116: reward: 83.180, steps: 1000
Episode 117: reward: 102.863, steps: 1000
Episode 118: reward: 157.986, steps: 1000
Episode 119: reward: -195.821, steps: 171
Episode 120: reward: 121.960, steps: 1000
Episode 121: reward: -0.317, steps: 411
Episode 122: reward: 136.984, steps: 1000
Episode 123: reward: 108.485, steps: 1000
Episode 124: reward: 110.244, steps: 1000
Episode 125: reward: 107.186, steps: 1000
Episode 126: reward: 88.482, steps: 1000
Episode 127: reward: 104.369, steps: 1000
Episode 128: reward: 123.094, steps: 1000
Episode 129: reward: -253.693, steps: 191
Episode 130: reward: 128.125, steps: 1000
Episode 131: reward: 114.658, steps: 1000
Episode 132: reward: 100.314, steps: 1000
Episode 133: reward: -285.037, steps: 271
Episode 134: reward: 204.663, steps: 463
Episode 135: reward: 115.492, steps: 1000
Episode 136: reward: 90.557, steps: 1000
Episode 137: reward: 109.047, steps: 1000
Episode 138: reward: 117.398, steps: 1000
Episode 139: reward: 121.217, steps: 1000
Episode 140: reward: 112.074, steps: 1000
Episode 141: reward: 116.983, steps: 1000
Episode 142: reward: -279.596, steps: 264
Episode 143: reward: 216.668, steps: 559
Episode 144: reward: 99.914, steps: 1000
Episode 145: reward: 127.172, steps: 1000
Episode 146: reward: 75.730, steps: 1000
Episode 147: reward: 108.816, steps: 1000
Episode 148: reward: 107.168, steps: 1000
Episode 149: reward: 148.345, steps: 1000
Episode 150: reward: 138.920, steps: 1000
Episode 151: reward: 206.454, steps: 488
Episode 152: reward: -264.928, steps: 204
Episode 153: reward: -226.498, steps: 207
Episode 154: reward: 216.824, steps: 540
Episode 155: reward: 214.470, steps: 631
Episode 156: reward: 84.138, steps: 1000
Episode 157: reward: 127.429, steps: 1000
Episode 158: reward: 135.286, steps: 1000
Episode 159: reward: 97.620, steps: 1000
Episode 160: reward: 105.645, steps: 1000
Episode 161: reward: 140.005, steps: 1000
Episode 162: reward: 199.904, steps: 485
Episode 163: reward: 236.058, steps: 599
Episode 164: reward: 118.814, steps: 1000
Episode 165: reward: 99.714, steps: 1000
Episode 166: reward: 224.535, steps: 411
Episode 167: reward: -262.821, steps: 202
Episode 168: reward: 123.494, steps: 1000
Episode 169: reward: 110.053, steps: 1000
Episode 170: reward: 95.360, steps: 1000
Episode 171: reward: 146.488, steps: 1000
Episode 172: reward: 102.129, steps: 1000
Episode 173: reward: 203.690, steps: 530
Episode 174: reward: -203.345, steps: 192
Episode 175: reward: 137.223, steps: 1000
Episode 176: reward: 80.635, steps: 1000
Episode 177: reward: 89.141, steps: 1000
Episode 178: reward: -180.901, steps: 205
Episode 179: reward: 111.332, steps: 1000
Episode 180: reward: 149.701, steps: 1000
Episode 181: reward: 114.439, steps: 1000
Episode 182: reward: 119.715, steps: 1000
Episode 183: reward: 93.006, steps: 1000
Episode 184: reward: 96.525, steps: 1000
Episode 185: reward: 233.903, steps: 456
Episode 186: reward: 102.917, steps: 1000
Episode 187: reward: 108.910, steps: 1000
Episode 188: reward: 143.452, steps: 1000
Episode 189: reward: 160.777, steps: 1000
Episode 190: reward: 143.924, steps: 1000
Episode 191: reward: 123.384, steps: 1000
Episode 192: reward: 112.224, steps: 1000
Episode 193: reward: 213.803, steps: 656
Episode 194: reward: 74.737, steps: 1000
Episode 195: reward: 114.660, steps: 1000
Episode 196: reward: 121.164, steps: 1000
Episode 197: reward: 100.244, steps: 1000
Episode 198: reward: 107.009, steps: 1000
Episode 199: reward: 236.327, steps: 559
Episode 200: reward: 80.062, steps: 1000

total rewards [93.794, 125.313, -215.775, 127.415, 115.491, 156.143, 86.42, 119.398, 209.597, 227.445, 123.056, -251.392, 106.589, 104.477, 105.321, 75.263, 97.711, 71.227, 70.1, 119.727, 116.849, -254.552, -220.091, 80.708, 109.717, 128.187, 102.185, 96.306, 230.772, 116.785, 127.158, 92.943, 129.31, 86.091, 89.587, 126.871, 91.344, 89.949, 119.616, 101.461, 112.469, 130.51, 100.772, -235.671, 100.647, 133.661, 201.735, 226.765, 126.702, 91.999, -75.686, 109.203, 142.278, 116.525, 114.192, 105.452, 190.514, 89.782, 75.24, 118.629, 144.411, 98.882, 99.009, 125.636, 124.957, 187.829, 109.886, 103.262, 118.556, 226.005, 123.445, 85.024, -302.401, 137.778, 133.225, -206.57, 81.686, 109.514, 124.476, 117.42, 65.103, 124.611, 102.941, 133.892, 115.395, 135.365, 125.919, 101.064, 117.343, 134.238, 150.757, 84.297, 217.491, 253.014, 118.088, -260.639, -287.826, 137.101, 171.227, 139.556, 118.78, 253.406, 101.907, 109.594, 105.027, 116.43, 98.255, 109.583, 93.167, 212.631, 94.787, 114.532, 102.494, 245.355, 94.439, 83.18, 102.863, 157.986, -195.821, 121.96, -0.317, 136.984, 108.485, 110.244, 107.186, 88.482, 104.369, 123.094, -253.693, 128.125, 114.658, 100.314, -285.037, 204.663, 115.492, 90.557, 109.047, 117.398, 121.217, 112.074, 116.983, -279.596, 216.668, 99.914, 127.172, 75.73, 108.816, 107.168, 148.345, 138.92, 206.454, -264.928, -226.498, 216.824, 214.47, 84.138, 127.429, 135.286, 97.62, 105.645, 140.005, 199.904, 236.058, 118.814, 99.714, 224.535, -262.821, 123.494, 110.053, 95.36, 146.488, 102.129, 203.69, -203.345, 137.223, 80.635, 89.141, -180.901, 111.332, 149.701, 114.439, 119.715, 93.006, 96.525, 233.903, 102.917, 108.91, 143.452, 160.777, 143.924, 123.384, 112.224, 213.803, 74.737, 114.66, 121.164, 100.244, 107.009, 236.327, 80.062]
average total reward 91.990245
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">task2_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 4&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;91.990245&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python lunar_lander_rl_player_model5.py
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Using TensorFlow backend.
2019-04-28 21:41:12.489404: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
results
Testing for 200 episodes ...
Episode 1: reward: -52.496, steps: 1000
Episode 2: reward: -58.191, steps: 298
Episode 3: reward: -129.416, steps: 202
Episode 4: reward: -39.778, steps: 1000
Episode 5: reward: -96.629, steps: 337
Episode 6: reward: -77.787, steps: 1000
Episode 7: reward: -33.579, steps: 1000
Episode 8: reward: 61.435, steps: 863
Episode 9: reward: -147.273, steps: 199
Episode 10: reward: -58.201, steps: 1000
Episode 11: reward: -131.636, steps: 228
Episode 12: reward: -51.474, steps: 1000
Episode 13: reward: -19.968, steps: 1000
Episode 14: reward: -34.425, steps: 1000
Episode 15: reward: -30.228, steps: 1000
Episode 16: reward: -124.573, steps: 294
Episode 17: reward: -54.870, steps: 1000
Episode 18: reward: -124.986, steps: 204
Episode 19: reward: -31.925, steps: 1000
Episode 20: reward: -104.185, steps: 141
Episode 21: reward: -27.211, steps: 1000
Episode 22: reward: -55.828, steps: 1000
Episode 23: reward: -164.693, steps: 182
Episode 24: reward: -60.554, steps: 1000
Episode 25: reward: -7.152, steps: 1000
Episode 26: reward: 225.593, steps: 625
Episode 27: reward: -32.728, steps: 1000
Episode 28: reward: -141.065, steps: 194
Episode 29: reward: -64.276, steps: 1000
Episode 30: reward: -20.900, steps: 1000
Episode 31: reward: 2.242, steps: 1000
Episode 32: reward: -6.377, steps: 1000
Episode 33: reward: -114.887, steps: 260
Episode 34: reward: -84.658, steps: 140
Episode 35: reward: -96.943, steps: 272
Episode 36: reward: -35.439, steps: 1000
Episode 37: reward: 42.902, steps: 1000
Episode 38: reward: -139.420, steps: 217
Episode 39: reward: -51.608, steps: 1000
Episode 40: reward: -37.925, steps: 1000
Episode 41: reward: -110.413, steps: 207
Episode 42: reward: -24.472, steps: 1000
Episode 43: reward: -40.609, steps: 1000
Episode 44: reward: -72.891, steps: 1000
Episode 45: reward: -162.750, steps: 193
Episode 46: reward: -42.145, steps: 1000
Episode 47: reward: -126.298, steps: 200
Episode 48: reward: -96.481, steps: 288
Episode 49: reward: -127.920, steps: 193
Episode 50: reward: -71.467, steps: 1000
Episode 51: reward: -130.241, steps: 194
Episode 52: reward: -66.679, steps: 1000
Episode 53: reward: -127.913, steps: 204
Episode 54: reward: -49.998, steps: 1000
Episode 55: reward: -101.710, steps: 262
Episode 56: reward: -47.035, steps: 1000
Episode 57: reward: -145.158, steps: 189
Episode 58: reward: -26.351, steps: 1000
Episode 59: reward: -114.491, steps: 216
Episode 60: reward: -156.201, steps: 177
Episode 61: reward: -73.433, steps: 1000
Episode 62: reward: -31.783, steps: 1000
Episode 63: reward: -19.283, steps: 1000
Episode 64: reward: -86.558, steps: 297
Episode 65: reward: -12.306, steps: 1000
Episode 66: reward: -69.993, steps: 1000
Episode 67: reward: -65.898, steps: 1000
Episode 68: reward: -82.353, steps: 1000
Episode 69: reward: -123.671, steps: 198
Episode 70: reward: -43.974, steps: 1000
Episode 71: reward: -123.520, steps: 248
Episode 72: reward: -37.076, steps: 1000
Episode 73: reward: -140.993, steps: 197
Episode 74: reward: -59.866, steps: 1000
Episode 75: reward: 159.406, steps: 997
Episode 76: reward: -26.995, steps: 1000
Episode 77: reward: -40.405, steps: 1000
Episode 78: reward: -29.404, steps: 1000
Episode 79: reward: -52.664, steps: 1000
Episode 80: reward: -62.625, steps: 1000
Episode 81: reward: -107.250, steps: 292
Episode 82: reward: -52.742, steps: 1000
Episode 83: reward: -37.055, steps: 1000
Episode 84: reward: -30.241, steps: 1000
Episode 85: reward: -53.550, steps: 1000
Episode 86: reward: -54.679, steps: 1000
Episode 87: reward: -136.160, steps: 206
Episode 88: reward: -70.750, steps: 1000
Episode 89: reward: -57.515, steps: 1000
Episode 90: reward: -38.352, steps: 1000
Episode 91: reward: -120.796, steps: 228
Episode 92: reward: -19.887, steps: 1000
Episode 93: reward: -10.613, steps: 1000
Episode 94: reward: -44.576, steps: 1000
Episode 95: reward: -47.732, steps: 1000
Episode 96: reward: -58.132, steps: 1000
Episode 97: reward: -48.618, steps: 1000
Episode 98: reward: -88.177, steps: 288
Episode 99: reward: -129.512, steps: 209
Episode 100: reward: -24.347, steps: 1000
Episode 101: reward: -48.555, steps: 1000
Episode 102: reward: -123.359, steps: 200
Episode 103: reward: -87.364, steps: 1000
Episode 104: reward: -37.622, steps: 1000
Episode 105: reward: -41.533, steps: 1000
Episode 106: reward: -87.700, steps: 376
Episode 107: reward: -49.503, steps: 1000
Episode 108: reward: -18.762, steps: 1000
Episode 109: reward: -116.279, steps: 200
Episode 110: reward: -29.293, steps: 1000
Episode 111: reward: -133.770, steps: 205
Episode 112: reward: -11.646, steps: 1000
Episode 113: reward: -130.502, steps: 196
Episode 114: reward: -48.974, steps: 1000
Episode 115: reward: -108.083, steps: 234
Episode 116: reward: -139.894, steps: 186
Episode 117: reward: -94.821, steps: 293
Episode 118: reward: -21.068, steps: 1000
Episode 119: reward: -3.628, steps: 1000
Episode 120: reward: -25.882, steps: 1000
Episode 121: reward: -134.492, steps: 201
Episode 122: reward: -52.509, steps: 1000
Episode 123: reward: -31.876, steps: 1000
Episode 124: reward: -123.746, steps: 237
Episode 125: reward: -83.620, steps: 275
Episode 126: reward: -36.949, steps: 1000
Episode 127: reward: -57.533, steps: 1000
Episode 128: reward: -84.229, steps: 1000
Episode 129: reward: -6.565, steps: 1000
Episode 130: reward: -61.724, steps: 1000
Episode 131: reward: -78.244, steps: 1000
Episode 132: reward: -46.067, steps: 1000
Episode 133: reward: -40.836, steps: 1000
Episode 134: reward: -23.445, steps: 1000
Episode 135: reward: -166.246, steps: 182
Episode 136: reward: -70.563, steps: 1000
Episode 137: reward: -39.373, steps: 1000
Episode 138: reward: -133.902, steps: 642
Episode 139: reward: -67.957, steps: 1000
Episode 140: reward: -20.003, steps: 1000
Episode 141: reward: -90.296, steps: 1000
Episode 142: reward: -60.180, steps: 1000
Episode 143: reward: -155.858, steps: 177
Episode 144: reward: -168.846, steps: 163
Episode 145: reward: -20.646, steps: 1000
Episode 146: reward: -14.396, steps: 1000
Episode 147: reward: -89.768, steps: 1000
Episode 148: reward: -31.402, steps: 1000
Episode 149: reward: -85.701, steps: 1000
Episode 150: reward: -25.579, steps: 1000
Episode 151: reward: -68.178, steps: 1000
Episode 152: reward: -80.773, steps: 350
Episode 153: reward: -40.646, steps: 1000
Episode 154: reward: -91.184, steps: 325
Episode 155: reward: -127.954, steps: 218
Episode 156: reward: -108.719, steps: 214
Episode 157: reward: -72.312, steps: 1000
Episode 158: reward: -98.904, steps: 239
Episode 159: reward: 189.355, steps: 836
Episode 160: reward: -99.570, steps: 314
Episode 161: reward: -28.911, steps: 1000
Episode 162: reward: -22.151, steps: 1000
Episode 163: reward: -38.527, steps: 1000
Episode 164: reward: -27.366, steps: 1000
Episode 165: reward: -33.850, steps: 1000
Episode 166: reward: -41.377, steps: 1000
Episode 167: reward: -122.355, steps: 210
Episode 168: reward: -13.886, steps: 1000
Episode 169: reward: -46.617, steps: 1000
Episode 170: reward: -48.283, steps: 1000
Episode 171: reward: -89.278, steps: 345
Episode 172: reward: -54.993, steps: 1000
Episode 173: reward: -171.318, steps: 171
Episode 174: reward: -18.670, steps: 1000
Episode 175: reward: -31.068, steps: 1000
Episode 176: reward: 136.859, steps: 804
Episode 177: reward: -24.211, steps: 1000
Episode 178: reward: -93.692, steps: 1000
Episode 179: reward: -121.864, steps: 1000
Episode 180: reward: -53.278, steps: 1000
Episode 181: reward: 29.884, steps: 1000
Episode 182: reward: -149.232, steps: 176
Episode 183: reward: -63.747, steps: 1000
Episode 184: reward: -111.304, steps: 251
Episode 185: reward: -18.195, steps: 1000
Episode 186: reward: -26.689, steps: 1000
Episode 187: reward: -19.239, steps: 1000
Episode 188: reward: 165.776, steps: 998
Episode 189: reward: -118.325, steps: 235
Episode 190: reward: -39.516, steps: 1000
Episode 191: reward: -33.161, steps: 1000
Episode 192: reward: -125.470, steps: 230
Episode 193: reward: 1.229, steps: 1000
Episode 194: reward: -50.896, steps: 1000
Episode 195: reward: -30.457, steps: 1000
Episode 196: reward: -79.637, steps: 509
Episode 197: reward: -111.275, steps: 272
Episode 198: reward: -54.021, steps: 1000
Episode 199: reward: -114.337, steps: 208
Episode 200: reward: -6.272, steps: 1000

total rewards [-52.496, -58.191, -129.416, -39.778, -96.629, -77.787, -33.579, 61.435, -147.273, -58.201, -131.636, -51.474, -19.968, -34.425, -30.228, -124.573, -54.87, -124.986, -31.925, -104.185, -27.211, -55.828, -164.693, -60.554, -7.152, 225.593, -32.728, -141.065, -64.276, -20.9, 2.242, -6.377, -114.887, -84.658, -96.943, -35.439, 42.902, -139.42, -51.608, -37.925, -110.413, -24.472, -40.609, -72.891, -162.75, -42.145, -126.298, -96.481, -127.92, -71.467, -130.241, -66.679, -127.913, -49.998, -101.71, -47.035, -145.158, -26.351, -114.491, -156.201, -73.433, -31.783, -19.283, -86.558, -12.306, -69.993, -65.898, -82.353, -123.671, -43.974, -123.52, -37.076, -140.993, -59.866, 159.406, -26.995, -40.405, -29.404, -52.664, -62.625, -107.25, -52.742, -37.055, -30.241, -53.55, -54.679, -136.16, -70.75, -57.515, -38.352, -120.796, -19.887, -10.613, -44.576, -47.732, -58.132, -48.618, -88.177, -129.512, -24.347, -48.555, -123.359, -87.364, -37.622, -41.533, -87.7, -49.503, -18.762, -116.279, -29.293, -133.77, -11.646, -130.502, -48.974, -108.083, -139.894, -94.821, -21.068, -3.628, -25.882, -134.492, -52.509, -31.876, -123.746, -83.62, -36.949, -57.533, -84.229, -6.565, -61.724, -78.244, -46.067, -40.836, -23.445, -166.246, -70.563, -39.373, -133.902, -67.957, -20.003, -90.296, -60.18, -155.858, -168.846, -20.646, -14.396, -89.768, -31.402, -85.701, -25.579, -68.178, -80.773, -40.646, -91.184, -127.954, -108.719, -72.312, -98.904, 189.355, -99.57, -28.911, -22.151, -38.527, -27.366, -33.85, -41.377, -122.355, -13.886, -46.617, -48.283, -89.278, -54.993, -171.318, -18.67, -31.068, 136.859, -24.211, -93.692, -121.864, -53.278, 29.884, -149.232, -63.747, -111.304, -18.195, -26.689, -19.239, 165.776, -118.325, -39.516, -33.161, -125.47, 1.229, -50.896, -30.457, -79.637, -111.275, -54.021, -114.337, -6.272]
average total reward -61.329035000000005
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">task2_model_reward_comparisons</span><span class="p">[</span><span class="s2">&quot;Model 5&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;-61.32903500&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rl_model_reward_comparisons</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[52]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;Model 1&#39;: -76.05800147872863,
 &#39;Model 2&#39;: -125.63024379728482,
 &#39;Model 3&#39;: -23.049652860423006,
 &#39;Model 4&#39;: 87.6691901914162,
 &#39;Model 5&#39;: -75.87643170241438}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rl_model_time_comparisons</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[53]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;Model 1&#39;: 639.8961799144745,
 &#39;Model 2&#39;: 683.990748167038,
 &#39;Model 3&#39;: 715.8376429080963,
 &#39;Model 4&#39;: 769.9784548282623,
 &#39;Model 5&#39;: 772.2631468772888}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">task2_model_reward_comparisons</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[54]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;Model 1&#39;: &#39;-79.07191&#39;,
 &#39;Model 2&#39;: &#39;-127.74672&#39;,
 &#39;Model 3&#39;: &#39;-26.935395&#39;,
 &#39;Model 4&#39;: &#39;91.990245&#39;,
 &#39;Model 5&#39;: &#39;-61.32903500&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dict_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">rl_model_reward_comparisons</span><span class="p">,</span><span class="n">rl_model_time_comparisons</span><span class="p">,</span><span class="n">task2_model_reward_comparisons</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;part2_model_results.txt&#39;</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
    <span class="n">fd</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">dict_list</span><span class="p">))</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fd</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[{&#39;Model 1&#39;: -76.05800147872863, &#39;Model 2&#39;: -125.63024379728482, &#39;Model 3&#39;: -23.049652860423006, &#39;Model 4&#39;: 87.6691901914162, &#39;Model 5&#39;: -75.87643170241438}, {&#39;Model 1&#39;: 639.8961799144745, &#39;Model 2&#39;: 683.990748167038, &#39;Model 3&#39;: 715.8376429080963, &#39;Model 4&#39;: 769.9784548282623, &#39;Model 5&#39;: 772.2631468772888}, {&#39;Model 1&#39;: &#39;-79.07191&#39;, &#39;Model 2&#39;: &#39;-127.74672&#39;, &#39;Model 3&#39;: &#39;-26.935395&#39;, &#39;Model 4&#39;: &#39;91.990245&#39;, &#39;Model 5&#39;: &#39;-61.32903500&#39;}]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
